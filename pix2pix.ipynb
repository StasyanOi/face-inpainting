{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookId":"68f84228-f3f2-4b07-8241-2be2f562fe98","language_info":{"mimetype":"text/x-python","version":"3.7.7","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"name":"ipython","version":3}},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"code","source":"from __future__ import print_function, division\n\nimport datetime\nimport os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.losses import mean_absolute_error\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Input, Dropout, Concatenate\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import UpSampling2D, Conv2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nimport PIL.Image as Image\nimport cv2.cv2 as cv2\nfrom data_loader import DataLoader","metadata":{"cellId":"7ihj9ch40kb5cqavz4fsr5","trusted":true},"outputs":[],"execution_count":194},{"cell_type":"code","source":"\nclass Pix2Pix():\n\n    def l1(self, y_true, y_pred):\n        return mean_absolute_error(y_true, y_pred)\n\n    def ssim_loss(self, y_true, y_pred):\n        return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n\n    def generator_loss(self, y_true, y_pred):\n        return self.l1(y_true, y_pred) + self.ssim_loss(y_true, y_pred)\n\n    def __init__(self):\n        self.img_rows = 256\n        self.img_cols = 256\n        self.channels = 3\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n\n        # Configure data loader\n        self.dataset_name = 'facades'\n        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n                                      img_res=(self.img_rows, self.img_cols))\n\n        # Calculate output shape of D (PatchGAN)\n        patch = int(self.img_rows / 2 ** 4)\n        self.disc_patch = (patch, patch, 1)\n\n        # Number of filters in the first layer of G and D\n        self.gf = 64\n        self.df = 64\n\n        optimizer = Adam(0.0002, 0.5)\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.summary()\n        self.discriminator.compile(loss='mse',\n                                   optimizer=optimizer,\n                                   metrics=['accuracy'])\n\n        self.discriminator_mask = self.build_discriminator()\n        self.discriminator_mask.compile(loss='mse', loss_weights=[2],\n                                        optimizer=optimizer,\n                                        metrics=['accuracy'])\n        # -------------------------\n        # Construct Computational\n        #   Graph of Generator\n        # -------------------------\n\n        # Build the generator\n        self.generator = self.build_generator()\n        self.generator.summary()\n\n        # Input images and their conditioning images\n        img_A = Input(shape=self.img_shape)\n        img_B = Input(shape=self.img_shape)\n\n        # By conditioning on B generate a fake version of A\n        fake_A = self.generator(img_B)\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n        self.discriminator_mask.trainable = False\n\n        # Discriminators determines validity of translated images / condition pairs\n        valid = self.discriminator([fake_A, img_B])\n        valid_mask = self.discriminator_mask([fake_A, img_B])\n\n        self.combined = Model(inputs=[img_A, img_B], outputs=[valid, valid_mask, fake_A])\n        self.combined.compile(loss=['mse', 'mse', self.generator_loss],\n                              loss_weights=[1, 2, 100],\n                              optimizer=optimizer)\n\n    def build_generator(self):\n        \"\"\"U-Net Generator\"\"\"\n\n        def conv2d(layer_input, filters, f_size=4, bn=True):\n            \"\"\"Layers used during downsampling\"\"\"\n            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n            d = LeakyReLU(alpha=0.2)(d)\n            if bn:\n                d = BatchNormalization(momentum=0.8)(d)\n            return d\n\n        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n            \"\"\"Layers used during upsampling\"\"\"\n            u = UpSampling2D(size=2)(layer_input)\n            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n            if dropout_rate:\n                u = Dropout(dropout_rate)(u)\n            u = BatchNormalization(momentum=0.8)(u)\n            u = Concatenate()([u, skip_input])\n            return u\n\n        # Image input\n        d0 = Input(shape=self.img_shape)\n\n        # Downsampling\n        d1 = conv2d(d0, self.gf, bn=False)\n        d2 = conv2d(d1, self.gf * 2)\n        d3 = conv2d(d2, self.gf * 4)\n        d4 = conv2d(d3, self.gf * 8)\n        d5 = conv2d(d4, self.gf * 8)\n        d6 = conv2d(d5, self.gf * 16)\n        d7 = conv2d(d6, self.gf * 16)\n\n        # Upsampling\n        u1 = deconv2d(d7, d6, self.gf * 8)\n        u2 = deconv2d(u1, d5, self.gf * 8)\n        u3 = deconv2d(u2, d4, self.gf * 8)\n        u4 = deconv2d(u3, d3, self.gf * 4)\n        u5 = deconv2d(u4, d2, self.gf * 2)\n        u6 = deconv2d(u5, d1, self.gf)\n\n        u7 = UpSampling2D(size=2)(u6)\n        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n\n        return Model(d0, output_img)\n\n    def build_discriminator(self):\n\n        def d_layer(layer_input, filters, f_size=4, bn=True):\n            \"\"\"Discriminator layer\"\"\"\n            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n            d = LeakyReLU(alpha=0.2)(d)\n            if bn:\n                d = BatchNormalization(momentum=0.8)(d)\n            return d\n\n        img_A = Input(shape=self.img_shape)\n        img_B = Input(shape=self.img_shape)\n\n        # Concatenate image and conditioning image by channels to produce input\n        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n\n        d1 = d_layer(combined_imgs, self.df, bn=False)\n        d2 = d_layer(d1, self.df * 2)\n        d3 = d_layer(d2, self.df * 4)\n        d4 = d_layer(d3, self.df * 8)\n\n        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n\n        return Model([img_A, img_B], validity)\n\n    def train(self, epochs, batch_size=1, sample_interval=50):\n\n        start_time = datetime.datetime.now()\n\n        # Adversarial loss ground truths\n        valid = np.ones((64,) + self.disc_patch)\n        fake = np.zeros((64,) + self.disc_patch)\n\n        for epoch in range(epochs):\n            (imgs_A, imgs_B, mask) = self.data_loader.load_data()\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Condition on B and generate a translated version\n            fake_A = self.generator.predict(imgs_B)\n\n            # Train the discriminators (original images = real / generated = Fake)\n            d_loss_real = self.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n            d_loss_fake = self.discriminator.train_on_batch([fake_A, imgs_B], fake)\n\n            d_loss_real_mask = self.discriminator_mask.train_on_batch([imgs_A, imgs_B], valid)\n            fake_A_mask = imgs_A * (1 - mask) + fake_A * mask\n            d_loss_fake_mask = self.discriminator_mask.train_on_batch([fake_A_mask, imgs_B], fake)\n\n            d_loss_whole = 0.5 * np.add(d_loss_real, d_loss_fake)\n            d_loss_mask = 0.5 * np.add(d_loss_real_mask, d_loss_fake_mask)\n\n            # -----------------\n            #  Train Generator\n            # -----------------\n\n            # Train the generators\n            g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, valid, imgs_A])\n\n            elapsed_time = datetime.datetime.now() - start_time\n            # Plot the progress\n            print(\"[Epoch %d/%d] [D loss_whole: %f, acc: %3d%%] [D loss_mask: %f, acc: %3d%%] [G loss: %f] time: %s\" % (\n            epoch, epochs,\n            d_loss_whole[0],\n            100 * d_loss_whole[1],\n            d_loss_mask[0],\n            100 * d_loss_mask[1],\n            g_loss[0],\n            elapsed_time))\n\n            # If at save interval => save generated image samples\n            # if epoch % sample_interval == 0:\n            if epoch % 100 == 0:\n                self.sample_images(epoch)\n                self.generator.save(\"saved_models/inpaint_net\" + str(epoch), save_format=\"tf\")\n\n    def sample_images(self, epoch):\n        imgs_A, imgs_B, _ = self.data_loader.load_data()\n        fake_A = self.generator.predict(imgs_B)\n        \n        cv2.imwrite(\"gan_images/real\" + str(epoch) + \".png\", ((0.5 * imgs_A[0] + 0.5) * 255).astype('uint8'))\n        cv2.imwrite(\"gan_images/input\" + str(epoch) + \".png\", ((0.5 * imgs_B[0] + 0.5) * 255).astype('uint8'))\n        cv2.imwrite(\"gan_images/generated\" + str(epoch) + \".png\", ((0.5 * fake_A[0] + 0.5) * 255).astype('uint8'))\n","metadata":{"cellId":"xcyb0y1znymkbxos4j4rzq","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n"}],"execution_count":195},{"cell_type":"code","source":"#!g1.1\nif __name__ == '__main__':\n    gan = Pix2Pix()\n    gan.train(epochs=80000, batch_size=1, sample_interval=200)","metadata":{"cellId":"f099v62c3noygwhsm70zq","execution_id":"ee44a1cc-529a-4306-85ce-46b2455a16fe","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 256, 256, 6)  0           input_1[0][0]                    \n                                                                 input_2[0][0]                    \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 128, 128, 64) 6208        concatenate[0][0]                \n__________________________________________________________________________________________________\nleaky_re_lu (LeakyReLU)         (None, 128, 128, 64) 0           conv2d[0][0]                     \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 64, 64, 128)  131200      leaky_re_lu[0][0]                \n__________________________________________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 128)  0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 64, 64, 128)  512         leaky_re_lu_1[0][0]              \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 32, 32, 256)  524544      batch_normalization[0][0]        \n__________________________________________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 256)  0           conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 32, 32, 256)  1024        leaky_re_lu_2[0][0]              \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 16, 16, 512)  2097664     batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 512)  0           conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 16, 16, 512)  2048        leaky_re_lu_3[0][0]              \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 16, 16, 1)    8193        batch_normalization_2[0][0]      \n==================================================================================================\nTotal params: 2,771,393\nTrainable params: 2,769,601\nNon-trainable params: 1,792\n__________________________________________________________________________________________________\nModel: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_5 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 128, 128, 64) 3136        input_5[0][0]                    \n__________________________________________________________________________________________________\nleaky_re_lu_8 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 64, 64, 128)  131200      leaky_re_lu_8[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_9 (LeakyReLU)       (None, 64, 64, 128)  0           conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 64, 64, 128)  512         leaky_re_lu_9[0][0]              \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 32, 32, 256)  524544      batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nleaky_re_lu_10 (LeakyReLU)      (None, 32, 32, 256)  0           conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        leaky_re_lu_10[0][0]             \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 16, 16, 512)  2097664     batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nleaky_re_lu_11 (LeakyReLU)      (None, 16, 16, 512)  0           conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 16, 16, 512)  2048        leaky_re_lu_11[0][0]             \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 8, 8, 512)    4194816     batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nleaky_re_lu_12 (LeakyReLU)      (None, 8, 8, 512)    0           conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 8, 8, 512)    2048        leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 4, 4, 1024)   8389632     batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nleaky_re_lu_13 (LeakyReLU)      (None, 4, 4, 1024)   0           conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 4, 4, 1024)   4096        leaky_re_lu_13[0][0]             \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 2, 2, 1024)   16778240    batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nleaky_re_lu_14 (LeakyReLU)      (None, 2, 2, 1024)   0           conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 2, 2, 1024)   4096        leaky_re_lu_14[0][0]             \n__________________________________________________________________________________________________\nup_sampling2d (UpSampling2D)    (None, 4, 4, 1024)   0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 4, 4, 512)    8389120     up_sampling2d[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 4, 4, 512)    2048        conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 4, 4, 1536)   0           batch_normalization_12[0][0]     \n                                                                 batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_1 (UpSampling2D)  (None, 8, 8, 1536)   0           concatenate_2[0][0]              \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 8, 8, 512)    12583424    up_sampling2d_1[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 8, 8, 512)    2048        conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 8, 8, 1024)   0           batch_normalization_13[0][0]     \n                                                                 batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nup_sampling2d_2 (UpSampling2D)  (None, 16, 16, 1024) 0           concatenate_3[0][0]              \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 16, 16, 512)  8389120     up_sampling2d_2[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 16, 16, 512)  2048        conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_4 (Concatenate)     (None, 16, 16, 1024) 0           batch_normalization_14[0][0]     \n                                                                 batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nup_sampling2d_3 (UpSampling2D)  (None, 32, 32, 1024) 0           concatenate_4[0][0]              \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 32, 32, 256)  4194560     up_sampling2d_3[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 32, 32, 256)  1024        conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_5 (Concatenate)     (None, 32, 32, 512)  0           batch_normalization_15[0][0]     \n                                                                 batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nup_sampling2d_4 (UpSampling2D)  (None, 64, 64, 512)  0           concatenate_5[0][0]              \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 64, 64, 128)  1048704     up_sampling2d_4[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 64, 64, 128)  512         conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_6 (Concatenate)     (None, 64, 64, 256)  0           batch_normalization_16[0][0]     \n                                                                 batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nup_sampling2d_5 (UpSampling2D)  (None, 128, 128, 256 0           concatenate_6[0][0]              \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 128, 128, 64) 262208      up_sampling2d_5[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 128, 128, 64) 256         conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_7 (Concatenate)     (None, 128, 128, 128 0           batch_normalization_17[0][0]     \n                                                                 leaky_re_lu_8[0][0]              \n__________________________________________________________________________________________________\nup_sampling2d_6 (UpSampling2D)  (None, 256, 256, 128 0           concatenate_7[0][0]              \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 256, 256, 3)  6147        up_sampling2d_6[0][0]            \n==================================================================================================\nTotal params: 67,014,275\nTrainable params: 67,003,395\nNon-trainable params: 10,880\n__________________________________________________________________________________________________\nWARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\nWARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\nWARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\nWARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n[Epoch 0/80000] [D loss_whole: 29.356922, acc:  49%] [D loss_mask: 61.568447, acc:  45%] [G loss: 195.644943] time: 0:00:31.648297\nINFO:tensorflow:Assets written to: saved_models/inpaint_net0/assets\n[Epoch 1/80000] [D loss_whole: 13.845313, acc:  43%] [D loss_mask: 6.824784, acc:  49%] [G loss: 143.474167] time: 0:00:53.120533\n[Epoch 2/80000] [D loss_whole: 3.217019, acc:  50%] [D loss_mask: 8.902453, acc:  48%] [G loss: 128.981293] time: 0:00:57.306546\n[Epoch 3/80000] [D loss_whole: 2.481916, acc:  50%] [D loss_mask: 3.185547, acc:  50%] [G loss: 116.908226] time: 0:01:01.465191\n[Epoch 4/80000] [D loss_whole: 1.346023, acc:  50%] [D loss_mask: 2.838844, acc:  57%] [G loss: 114.191605] time: 0:01:05.637631\n[Epoch 5/80000] [D loss_whole: 0.817765, acc:  50%] [D loss_mask: 1.889407, acc:  50%] [G loss: 101.916252] time: 0:01:09.899964\n[Epoch 6/80000] [D loss_whole: 0.701483, acc:  50%] [D loss_mask: 1.314965, acc:  50%] [G loss: 99.903534] time: 0:01:14.135156\n[Epoch 7/80000] [D loss_whole: 0.646230, acc:  50%] [D loss_mask: 1.172989, acc:  50%] [G loss: 97.082443] time: 0:01:18.364088\n[Epoch 8/80000] [D loss_whole: 0.577765, acc:  51%] [D loss_mask: 1.093417, acc:  50%] [G loss: 94.586136] time: 0:01:22.459804\n[Epoch 9/80000] [D loss_whole: 0.551447, acc:  50%] [D loss_mask: 1.049841, acc:  50%] [G loss: 87.084389] time: 0:01:26.532784\n[Epoch 10/80000] [D loss_whole: 0.535847, acc:  51%] [D loss_mask: 1.004950, acc:  50%] [G loss: 89.104774] time: 0:01:30.518597\n[Epoch 11/80000] [D loss_whole: 0.498812, acc:  52%] [D loss_mask: 0.982166, acc:  50%] [G loss: 81.050041] time: 0:01:34.611845\n[Epoch 12/80000] [D loss_whole: 0.486853, acc:  52%] [D loss_mask: 0.972259, acc:  50%] [G loss: 83.851280] time: 0:01:38.642202\n[Epoch 13/80000] [D loss_whole: 0.478929, acc:  51%] [D loss_mask: 0.946327, acc:  49%] [G loss: 84.870354] time: 0:01:42.723716\n[Epoch 14/80000] [D loss_whole: 0.461131, acc:  51%] [D loss_mask: 0.888184, acc:  49%] [G loss: 75.249725] time: 0:01:46.784481\n[Epoch 15/80000] [D loss_whole: 0.439123, acc:  50%] [D loss_mask: 0.882440, acc:  49%] [G loss: 81.338776] time: 0:01:50.653159\n[Epoch 16/80000] [D loss_whole: 0.433965, acc:  50%] [D loss_mask: 0.871332, acc:  48%] [G loss: 81.885078] time: 0:01:54.412168\n[Epoch 17/80000] [D loss_whole: 0.423166, acc:  49%] [D loss_mask: 0.858233, acc:  48%] [G loss: 74.923309] time: 0:01:58.630265\n[Epoch 18/80000] [D loss_whole: 0.434119, acc:  50%] [D loss_mask: 0.854710, acc:  48%] [G loss: 72.799637] time: 0:02:02.845095\n[Epoch 19/80000] [D loss_whole: 0.419062, acc:  50%] [D loss_mask: 0.828688, acc:  48%] [G loss: 71.175041] time: 0:02:07.015976\n[Epoch 20/80000] [D loss_whole: 0.406073, acc:  49%] [D loss_mask: 0.807199, acc:  49%] [G loss: 71.955894] time: 0:02:11.054076\n[Epoch 21/80000] [D loss_whole: 0.391508, acc:  50%] [D loss_mask: 0.870700, acc:  50%] [G loss: 69.808456] time: 0:02:14.960137\n[Epoch 22/80000] [D loss_whole: 0.391462, acc:  49%] [D loss_mask: 0.828187, acc:  49%] [G loss: 70.567169] time: 0:02:18.726283\n[Epoch 23/80000] [D loss_whole: 0.394857, acc:  49%] [D loss_mask: 0.884285, acc:  48%] [G loss: 68.501213] time: 0:02:22.823239\n[Epoch 24/80000] [D loss_whole: 0.389425, acc:  51%] [D loss_mask: 0.919940, acc:  50%] [G loss: 63.052952] time: 0:02:26.928055\n[Epoch 25/80000] [D loss_whole: 0.412193, acc:  49%] [D loss_mask: 1.099509, acc:  52%] [G loss: 64.914276] time: 0:02:31.008973\n[Epoch 26/80000] [D loss_whole: 0.390417, acc:  51%] [D loss_mask: 1.209504, acc:  55%] [G loss: 64.213928] time: 0:02:34.969202\n[Epoch 27/80000] [D loss_whole: 0.360482, acc:  50%] [D loss_mask: 1.117381, acc:  52%] [G loss: 62.216778] time: 0:02:38.943712\n[Epoch 28/80000] [D loss_whole: 0.434379, acc:  47%] [D loss_mask: 0.821791, acc:  52%] [G loss: 66.471611] time: 0:02:42.793278\n[Epoch 29/80000] [D loss_whole: 0.386095, acc:  48%] [D loss_mask: 0.784968, acc:  46%] [G loss: 61.794640] time: 0:02:46.741403\n[Epoch 30/80000] [D loss_whole: 0.488865, acc:  52%] [D loss_mask: 0.941291, acc:  44%] [G loss: 69.151772] time: 0:02:50.742010\n[Epoch 31/80000] [D loss_whole: 0.465032, acc:  51%] [D loss_mask: 1.155388, acc:  46%] [G loss: 64.690155] time: 0:02:54.866468\n[Epoch 32/80000] [D loss_whole: 0.366218, acc:  50%] [D loss_mask: 0.768660, acc:  50%] [G loss: 59.119678] time: 0:02:59.060200\n[Epoch 33/80000] [D loss_whole: 0.344307, acc:  50%] [D loss_mask: 0.702620, acc:  49%] [G loss: 71.486198] time: 0:03:03.175159\n[Epoch 34/80000] [D loss_whole: 0.350187, acc:  48%] [D loss_mask: 0.681632, acc:  48%] [G loss: 62.872063] time: 0:03:07.207820\n[Epoch 35/80000] [D loss_whole: 0.350504, acc:  49%] [D loss_mask: 0.689453, acc:  48%] [G loss: 62.915024] time: 0:03:11.165292\n[Epoch 36/80000] [D loss_whole: 0.459409, acc:  47%] [D loss_mask: 0.712525, acc:  47%] [G loss: 59.521126] time: 0:03:15.262269\n[Epoch 37/80000] [D loss_whole: 0.502020, acc:  49%] [D loss_mask: 0.738436, acc:  46%] [G loss: 60.944401] time: 0:03:19.417234\n[Epoch 38/80000] [D loss_whole: 0.345034, acc:  49%] [D loss_mask: 0.703359, acc:  47%] [G loss: 56.628937] time: 0:03:23.510543\n[Epoch 39/80000] [D loss_whole: 0.357369, acc:  51%] [D loss_mask: 0.681003, acc:  51%] [G loss: 61.756954] time: 0:03:27.633998\n[Epoch 40/80000] [D loss_whole: 0.331354, acc:  49%] [D loss_mask: 0.691139, acc:  46%] [G loss: 53.225479] time: 0:03:31.590006\n[Epoch 41/80000] [D loss_whole: 0.346806, acc:  48%] [D loss_mask: 0.757763, acc:  45%] [G loss: 60.423409] time: 0:03:35.628119\n[Epoch 42/80000] [D loss_whole: 0.328928, acc:  49%] [D loss_mask: 0.685272, acc:  46%] [G loss: 63.651588] time: 0:03:39.391640\n[Epoch 43/80000] [D loss_whole: 0.338149, acc:  49%] [D loss_mask: 0.648344, acc:  48%] [G loss: 68.478104] time: 0:03:43.392634\n[Epoch 44/80000] [D loss_whole: 0.435134, acc:  49%] [D loss_mask: 0.639022, acc:  50%] [G loss: 57.400440] time: 0:03:47.220249\n[Epoch 45/80000] [D loss_whole: 0.370442, acc:  52%] [D loss_mask: 0.643268, acc:  48%] [G loss: 56.309452] time: 0:03:51.094477\n[Epoch 46/80000] [D loss_whole: 0.361636, acc:  48%] [D loss_mask: 0.657821, acc:  47%] [G loss: 56.849701] time: 0:03:55.012267\n[Epoch 47/80000] [D loss_whole: 0.398787, acc:  50%] [D loss_mask: 0.636371, acc:  49%] [G loss: 63.205231] time: 0:03:59.069601\n[Epoch 48/80000] [D loss_whole: 0.502078, acc:  49%] [D loss_mask: 0.701528, acc:  46%] [G loss: 59.081196] time: 0:04:02.948664\n[Epoch 49/80000] [D loss_whole: 0.334215, acc:  50%] [D loss_mask: 0.665142, acc:  47%] [G loss: 62.953629] time: 0:04:06.846819\n[Epoch 50/80000] [D loss_whole: 0.355945, acc:  48%] [D loss_mask: 0.644182, acc:  47%] [G loss: 55.791203] time: 0:04:10.706304\n[Epoch 51/80000] [D loss_whole: 0.319191, acc:  50%] [D loss_mask: 0.636092, acc:  49%] [G loss: 57.563786] time: 0:04:14.808601\n[Epoch 52/80000] [D loss_whole: 0.315297, acc:  49%] [D loss_mask: 0.642324, acc:  48%] [G loss: 61.106941] time: 0:04:18.626682\n[Epoch 53/80000] [D loss_whole: 0.310951, acc:  48%] [D loss_mask: 0.632259, acc:  48%] [G loss: 59.251213] time: 0:04:22.554408\n[Epoch 54/80000] [D loss_whole: 0.298800, acc:  52%] [D loss_mask: 0.601254, acc:  51%] [G loss: 62.436554] time: 0:04:26.388980\n[Epoch 55/80000] [D loss_whole: 0.332743, acc:  48%] [D loss_mask: 0.721677, acc:  47%] [G loss: 54.336189] time: 0:04:30.242392\n[Epoch 56/80000] [D loss_whole: 0.330776, acc:  48%] [D loss_mask: 0.817331, acc:  49%] [G loss: 65.369942] time: 0:04:34.185038\n[Epoch 57/80000] [D loss_whole: 0.411949, acc:  49%] [D loss_mask: 1.044389, acc:  54%] [G loss: 53.231056] time: 0:04:38.197415\n[Epoch 58/80000] [D loss_whole: 0.383716, acc:  52%] [D loss_mask: 0.689460, acc:  48%] [G loss: 63.095093] time: 0:04:42.204233\n[Epoch 59/80000] [D loss_whole: 0.311007, acc:  50%] [D loss_mask: 0.883691, acc:  42%] [G loss: 57.310944] time: 0:04:46.222993\n[Epoch 60/80000] [D loss_whole: 0.302684, acc:  49%] [D loss_mask: 0.928529, acc:  39%] [G loss: 57.263611] time: 0:04:50.170341\n[Epoch 61/80000] [D loss_whole: 0.302858, acc:  51%] [D loss_mask: 0.952572, acc:  49%] [G loss: 54.026806] time: 0:04:54.172060\n[Epoch 62/80000] [D loss_whole: 0.302372, acc:  50%] [D loss_mask: 1.054825, acc:  42%] [G loss: 51.250450] time: 0:04:58.031452\n[Epoch 63/80000] [D loss_whole: 0.297678, acc:  50%] [D loss_mask: 0.830311, acc:  48%] [G loss: 54.113125] time: 0:05:02.050348\n[Epoch 64/80000] [D loss_whole: 0.296975, acc:  49%] [D loss_mask: 0.635948, acc:  50%] [G loss: 51.835701] time: 0:05:05.837017\n[Epoch 65/80000] [D loss_whole: 0.298875, acc:  49%] [D loss_mask: 0.644725, acc:  48%] [G loss: 52.203983] time: 0:05:09.805518\n[Epoch 66/80000] [D loss_whole: 0.297581, acc:  49%] [D loss_mask: 0.628381, acc:  49%] [G loss: 50.351803] time: 0:05:13.566959\n[Epoch 67/80000] [D loss_whole: 0.298700, acc:  50%] [D loss_mask: 0.604926, acc:  49%] [G loss: 52.069801] time: 0:05:17.345750\n[Epoch 68/80000] [D loss_whole: 0.293488, acc:  50%] [D loss_mask: 0.609198, acc:  48%] [G loss: 52.564693] time: 0:05:20.987976\n[Epoch 69/80000] [D loss_whole: 0.297190, acc:  49%] [D loss_mask: 0.610575, acc:  48%] [G loss: 52.481003] time: 0:05:25.031767\n[Epoch 70/80000] [D loss_whole: 0.294933, acc:  50%] [D loss_mask: 0.718665, acc:  51%] [G loss: 51.762943] time: 0:05:28.996363\n[Epoch 71/80000] [D loss_whole: 0.295390, acc:  50%] [D loss_mask: 0.887142, acc:  50%] [G loss: 58.079407] time: 0:05:32.992139\n[Epoch 72/80000] [D loss_whole: 0.293803, acc:  50%] [D loss_mask: 0.677380, acc:  49%] [G loss: 52.023941] time: 0:05:36.818021\n[Epoch 73/80000] [D loss_whole: 0.294024, acc:  49%] [D loss_mask: 0.593334, acc:  48%] [G loss: 52.111485] time: 0:05:40.710617\n[Epoch 74/80000] [D loss_whole: 0.301844, acc:  50%] [D loss_mask: 0.616018, acc:  49%] [G loss: 48.671120] time: 0:05:44.524410\n[Epoch 75/80000] [D loss_whole: 0.310924, acc:  49%] [D loss_mask: 0.635552, acc:  49%] [G loss: 47.803238] time: 0:05:48.427273\n[Epoch 76/80000] [D loss_whole: 0.315128, acc:  49%] [D loss_mask: 0.598794, acc:  50%] [G loss: 51.392517] time: 0:05:52.151671\n[Epoch 77/80000] [D loss_whole: 0.309465, acc:  50%] [D loss_mask: 0.594450, acc:  49%] [G loss: 53.289509] time: 0:05:56.170650\n[Epoch 78/80000] [D loss_whole: 0.319120, acc:  48%] [D loss_mask: 0.590694, acc:  49%] [G loss: 53.341213] time: 0:05:59.960162\n[Epoch 79/80000] [D loss_whole: 0.321372, acc:  49%] [D loss_mask: 0.575831, acc:  48%] [G loss: 50.118217] time: 0:06:03.942501\n[Epoch 80/80000] [D loss_whole: 0.326348, acc:  46%] [D loss_mask: 0.633474, acc:  46%] [G loss: 57.921341] time: 0:06:07.706323\n[Epoch 81/80000] [D loss_whole: 0.300519, acc:  49%] [D loss_mask: 0.624336, acc:  45%] [G loss: 54.590313] time: 0:06:11.438925\n[Epoch 82/80000] [D loss_whole: 0.286557, acc:  53%] [D loss_mask: 0.554750, acc:  51%] [G loss: 54.575527] time: 0:06:14.918203\n[Epoch 83/80000] [D loss_whole: 0.293091, acc:  49%] [D loss_mask: 0.623285, acc:  47%] [G loss: 49.282784] time: 0:06:18.922206\n[Epoch 84/80000] [D loss_whole: 0.312999, acc:  48%] [D loss_mask: 0.620500, acc:  47%] [G loss: 51.666073] time: 0:06:22.888189\n[Epoch 85/80000] [D loss_whole: 0.385844, acc:  51%] [D loss_mask: 0.616198, acc:  48%] [G loss: 49.895851] time: 0:06:26.785323\n[Epoch 86/80000] [D loss_whole: 0.419919, acc:  51%] [D loss_mask: 0.572230, acc:  49%] [G loss: 47.178787] time: 0:06:30.630209\n[Epoch 87/80000] [D loss_whole: 0.533597, acc:  50%] [D loss_mask: 0.571328, acc:  48%] [G loss: 48.053379] time: 0:06:34.582235\n[Epoch 88/80000] [D loss_whole: 0.479827, acc:  51%] [D loss_mask: 0.579541, acc:  48%] [G loss: 49.516331] time: 0:06:38.341349\n[Epoch 89/80000] [D loss_whole: 0.311656, acc:  49%] [D loss_mask: 0.590235, acc:  48%] [G loss: 47.484592] time: 0:06:42.234973\n[Epoch 90/80000] [D loss_whole: 0.306735, acc:  49%] [D loss_mask: 0.613057, acc:  50%] [G loss: 49.381134] time: 0:06:46.073308\n[Epoch 91/80000] [D loss_whole: 0.315066, acc:  48%] [D loss_mask: 0.665544, acc:  49%] [G loss: 49.030720] time: 0:06:49.985807\n[Epoch 92/80000] [D loss_whole: 0.289800, acc:  50%] [D loss_mask: 0.702487, acc:  49%] [G loss: 47.739052] time: 0:06:53.813926\n[Epoch 93/80000] [D loss_whole: 0.288719, acc:  50%] [D loss_mask: 0.693706, acc:  49%] [G loss: 49.859814] time: 0:06:57.694008\n[Epoch 94/80000] [D loss_whole: 0.291680, acc:  49%] [D loss_mask: 0.685473, acc:  49%] [G loss: 52.748653] time: 0:07:01.422654\n[Epoch 95/80000] [D loss_whole: 0.318703, acc:  47%] [D loss_mask: 0.706591, acc:  48%] [G loss: 48.327728] time: 0:07:05.286027\n[Epoch 96/80000] [D loss_whole: 0.348008, acc:  48%] [D loss_mask: 0.687362, acc:  49%] [G loss: 48.319553] time: 0:07:09.210400\n[Epoch 97/80000] [D loss_whole: 0.329436, acc:  51%] [D loss_mask: 0.619575, acc:  51%] [G loss: 48.428085] time: 0:07:13.107070\n[Epoch 98/80000] [D loss_whole: 0.284475, acc:  51%] [D loss_mask: 0.581622, acc:  51%] [G loss: 47.584564] time: 0:07:17.107362\n[Epoch 99/80000] [D loss_whole: 0.316877, acc:  47%] [D loss_mask: 0.580799, acc:  47%] [G loss: 48.678909] time: 0:07:21.009210\n[Epoch 100/80000] [D loss_whole: 0.318832, acc:  50%] [D loss_mask: 0.586075, acc:  44%] [G loss: 49.071167] time: 0:07:24.756683\nINFO:tensorflow:Assets written to: saved_models/inpaint_net100/assets\n[Epoch 101/80000] [D loss_whole: 0.281047, acc:  49%] [D loss_mask: 0.584627, acc:  44%] [G loss: 46.310631] time: 0:07:41.687892\n[Epoch 102/80000] [D loss_whole: 0.280553, acc:  48%] [D loss_mask: 0.574004, acc:  47%] [G loss: 46.969112] time: 0:07:44.964407\n[Epoch 103/80000] [D loss_whole: 0.285061, acc:  49%] [D loss_mask: 0.577936, acc:  46%] [G loss: 51.258057] time: 0:07:48.665749\n[Epoch 104/80000] [D loss_whole: 0.294672, acc:  50%] [D loss_mask: 0.597878, acc:  46%] [G loss: 50.353092] time: 0:07:52.134624\n[Epoch 105/80000] [D loss_whole: 0.283147, acc:  48%] [D loss_mask: 0.637907, acc:  41%] [G loss: 46.441483] time: 0:07:55.408456\n[Epoch 106/80000] [D loss_whole: 0.280096, acc:  50%] [D loss_mask: 0.601740, acc:  47%] [G loss: 47.459309] time: 0:07:58.957622\n[Epoch 107/80000] [D loss_whole: 0.300663, acc:  47%] [D loss_mask: 0.570336, acc:  47%] [G loss: 44.191353] time: 0:08:02.838838\n[Epoch 108/80000] [D loss_whole: 0.324035, acc:  47%] [D loss_mask: 0.570706, acc:  46%] [G loss: 48.099457] time: 0:08:06.327009\n[Epoch 109/80000] [D loss_whole: 0.292357, acc:  52%] [D loss_mask: 0.534673, acc:  51%] [G loss: 52.845699] time: 0:08:09.713736\n[Epoch 110/80000] [D loss_whole: 0.272174, acc:  51%] [D loss_mask: 0.540803, acc:  49%] [G loss: 49.082066] time: 0:08:13.379929\n[Epoch 111/80000] [D loss_whole: 0.441994, acc:  48%] [D loss_mask: 0.668560, acc:  47%] [G loss: 51.386173] time: 0:08:16.814644\n[Epoch 112/80000] [D loss_whole: 0.431065, acc:  54%] [D loss_mask: 0.688086, acc:  51%] [G loss: 47.159222] time: 0:08:20.249055\n[Epoch 113/80000] [D loss_whole: 0.330556, acc:  46%] [D loss_mask: 0.653525, acc:  44%] [G loss: 53.293293] time: 0:08:23.856030\n[Epoch 114/80000] [D loss_whole: 0.357598, acc:  48%] [D loss_mask: 0.595796, acc:  49%] [G loss: 47.757160] time: 0:08:27.727530\n[Epoch 115/80000] [D loss_whole: 0.612218, acc:  45%] [D loss_mask: 0.780910, acc:  54%] [G loss: 50.960365] time: 0:08:31.256807\n[Epoch 116/80000] [D loss_whole: 0.568259, acc:  48%] [D loss_mask: 0.826382, acc:  46%] [G loss: 49.255646] time: 0:08:34.635789\n[Epoch 117/80000] [D loss_whole: 0.357492, acc:  51%] [D loss_mask: 0.925266, acc:  53%] [G loss: 46.950912] time: 0:08:38.318024\n[Epoch 118/80000] [D loss_whole: 0.276576, acc:  49%] [D loss_mask: 1.025073, acc:  54%] [G loss: 46.796879] time: 0:08:41.682585\n[Epoch 119/80000] [D loss_whole: 0.288500, acc:  48%] [D loss_mask: 0.879259, acc:  46%] [G loss: 46.209930] time: 0:08:45.041413\n[Epoch 120/80000] [D loss_whole: 0.276454, acc:  48%] [D loss_mask: 0.643593, acc:  50%] [G loss: 49.255222] time: 0:08:48.627987\n[Epoch 121/80000] [D loss_whole: 0.280997, acc:  49%] [D loss_mask: 0.581420, acc:  50%] [G loss: 46.009304] time: 0:08:52.451259\n[Epoch 122/80000] [D loss_whole: 0.276936, acc:  50%] [D loss_mask: 0.576362, acc:  47%] [G loss: 50.834442] time: 0:08:55.918689\n[Epoch 123/80000] [D loss_whole: 0.277300, acc:  51%] [D loss_mask: 0.553717, acc:  48%] [G loss: 48.042374] time: 0:08:59.348293\n[Epoch 124/80000] [D loss_whole: 0.269565, acc:  51%] [D loss_mask: 0.578292, acc:  45%] [G loss: 46.276398] time: 0:09:02.928219\n[Epoch 125/80000] [D loss_whole: 0.288050, acc:  47%] [D loss_mask: 0.740494, acc:  45%] [G loss: 47.670021] time: 0:09:06.363217\n[Epoch 126/80000] [D loss_whole: 0.279566, acc:  49%] [D loss_mask: 0.676381, acc:  45%] [G loss: 46.994972] time: 0:09:09.682193\n[Epoch 127/80000] [D loss_whole: 0.275913, acc:  48%] [D loss_mask: 0.596023, acc:  45%] [G loss: 50.618671] time: 0:09:13.261746\n[Epoch 128/80000] [D loss_whole: 0.268536, acc:  53%] [D loss_mask: 0.532942, acc:  50%] [G loss: 47.734924] time: 0:09:17.063696\n[Epoch 129/80000] [D loss_whole: 0.284846, acc:  48%] [D loss_mask: 0.560662, acc:  45%] [G loss: 44.837807] time: 0:09:20.508662\n[Epoch 130/80000] [D loss_whole: 0.288255, acc:  49%] [D loss_mask: 0.568886, acc:  48%] [G loss: 42.628342] time: 0:09:23.840850\n[Epoch 131/80000] [D loss_whole: 0.276320, acc:  48%] [D loss_mask: 0.569615, acc:  49%] [G loss: 48.342583] time: 0:09:27.555130\n[Epoch 132/80000] [D loss_whole: 0.290551, acc:  48%] [D loss_mask: 0.559637, acc:  48%] [G loss: 48.986698] time: 0:09:31.037927\n[Epoch 133/80000] [D loss_whole: 0.310903, acc:  45%] [D loss_mask: 0.565744, acc:  50%] [G loss: 45.248878] time: 0:09:34.258896\n[Epoch 134/80000] [D loss_whole: 0.283044, acc:  51%] [D loss_mask: 0.527507, acc:  51%] [G loss: 50.210670] time: 0:09:37.894130\n[Epoch 135/80000] [D loss_whole: 0.273463, acc:  48%] [D loss_mask: 0.549328, acc:  47%] [G loss: 45.469528] time: 0:09:41.678996\n[Epoch 136/80000] [D loss_whole: 0.292241, acc:  49%] [D loss_mask: 0.568758, acc:  43%] [G loss: 48.450020] time: 0:09:45.155975\n[Epoch 137/80000] [D loss_whole: 0.272933, acc:  49%] [D loss_mask: 0.553069, acc:  45%] [G loss: 43.318722] time: 0:09:48.440622\n[Epoch 138/80000] [D loss_whole: 0.278549, acc:  49%] [D loss_mask: 0.542232, acc:  48%] [G loss: 40.786308] time: 0:09:52.124684\n[Epoch 139/80000] [D loss_whole: 0.285012, acc:  50%] [D loss_mask: 0.542180, acc:  50%] [G loss: 42.626991] time: 0:09:55.523386\n[Epoch 140/80000] [D loss_whole: 0.267359, acc:  52%] [D loss_mask: 0.543682, acc:  50%] [G loss: 44.494709] time: 0:09:58.825588\n[Epoch 141/80000] [D loss_whole: 0.278909, acc:  49%] [D loss_mask: 0.560242, acc:  48%] [G loss: 49.989441] time: 0:10:02.409820\n[Epoch 142/80000] [D loss_whole: 0.271164, acc:  49%] [D loss_mask: 0.549464, acc:  51%] [G loss: 46.464443] time: 0:10:06.228347\n[Epoch 143/80000] [D loss_whole: 0.281716, acc:  50%] [D loss_mask: 0.552356, acc:  45%] [G loss: 48.703091] time: 0:10:09.690614\n[Epoch 144/80000] [D loss_whole: 0.280943, acc:  49%] [D loss_mask: 0.543533, acc:  47%] [G loss: 42.481144] time: 0:10:12.980308\n[Epoch 145/80000] [D loss_whole: 0.283776, acc:  50%] [D loss_mask: 0.539692, acc:  48%] [G loss: 41.833725] time: 0:10:16.594307\n[Epoch 146/80000] [D loss_whole: 0.292227, acc:  51%] [D loss_mask: 0.550761, acc:  45%] [G loss: 49.043316] time: 0:10:19.984647\n[Epoch 147/80000] [D loss_whole: 0.287481, acc:  51%] [D loss_mask: 0.555844, acc:  45%] [G loss: 46.744347] time: 0:10:23.294893\n[Epoch 148/80000] [D loss_whole: 0.261992, acc:  51%] [D loss_mask: 0.519341, acc:  54%] [G loss: 45.215763] time: 0:10:26.841746\n[Epoch 149/80000] [D loss_whole: 0.310878, acc:  52%] [D loss_mask: 0.549194, acc:  51%] [G loss: 45.036274] time: 0:10:30.776665\n[Epoch 150/80000] [D loss_whole: 0.400727, acc:  52%] [D loss_mask: 0.554667, acc:  50%] [G loss: 44.983253] time: 0:10:34.212726\n[Epoch 151/80000] [D loss_whole: 0.349523, acc:  53%] [D loss_mask: 0.548791, acc:  49%] [G loss: 41.179718] time: 0:10:37.483572\n[Epoch 152/80000] [D loss_whole: 0.280426, acc:  50%] [D loss_mask: 0.632873, acc:  48%] [G loss: 41.044250] time: 0:10:41.103346\n[Epoch 153/80000] [D loss_whole: 0.291501, acc:  48%] [D loss_mask: 0.750799, acc:  50%] [G loss: 49.886673] time: 0:10:44.466379\n[Epoch 154/80000] [D loss_whole: 0.352746, acc:  49%] [D loss_mask: 0.774209, acc:  49%] [G loss: 44.572906] time: 0:10:47.776549\n[Epoch 155/80000] [D loss_whole: 0.425615, acc:  47%] [D loss_mask: 0.920915, acc:  48%] [G loss: 48.447411] time: 0:10:51.439012\n[Epoch 156/80000] [D loss_whole: 0.443611, acc:  43%] [D loss_mask: 1.064796, acc:  46%] [G loss: 43.643070] time: 0:10:55.174367\n[Epoch 157/80000] [D loss_whole: 0.395931, acc:  48%] [D loss_mask: 0.845343, acc:  50%] [G loss: 56.519215] time: 0:10:58.621572\n[Epoch 158/80000] [D loss_whole: 0.369247, acc:  50%] [D loss_mask: 0.626657, acc:  53%] [G loss: 43.516617] time: 0:11:01.927691\n[Epoch 159/80000] [D loss_whole: 0.280811, acc:  53%] [D loss_mask: 0.592729, acc:  57%] [G loss: 45.857922] time: 0:11:05.548461\n[Epoch 160/80000] [D loss_whole: 0.296050, acc:  48%] [D loss_mask: 0.576377, acc:  47%] [G loss: 46.337498] time: 0:11:08.924525\n[Epoch 161/80000] [D loss_whole: 0.273378, acc:  50%] [D loss_mask: 0.552130, acc:  47%] [G loss: 41.270840] time: 0:11:12.313500\n[Epoch 162/80000] [D loss_whole: 0.282178, acc:  49%] [D loss_mask: 0.550989, acc:  47%] [G loss: 43.475567] time: 0:11:15.921953\n[Epoch 163/80000] [D loss_whole: 0.341716, acc:  45%] [D loss_mask: 0.563957, acc:  46%] [G loss: 45.751053] time: 0:11:19.688294\n[Epoch 164/80000] [D loss_whole: 0.375553, acc:  47%] [D loss_mask: 0.568668, acc:  49%] [G loss: 42.751846] time: 0:11:23.137846\n[Epoch 165/80000] [D loss_whole: 0.343288, acc:  45%] [D loss_mask: 0.537822, acc:  51%] [G loss: 42.566582] time: 0:11:26.414140\n[Epoch 166/80000] [D loss_whole: 0.279789, acc:  50%] [D loss_mask: 0.557208, acc:  43%] [G loss: 47.118141] time: 0:11:29.991236\n[Epoch 167/80000] [D loss_whole: 0.262959, acc:  53%] [D loss_mask: 0.539615, acc:  46%] [G loss: 41.796581] time: 0:11:33.320160\n[Epoch 168/80000] [D loss_whole: 0.280973, acc:  48%] [D loss_mask: 0.621019, acc:  43%] [G loss: 42.605427] time: 0:11:36.605704\n[Epoch 169/80000] [D loss_whole: 0.270441, acc:  50%] [D loss_mask: 0.648890, acc:  46%] [G loss: 43.684147] time: 0:11:40.129660\n[Epoch 170/80000] [D loss_whole: 0.283864, acc:  49%] [D loss_mask: 0.595202, acc:  47%] [G loss: 41.894775] time: 0:11:43.876802\n[Epoch 171/80000] [D loss_whole: 0.361598, acc:  45%] [D loss_mask: 0.557035, acc:  48%] [G loss: 42.202477] time: 0:11:47.196090\n[Epoch 172/80000] [D loss_whole: 0.426519, acc:  46%] [D loss_mask: 0.565167, acc:  49%] [G loss: 46.293949] time: 0:11:50.485715\n[Epoch 173/80000] [D loss_whole: 0.407598, acc:  47%] [D loss_mask: 0.548680, acc:  51%] [G loss: 43.922390] time: 0:11:54.004781\n[Epoch 174/80000] [D loss_whole: 0.285729, acc:  52%] [D loss_mask: 0.532528, acc:  49%] [G loss: 42.784168] time: 0:11:57.371425\n[Epoch 175/80000] [D loss_whole: 0.354512, acc:  48%] [D loss_mask: 0.730787, acc:  46%] [G loss: 44.664841] time: 0:12:00.654117\n[Epoch 176/80000] [D loss_whole: 0.282943, acc:  52%] [D loss_mask: 0.662887, acc:  48%] [G loss: 42.762959] time: 0:12:04.147387\n[Epoch 177/80000] [D loss_whole: 0.311437, acc:  49%] [D loss_mask: 0.557611, acc:  45%] [G loss: 44.139221] time: 0:12:07.990966\n[Epoch 178/80000] [D loss_whole: 0.306951, acc:  48%] [D loss_mask: 0.542143, acc:  47%] [G loss: 41.662151] time: 0:12:11.381838\n[Epoch 179/80000] [D loss_whole: 0.294474, acc:  46%] [D loss_mask: 0.549732, acc:  46%] [G loss: 44.533134] time: 0:12:14.639079\n[Epoch 180/80000] [D loss_whole: 0.275941, acc:  52%] [D loss_mask: 0.523913, acc:  51%] [G loss: 44.172188] time: 0:12:18.259131\n[Epoch 181/80000] [D loss_whole: 0.302022, acc:  49%] [D loss_mask: 0.583160, acc:  47%] [G loss: 43.178310] time: 0:12:21.587905\n[Epoch 182/80000] [D loss_whole: 0.392213, acc:  53%] [D loss_mask: 0.702864, acc:  46%] [G loss: 40.663456] time: 0:12:24.867104\n[Epoch 183/80000] [D loss_whole: 0.342774, acc:  53%] [D loss_mask: 0.671153, acc:  46%] [G loss: 42.433887] time: 0:12:28.342359\n[Epoch 184/80000] [D loss_whole: 0.281879, acc:  49%] [D loss_mask: 0.619898, acc:  44%] [G loss: 45.597679] time: 0:12:32.131411\n[Epoch 185/80000] [D loss_whole: 0.276221, acc:  50%] [D loss_mask: 0.563887, acc:  46%] [G loss: 41.637695] time: 0:12:35.439562\n[Epoch 186/80000] [D loss_whole: 0.290472, acc:  49%] [D loss_mask: 0.543729, acc:  47%] [G loss: 40.638466] time: 0:12:38.764507\n[Epoch 187/80000] [D loss_whole: 0.291254, acc:  48%] [D loss_mask: 0.554779, acc:  48%] [G loss: 41.854507] time: 0:12:42.341207\n[Epoch 188/80000] [D loss_whole: 0.277176, acc:  49%] [D loss_mask: 0.571266, acc:  47%] [G loss: 49.487736] time: 0:12:45.647986\n[Epoch 189/80000] [D loss_whole: 0.279075, acc:  50%] [D loss_mask: 0.581042, acc:  50%] [G loss: 40.928383] time: 0:12:48.872424\n[Epoch 190/80000] [D loss_whole: 0.262685, acc:  50%] [D loss_mask: 0.579678, acc:  55%] [G loss: 44.686863] time: 0:12:52.350073\n[Epoch 191/80000] [D loss_whole: 0.299624, acc:  50%] [D loss_mask: 0.564164, acc:  47%] [G loss: 43.647663] time: 0:12:56.108632\n[Epoch 192/80000] [D loss_whole: 0.274267, acc:  51%] [D loss_mask: 0.566886, acc:  50%] [G loss: 46.282917] time: 0:12:59.431932\n[Epoch 193/80000] [D loss_whole: 0.321921, acc:  47%] [D loss_mask: 0.596827, acc:  46%] [G loss: 37.720356] time: 0:13:02.698404\n[Epoch 194/80000] [D loss_whole: 0.340196, acc:  46%] [D loss_mask: 0.595565, acc:  47%] [G loss: 38.161671] time: 0:13:06.234426\n[Epoch 195/80000] [D loss_whole: 0.310236, acc:  46%] [D loss_mask: 0.593861, acc:  47%] [G loss: 40.623234] time: 0:13:09.603219\n[Epoch 196/80000] [D loss_whole: 0.282682, acc:  48%] [D loss_mask: 0.592533, acc:  48%] [G loss: 42.037178] time: 0:13:12.847096\n[Epoch 197/80000] [D loss_whole: 0.265839, acc:  51%] [D loss_mask: 0.557335, acc:  49%] [G loss: 43.089127] time: 0:13:16.348517\n[Epoch 198/80000] [D loss_whole: 0.266688, acc:  50%] [D loss_mask: 0.554822, acc:  48%] [G loss: 41.009232] time: 0:13:20.125488\n[Epoch 199/80000] [D loss_whole: 0.269133, acc:  49%] [D loss_mask: 0.568196, acc:  47%] [G loss: 39.262070] time: 0:13:23.476121\n[Epoch 200/80000] [D loss_whole: 0.279165, acc:  49%] [D loss_mask: 0.547500, acc:  51%] [G loss: 38.763309] time: 0:13:26.705443\nINFO:tensorflow:Assets written to: saved_models/inpaint_net200/assets\n[Epoch 201/80000] [D loss_whole: 0.276506, acc:  49%] [D loss_mask: 0.540786, acc:  48%] [G loss: 44.240051] time: 0:13:43.799570\n[Epoch 202/80000] [D loss_whole: 0.495559, acc:  51%] [D loss_mask: 0.765936, acc:  47%] [G loss: 44.967468] time: 0:13:47.552407\n[Epoch 203/80000] [D loss_whole: 0.891841, acc:  53%] [D loss_mask: 1.707919, acc:  49%] [G loss: 43.119583] time: 0:13:51.303248\n[Epoch 204/80000] [D loss_whole: 0.838169, acc:  52%] [D loss_mask: 2.646604, acc:  48%] [G loss: 40.403225] time: 0:13:55.034073\n[Epoch 205/80000] [D loss_whole: 0.348071, acc:  51%] [D loss_mask: 1.467701, acc:  47%] [G loss: 42.734333] time: 0:13:58.827279\n[Epoch 206/80000] [D loss_whole: 0.298875, acc:  47%] [D loss_mask: 0.619171, acc:  48%] [G loss: 39.336166] time: 0:14:02.645215\n[Epoch 207/80000] [D loss_whole: 0.308603, acc:  47%] [D loss_mask: 0.623560, acc:  48%] [G loss: 41.571304] time: 0:14:06.456149\n[Epoch 208/80000] [D loss_whole: 0.271675, acc:  51%] [D loss_mask: 0.543962, acc:  48%] [G loss: 38.799824] time: 0:14:10.246947\n[Epoch 209/80000] [D loss_whole: 0.271477, acc:  50%] [D loss_mask: 0.566477, acc:  46%] [G loss: 40.587227] time: 0:14:14.096268\n[Epoch 210/80000] [D loss_whole: 0.276955, acc:  48%] [D loss_mask: 0.549701, acc:  50%] [G loss: 43.266060] time: 0:14:17.959750\n[Epoch 211/80000] [D loss_whole: 0.266258, acc:  50%] [D loss_mask: 0.555415, acc:  49%] [G loss: 38.499554] time: 0:14:21.731402\n[Epoch 212/80000] [D loss_whole: 0.265497, acc:  50%] [D loss_mask: 0.548725, acc:  50%] [G loss: 39.310513] time: 0:14:25.539970\n[Epoch 213/80000] [D loss_whole: 0.272080, acc:  50%] [D loss_mask: 0.559288, acc:  48%] [G loss: 41.677277] time: 0:14:29.344500\n[Epoch 214/80000] [D loss_whole: 0.278968, acc:  47%] [D loss_mask: 0.551642, acc:  48%] [G loss: 42.430161] time: 0:14:33.153115\n[Epoch 215/80000] [D loss_whole: 0.271140, acc:  51%] [D loss_mask: 0.536273, acc:  51%] [G loss: 45.820118] time: 0:14:36.966979\n[Epoch 216/80000] [D loss_whole: 0.262841, acc:  52%] [D loss_mask: 0.535534, acc:  50%] [G loss: 39.446846] time: 0:14:40.794131\n[Epoch 217/80000] [D loss_whole: 0.264538, acc:  50%] [D loss_mask: 0.536170, acc:  49%] [G loss: 40.266811] time: 0:14:44.595097\n[Epoch 218/80000] [D loss_whole: 0.280501, acc:  47%] [D loss_mask: 0.543218, acc:  48%] [G loss: 42.408787] time: 0:14:48.455876\n[Epoch 219/80000] [D loss_whole: 0.276619, acc:  51%] [D loss_mask: 0.516631, acc:  55%] [G loss: 42.351379] time: 0:14:52.316433\n[Epoch 220/80000] [D loss_whole: 0.253198, acc:  53%] [D loss_mask: 0.516012, acc:  56%] [G loss: 42.558666] time: 0:14:56.180887\n[Epoch 221/80000] [D loss_whole: 0.315361, acc:  52%] [D loss_mask: 0.548329, acc:  47%] [G loss: 49.716927] time: 0:15:00.012565\n[Epoch 222/80000] [D loss_whole: 0.275867, acc:  52%] [D loss_mask: 0.542215, acc:  51%] [G loss: 42.379997] time: 0:15:03.734704\n[Epoch 223/80000] [D loss_whole: 0.263962, acc:  50%] [D loss_mask: 0.524735, acc:  49%] [G loss: 39.815269] time: 0:15:07.468209\n[Epoch 224/80000] [D loss_whole: 0.277122, acc:  50%] [D loss_mask: 0.535475, acc:  52%] [G loss: 41.276054] time: 0:15:11.251129\n[Epoch 225/80000] [D loss_whole: 0.286212, acc:  52%] [D loss_mask: 0.547180, acc:  51%] [G loss: 38.136250] time: 0:15:15.043489\n[Epoch 226/80000] [D loss_whole: 0.281123, acc:  49%] [D loss_mask: 0.552113, acc:  49%] [G loss: 37.967529] time: 0:15:18.773682\n[Epoch 227/80000] [D loss_whole: 0.276869, acc:  51%] [D loss_mask: 0.538052, acc:  52%] [G loss: 40.252041] time: 0:15:22.560767\n[Epoch 228/80000] [D loss_whole: 0.262185, acc:  52%] [D loss_mask: 0.529010, acc:  48%] [G loss: 41.875984] time: 0:15:26.337925\n[Epoch 229/80000] [D loss_whole: 0.264922, acc:  51%] [D loss_mask: 0.526160, acc:  49%] [G loss: 43.950005] time: 0:15:30.091405\n[Epoch 230/80000] [D loss_whole: 0.264531, acc:  50%] [D loss_mask: 0.547269, acc:  45%] [G loss: 41.857906] time: 0:15:33.908212\n[Epoch 231/80000] [D loss_whole: 0.264807, acc:  51%] [D loss_mask: 0.536061, acc:  50%] [G loss: 41.146729] time: 0:15:37.639128\n[Epoch 232/80000] [D loss_whole: 0.269219, acc:  49%] [D loss_mask: 0.537538, acc:  49%] [G loss: 37.967747] time: 0:15:41.374593\n[Epoch 233/80000] [D loss_whole: 0.275131, acc:  49%] [D loss_mask: 0.550431, acc:  48%] [G loss: 38.946674] time: 0:15:45.132320\n[Epoch 234/80000] [D loss_whole: 0.277654, acc:  48%] [D loss_mask: 0.545032, acc:  49%] [G loss: 41.604053] time: 0:15:48.886676\n[Epoch 235/80000] [D loss_whole: 0.279060, acc:  47%] [D loss_mask: 0.547273, acc:  48%] [G loss: 43.082520] time: 0:15:52.649359\n[Epoch 236/80000] [D loss_whole: 0.264363, acc:  53%] [D loss_mask: 0.520798, acc:  54%] [G loss: 42.128544] time: 0:15:56.501571\n[Epoch 237/80000] [D loss_whole: 0.259526, acc:  51%] [D loss_mask: 0.533290, acc:  52%] [G loss: 41.775372] time: 0:16:00.273250\n[Epoch 238/80000] [D loss_whole: 0.264063, acc:  48%] [D loss_mask: 0.542170, acc:  48%] [G loss: 39.953697] time: 0:16:04.058379\n[Epoch 239/80000] [D loss_whole: 0.265377, acc:  50%] [D loss_mask: 0.542178, acc:  49%] [G loss: 42.262039] time: 0:16:07.812784\n[Epoch 240/80000] [D loss_whole: 0.275442, acc:  49%] [D loss_mask: 0.535282, acc:  51%] [G loss: 42.528202] time: 0:16:11.638734\n[Epoch 241/80000] [D loss_whole: 0.281663, acc:  50%] [D loss_mask: 0.538848, acc:  50%] [G loss: 42.312469] time: 0:16:15.385666\n[Epoch 242/80000] [D loss_whole: 0.273119, acc:  49%] [D loss_mask: 0.533520, acc:  51%] [G loss: 38.127151] time: 0:16:19.153374\n[Epoch 243/80000] [D loss_whole: 0.263406, acc:  51%] [D loss_mask: 0.534818, acc:  46%] [G loss: 42.818344] time: 0:16:22.914148\n[Epoch 244/80000] [D loss_whole: 0.261228, acc:  51%] [D loss_mask: 0.539269, acc:  47%] [G loss: 40.312019] time: 0:16:26.691027\n[Epoch 245/80000] [D loss_whole: 0.268580, acc:  50%] [D loss_mask: 0.545991, acc:  47%] [G loss: 37.497612] time: 0:16:30.512016\n[Epoch 246/80000] [D loss_whole: 0.289112, acc:  48%] [D loss_mask: 0.547026, acc:  48%] [G loss: 36.693043] time: 0:16:34.310398\n[Epoch 247/80000] [D loss_whole: 0.315373, acc:  47%] [D loss_mask: 0.556711, acc:  47%] [G loss: 38.953133] time: 0:16:38.073857\n[Epoch 248/80000] [D loss_whole: 0.299446, acc:  46%] [D loss_mask: 0.549748, acc:  47%] [G loss: 38.087841] time: 0:16:41.911633\n[Epoch 249/80000] [D loss_whole: 0.297901, acc:  48%] [D loss_mask: 0.552952, acc:  51%] [G loss: 41.384659] time: 0:16:45.670651\n[Epoch 250/80000] [D loss_whole: 0.290106, acc:  49%] [D loss_mask: 0.541269, acc:  51%] [G loss: 41.807629] time: 0:16:49.432450\n[Epoch 251/80000] [D loss_whole: 0.272939, acc:  50%] [D loss_mask: 0.517791, acc:  53%] [G loss: 39.254436] time: 0:16:53.214823\n[Epoch 252/80000] [D loss_whole: 0.262653, acc:  50%] [D loss_mask: 0.535011, acc:  46%] [G loss: 38.289837] time: 0:16:56.983284\n[Epoch 253/80000] [D loss_whole: 0.256320, acc:  53%] [D loss_mask: 0.517797, acc:  52%] [G loss: 38.230595] time: 0:17:00.710739\n[Epoch 254/80000] [D loss_whole: 0.252635, acc:  51%] [D loss_mask: 0.506480, acc:  52%] [G loss: 40.679417] time: 0:17:04.428087\n[Epoch 255/80000] [D loss_whole: 0.297806, acc:  49%] [D loss_mask: 0.556660, acc:  42%] [G loss: 41.109234] time: 0:17:08.220732\n[Epoch 256/80000] [D loss_whole: 0.275080, acc:  50%] [D loss_mask: 0.544360, acc:  48%] [G loss: 40.929836] time: 0:17:11.963000\n[Epoch 257/80000] [D loss_whole: 0.266222, acc:  50%] [D loss_mask: 0.547706, acc:  52%] [G loss: 38.867409] time: 0:17:15.708897\n[Epoch 258/80000] [D loss_whole: 0.273481, acc:  49%] [D loss_mask: 0.546932, acc:  48%] [G loss: 39.730587] time: 0:17:19.508062\n[Epoch 259/80000] [D loss_whole: 0.268691, acc:  49%] [D loss_mask: 0.523992, acc:  52%] [G loss: 37.198647] time: 0:17:23.203830\n[Epoch 260/80000] [D loss_whole: 0.260683, acc:  52%] [D loss_mask: 0.523245, acc:  47%] [G loss: 40.709743] time: 0:17:26.954925\n[Epoch 261/80000] [D loss_whole: 0.263760, acc:  47%] [D loss_mask: 0.537872, acc:  44%] [G loss: 38.176918] time: 0:17:30.701414\n[Epoch 262/80000] [D loss_whole: 0.280347, acc:  50%] [D loss_mask: 0.532026, acc:  48%] [G loss: 37.499527] time: 0:17:34.434694\n[Epoch 263/80000] [D loss_whole: 0.354622, acc:  46%] [D loss_mask: 0.549343, acc:  48%] [G loss: 39.284454] time: 0:17:38.224466\n[Epoch 264/80000] [D loss_whole: 0.405576, acc:  46%] [D loss_mask: 0.546290, acc:  49%] [G loss: 41.069675] time: 0:17:41.973353\n[Epoch 265/80000] [D loss_whole: 0.320927, acc:  48%] [D loss_mask: 0.540071, acc:  50%] [G loss: 40.985695] time: 0:17:45.754068\n[Epoch 266/80000] [D loss_whole: 0.291376, acc:  47%] [D loss_mask: 0.544810, acc:  49%] [G loss: 38.069248] time: 0:17:49.498534\n[Epoch 267/80000] [D loss_whole: 0.289980, acc:  47%] [D loss_mask: 0.541331, acc:  49%] [G loss: 39.003914] time: 0:17:53.241629\n[Epoch 268/80000] [D loss_whole: 0.299185, acc:  47%] [D loss_mask: 0.549001, acc:  47%] [G loss: 39.070004] time: 0:17:57.055231\n[Epoch 269/80000] [D loss_whole: 0.307168, acc:  48%] [D loss_mask: 0.555912, acc:  47%] [G loss: 40.162189] time: 0:18:00.820318\n[Epoch 270/80000] [D loss_whole: 0.312226, acc:  46%] [D loss_mask: 0.551356, acc:  52%] [G loss: 44.042728] time: 0:18:04.585551\n[Epoch 271/80000] [D loss_whole: 0.275888, acc:  51%] [D loss_mask: 0.521596, acc:  52%] [G loss: 36.112984] time: 0:18:08.335076\n[Epoch 272/80000] [D loss_whole: 0.259553, acc:  50%] [D loss_mask: 0.527430, acc:  46%] [G loss: 39.321922] time: 0:18:12.120085\n[Epoch 273/80000] [D loss_whole: 0.280836, acc:  53%] [D loss_mask: 0.535845, acc:  47%] [G loss: 40.957310] time: 0:18:15.868532\n[Epoch 274/80000] [D loss_whole: 0.318600, acc:  52%] [D loss_mask: 0.593595, acc:  46%] [G loss: 42.864834] time: 0:18:19.592507\n[Epoch 275/80000] [D loss_whole: 0.274163, acc:  52%] [D loss_mask: 0.547248, acc:  45%] [G loss: 37.510609] time: 0:18:23.403635\n[Epoch 276/80000] [D loss_whole: 0.257887, acc:  51%] [D loss_mask: 0.534701, acc:  45%] [G loss: 41.256668] time: 0:18:27.157392\n[Epoch 277/80000] [D loss_whole: 0.261406, acc:  50%] [D loss_mask: 0.546687, acc:  47%] [G loss: 39.186687] time: 0:18:30.904321\n[Epoch 278/80000] [D loss_whole: 0.260974, acc:  49%] [D loss_mask: 0.547873, acc:  48%] [G loss: 39.852901] time: 0:18:34.611585\n[Epoch 279/80000] [D loss_whole: 0.269981, acc:  50%] [D loss_mask: 0.562034, acc:  46%] [G loss: 35.777264] time: 0:18:38.370480\n[Epoch 280/80000] [D loss_whole: 0.281145, acc:  47%] [D loss_mask: 0.549581, acc:  51%] [G loss: 43.129238] time: 0:18:42.079188\n[Epoch 281/80000] [D loss_whole: 0.287831, acc:  47%] [D loss_mask: 0.541618, acc:  51%] [G loss: 41.681995] time: 0:18:45.832230\n[Epoch 282/80000] [D loss_whole: 0.290579, acc:  48%] [D loss_mask: 0.521582, acc:  52%] [G loss: 40.175961] time: 0:18:49.511100\n[Epoch 283/80000] [D loss_whole: 0.264324, acc:  52%] [D loss_mask: 0.531420, acc:  53%] [G loss: 38.501831] time: 0:18:53.319602\n[Epoch 284/80000] [D loss_whole: 0.272858, acc:  47%] [D loss_mask: 0.541628, acc:  48%] [G loss: 40.919327] time: 0:18:57.069445\n[Epoch 285/80000] [D loss_whole: 0.259953, acc:  49%] [D loss_mask: 0.530171, acc:  45%] [G loss: 37.311127] time: 0:19:00.824771\n[Epoch 286/80000] [D loss_whole: 0.257660, acc:  53%] [D loss_mask: 0.502495, acc:  52%] [G loss: 39.267891] time: 0:19:04.555187\n[Epoch 287/80000] [D loss_whole: 0.263924, acc:  50%] [D loss_mask: 0.508167, acc:  48%] [G loss: 44.221462] time: 0:19:08.295222\n[Epoch 288/80000] [D loss_whole: 0.431950, acc:  50%] [D loss_mask: 0.551684, acc:  47%] [G loss: 38.727779] time: 0:19:12.029674\n[Epoch 289/80000] [D loss_whole: 0.786341, acc:  53%] [D loss_mask: 0.749190, acc:  50%] [G loss: 37.991165] time: 0:19:15.736440\n[Epoch 290/80000] [D loss_whole: 0.537455, acc:  55%] [D loss_mask: 0.718217, acc:  45%] [G loss: 39.290955] time: 0:19:19.532378\n[Epoch 291/80000] [D loss_whole: 0.276646, acc:  50%] [D loss_mask: 0.616590, acc:  42%] [G loss: 38.876163] time: 0:19:23.287503\n[Epoch 292/80000] [D loss_whole: 0.338162, acc:  46%] [D loss_mask: 0.530874, acc:  48%] [G loss: 37.737186] time: 0:19:27.016115\n[Epoch 293/80000] [D loss_whole: 0.317476, acc:  44%] [D loss_mask: 0.534895, acc:  48%] [G loss: 37.906475] time: 0:19:30.809653\n[Epoch 294/80000] [D loss_whole: 0.287930, acc:  48%] [D loss_mask: 0.556130, acc:  47%] [G loss: 41.853519] time: 0:19:34.600592\n[Epoch 295/80000] [D loss_whole: 0.302681, acc:  48%] [D loss_mask: 0.588715, acc:  48%] [G loss: 41.244884] time: 0:19:38.343223\n[Epoch 296/80000] [D loss_whole: 0.270331, acc:  50%] [D loss_mask: 0.587832, acc:  50%] [G loss: 37.808514] time: 0:19:42.043314\n[Epoch 297/80000] [D loss_whole: 0.260719, acc:  50%] [D loss_mask: 0.575365, acc:  48%] [G loss: 37.307671] time: 0:19:45.712943\n[Epoch 298/80000] [D loss_whole: 0.272836, acc:  49%] [D loss_mask: 0.609056, acc:  47%] [G loss: 39.789272] time: 0:19:49.437574\n[Epoch 299/80000] [D loss_whole: 0.363752, acc:  44%] [D loss_mask: 0.690409, acc:  46%] [G loss: 38.852974] time: 0:19:53.152655\n[Epoch 300/80000] [D loss_whole: 0.390547, acc:  44%] [D loss_mask: 0.677675, acc:  46%] [G loss: 36.892948] time: 0:19:56.918353\nINFO:tensorflow:Assets written to: saved_models/inpaint_net300/assets\n[Epoch 301/80000] [D loss_whole: 0.313914, acc:  46%] [D loss_mask: 0.628605, acc:  47%] [G loss: 38.450466] time: 0:20:14.103683\n[Epoch 302/80000] [D loss_whole: 0.261138, acc:  50%] [D loss_mask: 0.667527, acc:  55%] [G loss: 38.189274] time: 0:20:17.685438\n[Epoch 303/80000] [D loss_whole: 0.287534, acc:  51%] [D loss_mask: 0.621831, acc:  55%] [G loss: 42.451389] time: 0:20:21.139365\n[Epoch 304/80000] [D loss_whole: 0.256657, acc:  52%] [D loss_mask: 0.547396, acc:  53%] [G loss: 39.201756] time: 0:20:24.537654\n[Epoch 305/80000] [D loss_whole: 0.281201, acc:  52%] [D loss_mask: 0.543876, acc:  54%] [G loss: 39.331779] time: 0:20:28.330628\n[Epoch 306/80000] [D loss_whole: 0.265312, acc:  48%] [D loss_mask: 0.535399, acc:  48%] [G loss: 36.851318] time: 0:20:32.122381\n[Epoch 307/80000] [D loss_whole: 0.281875, acc:  49%] [D loss_mask: 0.538447, acc:  51%] [G loss: 36.995728] time: 0:20:35.866816\n[Epoch 308/80000] [D loss_whole: 0.316385, acc:  46%] [D loss_mask: 0.532097, acc:  49%] [G loss: 41.628788] time: 0:20:39.499001\n[Epoch 309/80000] [D loss_whole: 0.286628, acc:  46%] [D loss_mask: 0.536612, acc:  48%] [G loss: 38.573963] time: 0:20:43.195990\n[Epoch 310/80000] [D loss_whole: 0.266580, acc:  50%] [D loss_mask: 0.518562, acc:  49%] [G loss: 38.126232] time: 0:20:46.714566\n[Epoch 311/80000] [D loss_whole: 0.260045, acc:  50%] [D loss_mask: 0.547491, acc:  41%] [G loss: 37.447220] time: 0:20:50.378966\n[Epoch 312/80000] [D loss_whole: 0.256951, acc:  52%] [D loss_mask: 0.536813, acc:  43%] [G loss: 38.020187] time: 0:20:53.889747\n[Epoch 313/80000] [D loss_whole: 0.257213, acc:  50%] [D loss_mask: 0.540401, acc:  43%] [G loss: 36.824123] time: 0:20:57.343783\n[Epoch 314/80000] [D loss_whole: 0.251412, acc:  52%] [D loss_mask: 0.535259, acc:  46%] [G loss: 36.148365] time: 0:21:00.719741\n[Epoch 315/80000] [D loss_whole: 0.267583, acc:  51%] [D loss_mask: 0.610330, acc:  46%] [G loss: 35.361580] time: 0:21:04.460641\n[Epoch 316/80000] [D loss_whole: 0.270028, acc:  50%] [D loss_mask: 0.632108, acc:  48%] [G loss: 35.213043] time: 0:21:08.224326\n[Epoch 317/80000] [D loss_whole: 0.263677, acc:  50%] [D loss_mask: 0.564720, acc:  43%] [G loss: 36.491261] time: 0:21:11.976996\n[Epoch 318/80000] [D loss_whole: 0.262030, acc:  53%] [D loss_mask: 0.521002, acc:  48%] [G loss: 39.971661] time: 0:21:15.563315\n[Epoch 319/80000] [D loss_whole: 0.255623, acc:  52%] [D loss_mask: 0.513568, acc:  48%] [G loss: 36.868576] time: 0:21:19.300007\n[Epoch 320/80000] [D loss_whole: 0.277840, acc:  47%] [D loss_mask: 0.573318, acc:  43%] [G loss: 35.175789] time: 0:21:22.825458\n[Epoch 321/80000] [D loss_whole: 0.263775, acc:  50%] [D loss_mask: 0.561621, acc:  42%] [G loss: 36.412590] time: 0:21:26.486316\n[Epoch 322/80000] [D loss_whole: 0.261408, acc:  52%] [D loss_mask: 0.543004, acc:  41%] [G loss: 39.815098] time: 0:21:30.014835\n[Epoch 323/80000] [D loss_whole: 0.282512, acc:  49%] [D loss_mask: 0.536517, acc:  47%] [G loss: 41.006413] time: 0:21:33.620711\n[Epoch 324/80000] [D loss_whole: 0.305572, acc:  45%] [D loss_mask: 0.559751, acc:  45%] [G loss: 34.114643] time: 0:21:37.292472\n[Epoch 325/80000] [D loss_whole: 0.282398, acc:  49%] [D loss_mask: 0.553174, acc:  49%] [G loss: 36.015865] time: 0:21:41.015222\n[Epoch 326/80000] [D loss_whole: 0.264057, acc:  51%] [D loss_mask: 0.541970, acc:  51%] [G loss: 39.014881] time: 0:21:44.753612\n[Epoch 327/80000] [D loss_whole: 0.267789, acc:  51%] [D loss_mask: 0.552675, acc:  49%] [G loss: 40.444553] time: 0:21:48.476061\n[Epoch 328/80000] [D loss_whole: 0.267619, acc:  49%] [D loss_mask: 0.539024, acc:  49%] [G loss: 38.160156] time: 0:21:52.081900\n[Epoch 329/80000] [D loss_whole: 0.257686, acc:  51%] [D loss_mask: 0.545445, acc:  53%] [G loss: 37.194843] time: 0:21:55.692124\n[Epoch 330/80000] [D loss_whole: 0.269849, acc:  50%] [D loss_mask: 0.539884, acc:  48%] [G loss: 38.860931] time: 0:21:59.223424\n[Epoch 331/80000] [D loss_whole: 0.255153, acc:  52%] [D loss_mask: 0.533993, acc:  48%] [G loss: 35.170422] time: 0:22:02.853519\n[Epoch 332/80000] [D loss_whole: 0.259493, acc:  52%] [D loss_mask: 0.540960, acc:  48%] [G loss: 37.598549] time: 0:22:06.360645\n[Epoch 333/80000] [D loss_whole: 0.269704, acc:  51%] [D loss_mask: 0.559523, acc:  46%] [G loss: 37.087990] time: 0:22:10.054636\n[Epoch 334/80000] [D loss_whole: 0.280587, acc:  47%] [D loss_mask: 0.573471, acc:  47%] [G loss: 36.518410] time: 0:22:13.552964\n[Epoch 335/80000] [D loss_whole: 0.274147, acc:  51%] [D loss_mask: 0.574625, acc:  53%] [G loss: 38.194679] time: 0:22:17.207177\n[Epoch 336/80000] [D loss_whole: 0.265640, acc:  50%] [D loss_mask: 0.562621, acc:  49%] [G loss: 36.251884] time: 0:22:20.721077\n[Epoch 337/80000] [D loss_whole: 0.260828, acc:  52%] [D loss_mask: 0.546718, acc:  46%] [G loss: 37.209908] time: 0:22:24.338132\n[Epoch 338/80000] [D loss_whole: 0.257587, acc:  53%] [D loss_mask: 0.516412, acc:  53%] [G loss: 36.357056] time: 0:22:27.991707\n[Epoch 339/80000] [D loss_whole: 0.268595, acc:  51%] [D loss_mask: 0.511844, acc:  51%] [G loss: 38.231422] time: 0:22:31.693687\n[Epoch 340/80000] [D loss_whole: 0.385399, acc:  51%] [D loss_mask: 0.594394, acc:  44%] [G loss: 39.613430] time: 0:22:35.445285\n[Epoch 341/80000] [D loss_whole: 0.275223, acc:  54%] [D loss_mask: 0.594300, acc:  53%] [G loss: 40.761909] time: 0:22:39.201719\n[Epoch 342/80000] [D loss_whole: 0.377748, acc:  52%] [D loss_mask: 0.539141, acc:  50%] [G loss: 37.241070] time: 0:22:42.773885\n[Epoch 343/80000] [D loss_whole: 0.589349, acc:  44%] [D loss_mask: 0.553456, acc:  48%] [G loss: 35.864902] time: 0:22:46.404622\n[Epoch 344/80000] [D loss_whole: 0.560359, acc:  42%] [D loss_mask: 0.630599, acc:  47%] [G loss: 38.958973] time: 0:22:49.938989\n[Epoch 345/80000] [D loss_whole: 0.353650, acc:  50%] [D loss_mask: 0.730532, acc:  50%] [G loss: 40.776936] time: 0:22:53.338511\n[Epoch 346/80000] [D loss_whole: 0.275051, acc:  55%] [D loss_mask: 0.826849, acc:  49%] [G loss: 37.296173] time: 0:22:56.625298\n[Epoch 347/80000] [D loss_whole: 0.261114, acc:  51%] [D loss_mask: 0.749449, acc:  45%] [G loss: 36.824665] time: 0:23:00.320255\n[Epoch 348/80000] [D loss_whole: 0.257093, acc:  52%] [D loss_mask: 0.584042, acc:  46%] [G loss: 36.438217] time: 0:23:04.049955\n[Epoch 349/80000] [D loss_whole: 0.258233, acc:  52%] [D loss_mask: 0.535829, acc:  47%] [G loss: 36.026283] time: 0:23:07.728533\n[Epoch 350/80000] [D loss_whole: 0.250083, acc:  55%] [D loss_mask: 0.514777, acc:  49%] [G loss: 39.286785] time: 0:23:11.337756\n[Epoch 351/80000] [D loss_whole: 0.257241, acc:  50%] [D loss_mask: 0.541612, acc:  46%] [G loss: 36.647362] time: 0:23:14.904352\n[Epoch 352/80000] [D loss_whole: 0.253303, acc:  54%] [D loss_mask: 0.547225, acc:  43%] [G loss: 37.707909] time: 0:23:18.446484\n[Epoch 353/80000] [D loss_whole: 0.256580, acc:  50%] [D loss_mask: 0.584272, acc:  48%] [G loss: 37.946159] time: 0:23:21.991520\n[Epoch 354/80000] [D loss_whole: 0.256661, acc:  52%] [D loss_mask: 0.598269, acc:  40%] [G loss: 35.485928] time: 0:23:25.413231\n[Epoch 355/80000] [D loss_whole: 0.253943, acc:  53%] [D loss_mask: 0.613549, acc:  42%] [G loss: 37.131050] time: 0:23:28.865496\n[Epoch 356/80000] [D loss_whole: 0.252292, acc:  53%] [D loss_mask: 0.594076, acc:  48%] [G loss: 37.140816] time: 0:23:32.152877\n[Epoch 357/80000] [D loss_whole: 0.255300, acc:  50%] [D loss_mask: 0.630087, acc:  49%] [G loss: 34.315899] time: 0:23:35.865733\n[Epoch 358/80000] [D loss_whole: 0.250431, acc:  52%] [D loss_mask: 0.609427, acc:  51%] [G loss: 36.987728] time: 0:23:39.586543\n[Epoch 359/80000] [D loss_whole: 0.265260, acc:  48%] [D loss_mask: 0.613013, acc:  46%] [G loss: 37.935921] time: 0:23:43.285629\n[Epoch 360/80000] [D loss_whole: 0.255324, acc:  50%] [D loss_mask: 0.573641, acc:  43%] [G loss: 35.820278] time: 0:23:46.847429\n[Epoch 361/80000] [D loss_whole: 0.251687, acc:  52%] [D loss_mask: 0.544944, acc:  47%] [G loss: 36.420063] time: 0:23:50.395773\n[Epoch 362/80000] [D loss_whole: 0.259523, acc:  52%] [D loss_mask: 0.548395, acc:  45%] [G loss: 37.637257] time: 0:23:53.974027\n[Epoch 363/80000] [D loss_whole: 0.268998, acc:  50%] [D loss_mask: 0.557187, acc:  53%] [G loss: 36.589989] time: 0:23:57.632484\n[Epoch 364/80000] [D loss_whole: 0.264219, acc:  53%] [D loss_mask: 0.517126, acc:  55%] [G loss: 37.196796] time: 0:24:01.156350\n[Epoch 365/80000] [D loss_whole: 0.256542, acc:  54%] [D loss_mask: 0.563578, acc:  55%] [G loss: 38.594784] time: 0:24:04.571633\n[Epoch 366/80000] [D loss_whole: 0.256711, acc:  49%] [D loss_mask: 0.566621, acc:  46%] [G loss: 36.979221] time: 0:24:07.885479\n[Epoch 367/80000] [D loss_whole: 0.257126, acc:  52%] [D loss_mask: 0.548676, acc:  45%] [G loss: 37.170330] time: 0:24:11.622913\n[Epoch 368/80000] [D loss_whole: 0.262508, acc:  52%] [D loss_mask: 0.557686, acc:  49%] [G loss: 36.155827] time: 0:24:15.034757\n[Epoch 369/80000] [D loss_whole: 0.271421, acc:  49%] [D loss_mask: 0.593832, acc:  45%] [G loss: 34.999065] time: 0:24:18.705070\n[Epoch 370/80000] [D loss_whole: 0.269173, acc:  50%] [D loss_mask: 0.585050, acc:  46%] [G loss: 36.084362] time: 0:24:22.425471\n[Epoch 371/80000] [D loss_whole: 0.268256, acc:  52%] [D loss_mask: 0.556433, acc:  48%] [G loss: 38.139915] time: 0:24:26.150912\n[Epoch 372/80000] [D loss_whole: 0.255125, acc:  54%] [D loss_mask: 0.512336, acc:  54%] [G loss: 37.950764] time: 0:24:29.737814\n[Epoch 373/80000] [D loss_whole: 0.254069, acc:  52%] [D loss_mask: 0.525891, acc:  46%] [G loss: 35.100544] time: 0:24:33.322786\n[Epoch 374/80000] [D loss_whole: 0.266587, acc:  49%] [D loss_mask: 0.545994, acc:  41%] [G loss: 34.784088] time: 0:24:36.786364\n[Epoch 375/80000] [D loss_whole: 0.256233, acc:  51%] [D loss_mask: 0.532080, acc:  44%] [G loss: 38.977615] time: 0:24:40.388700\n[Epoch 376/80000] [D loss_whole: 0.256780, acc:  50%] [D loss_mask: 0.536716, acc:  45%] [G loss: 37.048210] time: 0:24:43.902317\n[Epoch 377/80000] [D loss_whole: 0.253995, acc:  55%] [D loss_mask: 0.534213, acc:  48%] [G loss: 42.665234] time: 0:24:47.440861\n[Epoch 378/80000] [D loss_whole: 0.253755, acc:  54%] [D loss_mask: 0.527583, acc:  47%] [G loss: 38.016541] time: 0:24:50.876647\n[Epoch 379/80000] [D loss_whole: 0.257375, acc:  53%] [D loss_mask: 0.537404, acc:  43%] [G loss: 35.718086] time: 0:24:54.454105\n[Epoch 380/80000] [D loss_whole: 0.258937, acc:  53%] [D loss_mask: 0.530556, acc:  46%] [G loss: 36.692616] time: 0:24:57.964192\n[Epoch 381/80000] [D loss_whole: 0.259353, acc:  53%] [D loss_mask: 0.524238, acc:  49%] [G loss: 36.882195] time: 0:25:01.390786\n[Epoch 382/80000] [D loss_whole: 0.259175, acc:  52%] [D loss_mask: 0.532253, acc:  48%] [G loss: 36.471645] time: 0:25:04.720249\n[Epoch 383/80000] [D loss_whole: 0.258336, acc:  52%] [D loss_mask: 0.531721, acc:  48%] [G loss: 35.710255] time: 0:25:08.434365\n[Epoch 384/80000] [D loss_whole: 0.261650, acc:  52%] [D loss_mask: 0.549229, acc:  47%] [G loss: 36.045193] time: 0:25:12.143085\n[Epoch 385/80000] [D loss_whole: 0.257982, acc:  53%] [D loss_mask: 0.542094, acc:  47%] [G loss: 38.695686] time: 0:25:15.907980\n[Epoch 386/80000] [D loss_whole: 0.256707, acc:  53%] [D loss_mask: 0.556805, acc:  50%] [G loss: 36.518906] time: 0:25:19.480240\n[Epoch 387/80000] [D loss_whole: 0.255624, acc:  54%] [D loss_mask: 0.552154, acc:  47%] [G loss: 36.587231] time: 0:25:23.228582\n[Epoch 388/80000] [D loss_whole: 0.247347, acc:  55%] [D loss_mask: 0.518514, acc:  53%] [G loss: 35.571136] time: 0:25:26.704663\n[Epoch 389/80000] [D loss_whole: 0.258251, acc:  52%] [D loss_mask: 0.527291, acc:  49%] [G loss: 35.625225] time: 0:25:30.114445\n[Epoch 390/80000] [D loss_whole: 0.261183, acc:  50%] [D loss_mask: 0.544498, acc:  48%] [G loss: 37.821842] time: 0:25:33.400392\n[Epoch 391/80000] [D loss_whole: 0.249456, acc:  53%] [D loss_mask: 0.522932, acc:  55%] [G loss: 39.221062] time: 0:25:37.110869\n[Epoch 392/80000] [D loss_whole: 0.257405, acc:  49%] [D loss_mask: 0.531930, acc:  51%] [G loss: 34.488041] time: 0:25:40.793184\n[Epoch 393/80000] [D loss_whole: 0.255586, acc:  49%] [D loss_mask: 0.550557, acc:  49%] [G loss: 34.666443] time: 0:25:44.494760\n[Epoch 394/80000] [D loss_whole: 0.258699, acc:  51%] [D loss_mask: 0.583750, acc:  48%] [G loss: 38.317154] time: 0:25:48.106351\n[Epoch 395/80000] [D loss_whole: 0.251508, acc:  55%] [D loss_mask: 0.620542, acc:  50%] [G loss: 37.271061] time: 0:25:51.512584\n[Epoch 396/80000] [D loss_whole: 0.258253, acc:  50%] [D loss_mask: 0.672280, acc:  51%] [G loss: 37.859123] time: 0:25:54.723225\n[Epoch 397/80000] [D loss_whole: 0.256135, acc:  49%] [D loss_mask: 0.723609, acc:  46%] [G loss: 35.667889] time: 0:25:58.504495\n[Epoch 398/80000] [D loss_whole: 0.259622, acc:  51%] [D loss_mask: 0.821321, acc:  51%] [G loss: 36.124714] time: 0:26:02.197993\n[Epoch 399/80000] [D loss_whole: 0.254140, acc:  55%] [D loss_mask: 0.613711, acc:  58%] [G loss: 39.596340] time: 0:26:05.906401\n[Epoch 400/80000] [D loss_whole: 0.267315, acc:  52%] [D loss_mask: 0.518381, acc:  52%] [G loss: 37.271130] time: 0:26:09.496927\nINFO:tensorflow:Assets written to: saved_models/inpaint_net400/assets\n[Epoch 401/80000] [D loss_whole: 0.651726, acc:  51%] [D loss_mask: 1.023676, acc:  52%] [G loss: 36.841408] time: 0:26:26.013612\n[Epoch 402/80000] [D loss_whole: 0.891638, acc:  51%] [D loss_mask: 1.101982, acc:  45%] [G loss: 39.441074] time: 0:26:29.649919\n[Epoch 403/80000] [D loss_whole: 0.690559, acc:  55%] [D loss_mask: 0.813979, acc:  46%] [G loss: 35.151653] time: 0:26:33.370736\n[Epoch 404/80000] [D loss_whole: 0.346315, acc:  57%] [D loss_mask: 0.546337, acc:  50%] [G loss: 37.888569] time: 0:26:36.762897\n[Epoch 405/80000] [D loss_whole: 0.255803, acc:  53%] [D loss_mask: 0.519158, acc:  47%] [G loss: 35.691113] time: 0:26:40.424761\n[Epoch 406/80000] [D loss_whole: 0.261393, acc:  50%] [D loss_mask: 0.546956, acc:  47%] [G loss: 36.873451] time: 0:26:44.165639\n[Epoch 407/80000] [D loss_whole: 0.278548, acc:  48%] [D loss_mask: 0.557682, acc:  50%] [G loss: 35.031425] time: 0:26:47.709634\n[Epoch 408/80000] [D loss_whole: 0.277420, acc:  50%] [D loss_mask: 0.543353, acc:  52%] [G loss: 36.566528] time: 0:26:51.431348\n[Epoch 409/80000] [D loss_whole: 0.263131, acc:  52%] [D loss_mask: 0.531721, acc:  50%] [G loss: 36.409470] time: 0:26:54.914435\n[Epoch 410/80000] [D loss_whole: 0.254427, acc:  54%] [D loss_mask: 0.530920, acc:  44%] [G loss: 33.667263] time: 0:26:58.581530\n[Epoch 411/80000] [D loss_whole: 0.244770, acc:  58%] [D loss_mask: 0.498927, acc:  51%] [G loss: 36.298023] time: 0:27:02.283854\n[Epoch 412/80000] [D loss_whole: 0.250879, acc:  52%] [D loss_mask: 0.514690, acc:  49%] [G loss: 35.890747] time: 0:27:05.870365\n[Epoch 413/80000] [D loss_whole: 0.260362, acc:  49%] [D loss_mask: 0.532916, acc:  43%] [G loss: 33.408417] time: 0:27:09.631321\n[Epoch 414/80000] [D loss_whole: 0.255740, acc:  52%] [D loss_mask: 0.528485, acc:  48%] [G loss: 36.462769] time: 0:27:13.153632\n[Epoch 415/80000] [D loss_whole: 0.271589, acc:  51%] [D loss_mask: 0.551540, acc:  46%] [G loss: 33.795712] time: 0:27:16.816765\n[Epoch 416/80000] [D loss_whole: 0.297306, acc:  46%] [D loss_mask: 0.572922, acc:  44%] [G loss: 36.108051] time: 0:27:20.552801\n[Epoch 417/80000] [D loss_whole: 0.270750, acc:  49%] [D loss_mask: 0.540850, acc:  48%] [G loss: 36.830444] time: 0:27:24.039877\n[Epoch 418/80000] [D loss_whole: 0.255739, acc:  53%] [D loss_mask: 0.534919, acc:  46%] [G loss: 33.944057] time: 0:27:27.717736\n[Epoch 419/80000] [D loss_whole: 0.251957, acc:  54%] [D loss_mask: 0.542703, acc:  44%] [G loss: 34.763386] time: 0:27:31.450174\n[Epoch 420/80000] [D loss_whole: 0.255479, acc:  53%] [D loss_mask: 0.530622, acc:  47%] [G loss: 36.743519] time: 0:27:34.921231\n[Epoch 421/80000] [D loss_whole: 0.258178, acc:  52%] [D loss_mask: 0.537501, acc:  46%] [G loss: 34.650753] time: 0:27:38.611893\n[Epoch 422/80000] [D loss_whole: 0.263412, acc:  50%] [D loss_mask: 0.539064, acc:  46%] [G loss: 34.151569] time: 0:27:42.338710\n[Epoch 423/80000] [D loss_whole: 0.254574, acc:  54%] [D loss_mask: 0.514528, acc:  53%] [G loss: 33.981377] time: 0:27:45.952599\n[Epoch 424/80000] [D loss_whole: 0.247484, acc:  57%] [D loss_mask: 0.517284, acc:  47%] [G loss: 36.627316] time: 0:27:48.929180\n[Epoch 425/80000] [D loss_whole: 0.249720, acc:  53%] [D loss_mask: 0.517693, acc:  47%] [G loss: 34.720558] time: 0:27:52.549829\n[Epoch 426/80000] [D loss_whole: 0.246607, acc:  53%] [D loss_mask: 0.508687, acc:  50%] [G loss: 36.963711] time: 0:27:56.240034\n[Epoch 427/80000] [D loss_whole: 0.256781, acc:  51%] [D loss_mask: 0.533974, acc:  44%] [G loss: 38.838215] time: 0:27:59.713417\n[Epoch 428/80000] [D loss_whole: 0.242728, acc:  57%] [D loss_mask: 0.520095, acc:  50%] [G loss: 34.021217] time: 0:28:03.365680\n[Epoch 429/80000] [D loss_whole: 0.255868, acc:  50%] [D loss_mask: 0.533673, acc:  51%] [G loss: 34.893452] time: 0:28:07.123280\n[Epoch 430/80000] [D loss_whole: 0.246444, acc:  52%] [D loss_mask: 0.518147, acc:  51%] [G loss: 34.693485] time: 0:28:10.633687\n[Epoch 431/80000] [D loss_whole: 0.256117, acc:  49%] [D loss_mask: 0.532287, acc:  45%] [G loss: 34.941013] time: 0:28:13.633299\n[Epoch 432/80000] [D loss_whole: 0.252945, acc:  55%] [D loss_mask: 0.536414, acc:  51%] [G loss: 35.107990] time: 0:28:17.246033\n[Epoch 433/80000] [D loss_whole: 0.257091, acc:  55%] [D loss_mask: 0.521473, acc:  48%] [G loss: 35.467464] time: 0:28:20.939104\n[Epoch 434/80000] [D loss_whole: 0.257430, acc:  54%] [D loss_mask: 0.522854, acc:  47%] [G loss: 34.281559] time: 0:28:24.366551\n[Epoch 435/80000] [D loss_whole: 0.259074, acc:  53%] [D loss_mask: 0.528056, acc:  49%] [G loss: 33.541454] time: 0:28:28.047108\n[Epoch 436/80000] [D loss_whole: 0.254966, acc:  55%] [D loss_mask: 0.513895, acc:  51%] [G loss: 36.314972] time: 0:28:31.746069\n[Epoch 437/80000] [D loss_whole: 0.255582, acc:  53%] [D loss_mask: 0.536357, acc:  43%] [G loss: 37.851006] time: 0:28:35.202328\n[Epoch 438/80000] [D loss_whole: 0.260063, acc:  55%] [D loss_mask: 0.540227, acc:  41%] [G loss: 32.708088] time: 0:28:38.864885\n[Epoch 439/80000] [D loss_whole: 0.275976, acc:  52%] [D loss_mask: 0.543149, acc:  49%] [G loss: 35.346531] time: 0:28:42.584171\n[Epoch 440/80000] [D loss_whole: 0.288012, acc:  48%] [D loss_mask: 0.529037, acc:  49%] [G loss: 32.972412] time: 0:28:46.002319\n[Epoch 441/80000] [D loss_whole: 0.278545, acc:  49%] [D loss_mask: 0.533723, acc:  51%] [G loss: 34.110634] time: 0:28:49.665640\n[Epoch 442/80000] [D loss_whole: 0.287836, acc:  47%] [D loss_mask: 0.564582, acc:  44%] [G loss: 40.145851] time: 0:28:53.339549\n[Epoch 443/80000] [D loss_whole: 0.302573, acc:  47%] [D loss_mask: 0.571695, acc:  48%] [G loss: 36.013630] time: 0:28:56.883016\n[Epoch 444/80000] [D loss_whole: 0.279590, acc:  50%] [D loss_mask: 0.563589, acc:  52%] [G loss: 34.891960] time: 0:29:00.646351\n[Epoch 445/80000] [D loss_whole: 0.257466, acc:  54%] [D loss_mask: 0.574385, acc:  49%] [G loss: 34.002308] time: 0:29:04.124590\n[Epoch 446/80000] [D loss_whole: 0.254353, acc:  54%] [D loss_mask: 0.571391, acc:  46%] [G loss: 35.581947] time: 0:29:07.778017\n[Epoch 447/80000] [D loss_whole: 0.252110, acc:  54%] [D loss_mask: 0.569467, acc:  47%] [G loss: 33.934898] time: 0:29:11.487138\n[Epoch 448/80000] [D loss_whole: 0.251608, acc:  54%] [D loss_mask: 0.557218, acc:  51%] [G loss: 34.365707] time: 0:29:15.040044\n[Epoch 449/80000] [D loss_whole: 0.250793, acc:  56%] [D loss_mask: 0.532815, acc:  50%] [G loss: 33.046982] time: 0:29:18.700603\n[Epoch 450/80000] [D loss_whole: 0.255920, acc:  54%] [D loss_mask: 0.526371, acc:  48%] [G loss: 39.475372] time: 0:29:22.421111\n[Epoch 451/80000] [D loss_whole: 0.240339, acc:  61%] [D loss_mask: 0.487868, acc:  58%] [G loss: 33.487228] time: 0:29:25.922052\n[Epoch 452/80000] [D loss_whole: 0.295136, acc:  51%] [D loss_mask: 0.561670, acc:  50%] [G loss: 36.571423] time: 0:29:29.546414\n[Epoch 453/80000] [D loss_whole: 0.397349, acc:  48%] [D loss_mask: 0.647415, acc:  42%] [G loss: 39.572651] time: 0:29:33.237244\n[Epoch 454/80000] [D loss_whole: 0.337065, acc:  54%] [D loss_mask: 0.655235, acc:  45%] [G loss: 35.552784] time: 0:29:36.680592\n[Epoch 455/80000] [D loss_whole: 0.256506, acc:  54%] [D loss_mask: 0.586820, acc:  46%] [G loss: 41.413486] time: 0:29:40.337896\n[Epoch 456/80000] [D loss_whole: 0.252828, acc:  54%] [D loss_mask: 0.503210, acc:  53%] [G loss: 33.378983] time: 0:29:44.053028\n[Epoch 457/80000] [D loss_whole: 0.250711, acc:  54%] [D loss_mask: 0.673783, acc:  48%] [G loss: 38.435928] time: 0:29:47.538455\n[Epoch 458/80000] [D loss_whole: 0.322612, acc:  53%] [D loss_mask: 1.214474, acc:  47%] [G loss: 34.809898] time: 0:29:51.190169\n[Epoch 459/80000] [D loss_whole: 0.311765, acc:  55%] [D loss_mask: 0.997298, acc:  50%] [G loss: 34.620850] time: 0:29:54.868626\n[Epoch 460/80000] [D loss_whole: 0.272542, acc:  54%] [D loss_mask: 0.677604, acc:  50%] [G loss: 35.834686] time: 0:29:58.402377\n[Epoch 461/80000] [D loss_whole: 0.246789, acc:  55%] [D loss_mask: 0.551950, acc:  44%] [G loss: 33.917515] time: 0:30:02.017404\n[Epoch 462/80000] [D loss_whole: 0.249851, acc:  53%] [D loss_mask: 0.534923, acc:  41%] [G loss: 35.108734] time: 0:30:05.683731\n[Epoch 463/80000] [D loss_whole: 0.242134, acc:  58%] [D loss_mask: 0.525010, acc:  47%] [G loss: 35.454414] time: 0:30:09.219899\n[Epoch 464/80000] [D loss_whole: 0.247273, acc:  57%] [D loss_mask: 0.531181, acc:  49%] [G loss: 34.977585] time: 0:30:12.853111\n[Epoch 465/80000] [D loss_whole: 0.242082, acc:  56%] [D loss_mask: 0.532043, acc:  49%] [G loss: 35.115471] time: 0:30:16.531744\n[Epoch 466/80000] [D loss_whole: 0.258513, acc:  52%] [D loss_mask: 0.554517, acc:  46%] [G loss: 35.576572] time: 0:30:20.186312\n[Epoch 467/80000] [D loss_whole: 0.245545, acc:  53%] [D loss_mask: 0.550761, acc:  46%] [G loss: 35.507671] time: 0:30:23.870637\n[Epoch 468/80000] [D loss_whole: 0.252622, acc:  53%] [D loss_mask: 0.546762, acc:  45%] [G loss: 34.184059] time: 0:30:27.343157\n[Epoch 469/80000] [D loss_whole: 0.266895, acc:  54%] [D loss_mask: 0.540105, acc:  51%] [G loss: 34.229149] time: 0:30:30.996060\n[Epoch 470/80000] [D loss_whole: 0.310078, acc:  49%] [D loss_mask: 0.545267, acc:  51%] [G loss: 33.351105] time: 0:30:34.704626\n[Epoch 471/80000] [D loss_whole: 0.370223, acc:  47%] [D loss_mask: 0.552558, acc:  50%] [G loss: 36.902252] time: 0:30:38.192262\n[Epoch 472/80000] [D loss_whole: 0.361871, acc:  46%] [D loss_mask: 0.524408, acc:  52%] [G loss: 32.967979] time: 0:30:41.839316\n[Epoch 473/80000] [D loss_whole: 0.307896, acc:  45%] [D loss_mask: 0.497587, acc:  52%] [G loss: 35.766804] time: 0:30:45.561787\n[Epoch 474/80000] [D loss_whole: 0.248780, acc:  56%] [D loss_mask: 0.523358, acc:  46%] [G loss: 35.128216] time: 0:30:49.057269\n[Epoch 475/80000] [D loss_whole: 0.251824, acc:  52%] [D loss_mask: 0.533353, acc:  46%] [G loss: 32.799126] time: 0:30:52.706002\n[Epoch 476/80000] [D loss_whole: 0.267639, acc:  53%] [D loss_mask: 0.549790, acc:  49%] [G loss: 34.729469] time: 0:30:56.383027\n[Epoch 477/80000] [D loss_whole: 0.303230, acc:  48%] [D loss_mask: 0.537048, acc:  50%] [G loss: 34.009079] time: 0:30:59.837677\n[Epoch 478/80000] [D loss_whole: 0.338897, acc:  50%] [D loss_mask: 0.523115, acc:  49%] [G loss: 36.492138] time: 0:31:03.448856\n[Epoch 479/80000] [D loss_whole: 0.304220, acc:  52%] [D loss_mask: 0.501604, acc:  56%] [G loss: 36.420475] time: 0:31:07.157383\n[Epoch 480/80000] [D loss_whole: 0.254463, acc:  54%] [D loss_mask: 0.522167, acc:  48%] [G loss: 32.185547] time: 0:31:10.726041\n[Epoch 481/80000] [D loss_whole: 0.258950, acc:  53%] [D loss_mask: 0.536258, acc:  45%] [G loss: 35.875214] time: 0:31:13.738191\n[Epoch 482/80000] [D loss_whole: 0.256519, acc:  54%] [D loss_mask: 0.509154, acc:  53%] [G loss: 36.623650] time: 0:31:17.330651\n[Epoch 483/80000] [D loss_whole: 0.247939, acc:  55%] [D loss_mask: 0.522867, acc:  45%] [G loss: 36.459518] time: 0:31:21.032349\n[Epoch 484/80000] [D loss_whole: 0.274551, acc:  51%] [D loss_mask: 0.532024, acc:  44%] [G loss: 35.924828] time: 0:31:24.571931\n[Epoch 485/80000] [D loss_whole: 0.256101, acc:  52%] [D loss_mask: 0.531079, acc:  48%] [G loss: 35.499962] time: 0:31:27.567729\n[Epoch 486/80000] [D loss_whole: 0.246816, acc:  56%] [D loss_mask: 0.523080, acc:  48%] [G loss: 35.833405] time: 0:31:31.141902\n[Epoch 487/80000] [D loss_whole: 0.249168, acc:  56%] [D loss_mask: 0.534954, acc:  46%] [G loss: 35.198311] time: 0:31:34.851337\n[Epoch 488/80000] [D loss_whole: 0.233767, acc:  58%] [D loss_mask: 0.494882, acc:  56%] [G loss: 33.422310] time: 0:31:38.435229\n[Epoch 489/80000] [D loss_whole: 0.345598, acc:  52%] [D loss_mask: 0.513881, acc:  50%] [G loss: 35.024918] time: 0:31:42.078062\n[Epoch 490/80000] [D loss_whole: 0.517867, acc:  51%] [D loss_mask: 0.534338, acc:  41%] [G loss: 34.600334] time: 0:31:45.779099\n[Epoch 491/80000] [D loss_whole: 0.523179, acc:  57%] [D loss_mask: 0.535861, acc:  46%] [G loss: 35.315701] time: 0:31:49.157750\n[Epoch 492/80000] [D loss_whole: 0.359839, acc:  59%] [D loss_mask: 0.541648, acc:  44%] [G loss: 35.255497] time: 0:31:52.789813\n[Epoch 493/80000] [D loss_whole: 0.274005, acc:  50%] [D loss_mask: 0.535860, acc:  48%] [G loss: 34.953331] time: 0:31:56.493537\n[Epoch 494/80000] [D loss_whole: 0.242886, acc:  55%] [D loss_mask: 0.552300, acc:  45%] [G loss: 33.130478] time: 0:31:59.875368\n[Epoch 495/80000] [D loss_whole: 0.270763, acc:  48%] [D loss_mask: 0.545065, acc:  46%] [G loss: 38.528255] time: 0:32:03.523701\n[Epoch 496/80000] [D loss_whole: 0.251467, acc:  52%] [D loss_mask: 0.499300, acc:  56%] [G loss: 36.585037] time: 0:32:07.202234\n[Epoch 497/80000] [D loss_whole: 0.342424, acc:  54%] [D loss_mask: 0.521162, acc:  48%] [G loss: 33.034668] time: 0:32:10.712135\n[Epoch 498/80000] [D loss_whole: 0.408469, acc:  53%] [D loss_mask: 0.560572, acc:  39%] [G loss: 36.598026] time: 0:32:14.361929\n[Epoch 499/80000] [D loss_whole: 0.284136, acc:  55%] [D loss_mask: 0.529454, acc:  43%] [G loss: 37.671234] time: 0:32:18.031695\n[Epoch 500/80000] [D loss_whole: 0.249045, acc:  55%] [D loss_mask: 0.534975, acc:  45%] [G loss: 34.290493] time: 0:32:21.538431\nINFO:tensorflow:Assets written to: saved_models/inpaint_net500/assets\n[Epoch 501/80000] [D loss_whole: 0.263561, acc:  54%] [D loss_mask: 0.523672, acc:  45%] [G loss: 32.800900] time: 0:32:38.623009\n[Epoch 502/80000] [D loss_whole: 0.258595, acc:  53%] [D loss_mask: 0.527225, acc:  48%] [G loss: 37.972076] time: 0:32:42.250716\n[Epoch 503/80000] [D loss_whole: 0.249095, acc:  57%] [D loss_mask: 0.525881, acc:  47%] [G loss: 33.274006] time: 0:32:45.893489\n[Epoch 504/80000] [D loss_whole: 0.254329, acc:  54%] [D loss_mask: 0.535899, acc:  47%] [G loss: 33.487286] time: 0:32:49.465783\n[Epoch 505/80000] [D loss_whole: 0.270629, acc:  54%] [D loss_mask: 0.584600, acc:  48%] [G loss: 34.331802] time: 0:32:53.115563\n[Epoch 506/80000] [D loss_whole: 0.267154, acc:  51%] [D loss_mask: 0.609787, acc:  45%] [G loss: 34.050407] time: 0:32:56.740074\n[Epoch 507/80000] [D loss_whole: 0.242854, acc:  57%] [D loss_mask: 0.578980, acc:  51%] [G loss: 34.011215] time: 0:33:00.407785\n[Epoch 508/80000] [D loss_whole: 0.241254, acc:  55%] [D loss_mask: 0.553209, acc:  46%] [G loss: 35.281071] time: 0:33:04.055634\n[Epoch 509/80000] [D loss_whole: 0.243444, acc:  55%] [D loss_mask: 0.541066, acc:  45%] [G loss: 33.342743] time: 0:33:07.707216\n[Epoch 510/80000] [D loss_whole: 0.248665, acc:  54%] [D loss_mask: 0.561471, acc:  46%] [G loss: 34.456875] time: 0:33:11.380510\n[Epoch 511/80000] [D loss_whole: 0.254460, acc:  54%] [D loss_mask: 0.592556, acc:  44%] [G loss: 38.719131] time: 0:33:15.065906\n[Epoch 512/80000] [D loss_whole: 0.264927, acc:  53%] [D loss_mask: 0.675639, acc:  49%] [G loss: 32.214035] time: 0:33:18.733124\n[Epoch 513/80000] [D loss_whole: 0.258158, acc:  54%] [D loss_mask: 0.749603, acc:  47%] [G loss: 35.216015] time: 0:33:22.414909\n[Epoch 514/80000] [D loss_whole: 0.241317, acc:  58%] [D loss_mask: 0.708847, acc:  48%] [G loss: 33.620586] time: 0:33:26.084053\n[Epoch 515/80000] [D loss_whole: 0.247683, acc:  54%] [D loss_mask: 0.613500, acc:  49%] [G loss: 33.776848] time: 0:33:29.757760\n[Epoch 516/80000] [D loss_whole: 0.249999, acc:  53%] [D loss_mask: 0.593584, acc:  46%] [G loss: 33.551380] time: 0:33:33.395678\n[Epoch 517/80000] [D loss_whole: 0.254947, acc:  54%] [D loss_mask: 0.560816, acc:  46%] [G loss: 34.233547] time: 0:33:37.053057\n[Epoch 518/80000] [D loss_whole: 0.281017, acc:  54%] [D loss_mask: 0.550280, acc:  49%] [G loss: 33.826557] time: 0:33:40.730028\n[Epoch 519/80000] [D loss_whole: 0.270219, acc:  60%] [D loss_mask: 0.540183, acc:  49%] [G loss: 31.886621] time: 0:33:44.384910\n[Epoch 520/80000] [D loss_whole: 0.237029, acc:  61%] [D loss_mask: 0.515740, acc:  50%] [G loss: 35.315571] time: 0:33:48.017115\n[Epoch 521/80000] [D loss_whole: 0.262540, acc:  50%] [D loss_mask: 0.540293, acc:  42%] [G loss: 37.789608] time: 0:33:51.682863\n[Epoch 522/80000] [D loss_whole: 0.263149, acc:  55%] [D loss_mask: 0.540210, acc:  44%] [G loss: 37.041115] time: 0:33:55.318558\n[Epoch 523/80000] [D loss_whole: 0.318161, acc:  48%] [D loss_mask: 0.472376, acc:  58%] [G loss: 48.297344] time: 0:33:58.972963\n[Epoch 524/80000] [D loss_whole: 0.245867, acc:  61%] [D loss_mask: 0.651189, acc:  52%] [G loss: 54.410450] time: 0:34:02.620084\n[Epoch 525/80000] [D loss_whole: 0.452757, acc:  56%] [D loss_mask: 3.179506, acc:  48%] [G loss: 53.745495] time: 0:34:06.256901\n[Epoch 526/80000] [D loss_whole: 0.534674, acc:  55%] [D loss_mask: 2.153858, acc:  56%] [G loss: 46.511932] time: 0:34:09.952786\n[Epoch 527/80000] [D loss_whole: 0.292279, acc:  52%] [D loss_mask: 1.634805, acc:  60%] [G loss: 48.840752] time: 0:34:13.634196\n[Epoch 528/80000] [D loss_whole: 0.651320, acc:  45%] [D loss_mask: 1.490574, acc:  57%] [G loss: 41.476505] time: 0:34:17.301561\n[Epoch 529/80000] [D loss_whole: 0.660738, acc:  44%] [D loss_mask: 0.710635, acc:  53%] [G loss: 40.660110] time: 0:34:20.931624\n[Epoch 530/80000] [D loss_whole: 0.285369, acc:  54%] [D loss_mask: 0.613438, acc:  50%] [G loss: 45.158714] time: 0:34:24.624648\n[Epoch 531/80000] [D loss_whole: 0.261336, acc:  54%] [D loss_mask: 0.547636, acc:  49%] [G loss: 39.959476] time: 0:34:28.318962\n[Epoch 532/80000] [D loss_whole: 0.308470, acc:  46%] [D loss_mask: 0.524776, acc:  47%] [G loss: 39.260212] time: 0:34:32.005556\n[Epoch 533/80000] [D loss_whole: 0.271431, acc:  53%] [D loss_mask: 0.534431, acc:  47%] [G loss: 38.901165] time: 0:34:35.680080\n[Epoch 534/80000] [D loss_whole: 0.240333, acc:  53%] [D loss_mask: 0.538023, acc:  45%] [G loss: 40.117840] time: 0:34:39.405826\n[Epoch 535/80000] [D loss_whole: 0.241578, acc:  55%] [D loss_mask: 0.531885, acc:  46%] [G loss: 36.632843] time: 0:34:43.118461\n[Epoch 536/80000] [D loss_whole: 0.233904, acc:  60%] [D loss_mask: 0.538333, acc:  44%] [G loss: 37.607861] time: 0:34:46.770428\n[Epoch 537/80000] [D loss_whole: 0.226689, acc:  60%] [D loss_mask: 0.491526, acc:  57%] [G loss: 38.568962] time: 0:34:50.419983\n[Epoch 538/80000] [D loss_whole: 0.310999, acc:  54%] [D loss_mask: 0.581652, acc:  59%] [G loss: 37.811596] time: 0:34:54.046478\n[Epoch 539/80000] [D loss_whole: 0.292510, acc:  56%] [D loss_mask: 0.567297, acc:  44%] [G loss: 37.387806] time: 0:34:57.706619\n[Epoch 540/80000] [D loss_whole: 0.240868, acc:  57%] [D loss_mask: 0.539919, acc:  42%] [G loss: 35.802067] time: 0:35:01.344597\n[Epoch 541/80000] [D loss_whole: 0.231338, acc:  63%] [D loss_mask: 0.522622, acc:  46%] [G loss: 37.890896] time: 0:35:04.993470\n[Epoch 542/80000] [D loss_whole: 0.222961, acc:  63%] [D loss_mask: 0.513537, acc:  51%] [G loss: 35.866673] time: 0:35:08.668191\n[Epoch 543/80000] [D loss_whole: 0.262261, acc:  58%] [D loss_mask: 0.522307, acc:  52%] [G loss: 36.312042] time: 0:35:12.326956\n[Epoch 544/80000] [D loss_whole: 0.287224, acc:  54%] [D loss_mask: 0.535296, acc:  47%] [G loss: 38.302589] time: 0:35:16.058361\n[Epoch 545/80000] [D loss_whole: 0.247308, acc:  56%] [D loss_mask: 0.524951, acc:  51%] [G loss: 34.949932] time: 0:35:19.697426\n[Epoch 546/80000] [D loss_whole: 0.225270, acc:  61%] [D loss_mask: 0.515170, acc:  48%] [G loss: 34.795956] time: 0:35:23.364371\n[Epoch 547/80000] [D loss_whole: 0.234588, acc:  60%] [D loss_mask: 0.489390, acc:  56%] [G loss: 34.297726] time: 0:35:27.030615\n[Epoch 548/80000] [D loss_whole: 0.270775, acc:  57%] [D loss_mask: 0.525201, acc:  57%] [G loss: 34.678577] time: 0:35:30.686035\n[Epoch 549/80000] [D loss_whole: 0.276748, acc:  55%] [D loss_mask: 0.544483, acc:  48%] [G loss: 38.033142] time: 0:35:34.352237\n[Epoch 550/80000] [D loss_whole: 0.233555, acc:  62%] [D loss_mask: 0.482618, acc:  58%] [G loss: 37.680351] time: 0:35:38.029353\n[Epoch 551/80000] [D loss_whole: 0.279706, acc:  60%] [D loss_mask: 0.506614, acc:  62%] [G loss: 37.924789] time: 0:35:41.706137\n[Epoch 552/80000] [D loss_whole: 0.338793, acc:  56%] [D loss_mask: 0.535547, acc:  50%] [G loss: 36.004303] time: 0:35:45.373320\n[Epoch 553/80000] [D loss_whole: 0.330233, acc:  49%] [D loss_mask: 0.536531, acc:  47%] [G loss: 38.527676] time: 0:35:49.036112\n[Epoch 554/80000] [D loss_whole: 0.263072, acc:  50%] [D loss_mask: 0.528759, acc:  45%] [G loss: 39.130703] time: 0:35:52.671998\n[Epoch 555/80000] [D loss_whole: 0.241841, acc:  62%] [D loss_mask: 0.522168, acc:  49%] [G loss: 36.417107] time: 0:35:56.341317\n[Epoch 556/80000] [D loss_whole: 0.264886, acc:  64%] [D loss_mask: 0.522666, acc:  48%] [G loss: 35.855347] time: 0:36:00.015470\n[Epoch 557/80000] [D loss_whole: 0.256685, acc:  59%] [D loss_mask: 0.529390, acc:  46%] [G loss: 36.144466] time: 0:36:03.690012\n[Epoch 558/80000] [D loss_whole: 0.249324, acc:  56%] [D loss_mask: 0.529424, acc:  48%] [G loss: 34.825912] time: 0:36:07.346148\n[Epoch 559/80000] [D loss_whole: 0.235156, acc:  61%] [D loss_mask: 0.518751, acc:  47%] [G loss: 36.227470] time: 0:36:10.989323\n[Epoch 560/80000] [D loss_whole: 0.233277, acc:  61%] [D loss_mask: 0.531271, acc:  44%] [G loss: 37.669472] time: 0:36:14.657971\n[Epoch 561/80000] [D loss_whole: 0.230208, acc:  62%] [D loss_mask: 0.515821, acc:  50%] [G loss: 38.321568] time: 0:36:18.359243\n[Epoch 562/80000] [D loss_whole: 0.226005, acc:  61%] [D loss_mask: 0.525143, acc:  45%] [G loss: 36.832054] time: 0:36:22.148717\n[Epoch 563/80000] [D loss_whole: 0.226535, acc:  60%] [D loss_mask: 0.507816, acc:  53%] [G loss: 35.156506] time: 0:36:25.839306\n[Epoch 564/80000] [D loss_whole: 0.237725, acc:  57%] [D loss_mask: 0.528184, acc:  48%] [G loss: 35.283684] time: 0:36:29.602162\n[Epoch 565/80000] [D loss_whole: 0.238233, acc:  57%] [D loss_mask: 0.528074, acc:  48%] [G loss: 34.173786] time: 0:36:33.265821\n[Epoch 566/80000] [D loss_whole: 0.232945, acc:  59%] [D loss_mask: 0.528699, acc:  44%] [G loss: 34.093971] time: 0:36:36.936232\n[Epoch 567/80000] [D loss_whole: 0.228293, acc:  63%] [D loss_mask: 0.515440, acc:  51%] [G loss: 32.626343] time: 0:36:40.592258\n[Epoch 568/80000] [D loss_whole: 0.236886, acc:  61%] [D loss_mask: 0.523972, acc:  49%] [G loss: 32.412239] time: 0:36:44.242137\n[Epoch 569/80000] [D loss_whole: 0.231059, acc:  62%] [D loss_mask: 0.518853, acc:  50%] [G loss: 33.234234] time: 0:36:47.864523\n[Epoch 570/80000] [D loss_whole: 0.232848, acc:  61%] [D loss_mask: 0.507192, acc:  51%] [G loss: 34.430725] time: 0:36:51.514649\n[Epoch 571/80000] [D loss_whole: 0.229896, acc:  63%] [D loss_mask: 0.515325, acc:  52%] [G loss: 37.050884] time: 0:36:55.152621\n[Epoch 572/80000] [D loss_whole: 0.233624, acc:  60%] [D loss_mask: 0.532485, acc:  46%] [G loss: 35.433891] time: 0:36:58.822199\n[Epoch 573/80000] [D loss_whole: 0.234004, acc:  62%] [D loss_mask: 0.517362, acc:  49%] [G loss: 36.097172] time: 0:37:02.465852\n[Epoch 574/80000] [D loss_whole: 0.225687, acc:  64%] [D loss_mask: 0.520971, acc:  48%] [G loss: 37.024208] time: 0:37:06.155203\n[Epoch 575/80000] [D loss_whole: 0.234319, acc:  61%] [D loss_mask: 0.532474, acc:  46%] [G loss: 33.603321] time: 0:37:09.871064\n[Epoch 576/80000] [D loss_whole: 0.246708, acc:  59%] [D loss_mask: 0.539125, acc:  44%] [G loss: 35.699287] time: 0:37:13.547038\n[Epoch 577/80000] [D loss_whole: 0.255528, acc:  58%] [D loss_mask: 0.503676, acc:  55%] [G loss: 36.767712] time: 0:37:17.229183\n[Epoch 578/80000] [D loss_whole: 0.229249, acc:  65%] [D loss_mask: 0.515039, acc:  53%] [G loss: 35.255928] time: 0:37:20.908506\n[Epoch 579/80000] [D loss_whole: 0.229629, acc:  61%] [D loss_mask: 0.514439, acc:  51%] [G loss: 32.029560] time: 0:37:24.580002\n[Epoch 580/80000] [D loss_whole: 0.247545, acc:  56%] [D loss_mask: 0.532813, acc:  44%] [G loss: 32.911819] time: 0:37:28.258471\n[Epoch 581/80000] [D loss_whole: 0.228946, acc:  61%] [D loss_mask: 0.523671, acc:  48%] [G loss: 34.875900] time: 0:37:31.927858\n[Epoch 582/80000] [D loss_whole: 0.224728, acc:  62%] [D loss_mask: 0.499473, acc:  52%] [G loss: 35.420658] time: 0:37:35.588577\n[Epoch 583/80000] [D loss_whole: 0.241484, acc:  61%] [D loss_mask: 0.492086, acc:  55%] [G loss: 33.875145] time: 0:37:39.270831\n[Epoch 584/80000] [D loss_whole: 0.288565, acc:  55%] [D loss_mask: 0.537802, acc:  46%] [G loss: 35.678421] time: 0:37:42.936514\n[Epoch 585/80000] [D loss_whole: 0.264041, acc:  60%] [D loss_mask: 0.520423, acc:  52%] [G loss: 38.042969] time: 0:37:46.599597\n[Epoch 586/80000] [D loss_whole: 0.255661, acc:  57%] [D loss_mask: 0.529169, acc:  43%] [G loss: 34.468330] time: 0:37:50.263447\n[Epoch 587/80000] [D loss_whole: 0.242847, acc:  55%] [D loss_mask: 0.504428, acc:  55%] [G loss: 34.206863] time: 0:37:53.958009\n[Epoch 588/80000] [D loss_whole: 0.243903, acc:  55%] [D loss_mask: 0.529214, acc:  48%] [G loss: 35.382446] time: 0:37:57.630058\n[Epoch 589/80000] [D loss_whole: 0.243673, acc:  57%] [D loss_mask: 0.546044, acc:  46%] [G loss: 32.844440] time: 0:38:01.315803\n[Epoch 590/80000] [D loss_whole: 0.268644, acc:  53%] [D loss_mask: 0.535474, acc:  45%] [G loss: 33.125534] time: 0:38:04.988484\n[Epoch 591/80000] [D loss_whole: 0.348224, acc:  48%] [D loss_mask: 0.537552, acc:  41%] [G loss: 36.714508] time: 0:38:08.704035\n[Epoch 592/80000] [D loss_whole: 0.486688, acc:  51%] [D loss_mask: 0.517067, acc:  46%] [G loss: 33.004494] time: 0:38:12.393838\n[Epoch 593/80000] [D loss_whole: 0.519591, acc:  50%] [D loss_mask: 0.498605, acc:  54%] [G loss: 32.073475] time: 0:38:16.060398\n[Epoch 594/80000] [D loss_whole: 0.418408, acc:  47%] [D loss_mask: 0.526909, acc:  48%] [G loss: 36.462883] time: 0:38:19.724600\n[Epoch 595/80000] [D loss_whole: 0.297478, acc:  49%] [D loss_mask: 0.536117, acc:  45%] [G loss: 34.967796] time: 0:38:23.400963\n[Epoch 596/80000] [D loss_whole: 0.278671, acc:  51%] [D loss_mask: 0.537187, acc:  43%] [G loss: 33.334763] time: 0:38:27.067500\n[Epoch 597/80000] [D loss_whole: 0.275953, acc:  55%] [D loss_mask: 0.497468, acc:  53%] [G loss: 34.016182] time: 0:38:30.726032\n[Epoch 598/80000] [D loss_whole: 0.231170, acc:  62%] [D loss_mask: 0.512148, acc:  49%] [G loss: 35.712643] time: 0:38:34.380230\n[Epoch 599/80000] [D loss_whole: 0.235554, acc:  57%] [D loss_mask: 0.491071, acc:  55%] [G loss: 34.655552] time: 0:38:38.079725\n[Epoch 600/80000] [D loss_whole: 0.322931, acc:  50%] [D loss_mask: 0.516516, acc:  54%] [G loss: 33.429901] time: 0:38:41.756180\nINFO:tensorflow:Assets written to: saved_models/inpaint_net600/assets\n[Epoch 601/80000] [D loss_whole: 0.350043, acc:  51%] [D loss_mask: 0.522880, acc:  49%] [G loss: 35.973930] time: 0:38:59.052961\n[Epoch 602/80000] [D loss_whole: 0.326393, acc:  45%] [D loss_mask: 0.550799, acc:  45%] [G loss: 36.499790] time: 0:39:02.593687\n[Epoch 603/80000] [D loss_whole: 0.239565, acc:  58%] [D loss_mask: 0.529078, acc:  49%] [G loss: 35.303337] time: 0:39:05.963650\n[Epoch 604/80000] [D loss_whole: 0.270092, acc:  57%] [D loss_mask: 0.530011, acc:  45%] [G loss: 34.233387] time: 0:39:09.228552\n[Epoch 605/80000] [D loss_whole: 0.269732, acc:  57%] [D loss_mask: 0.518946, acc:  47%] [G loss: 32.696907] time: 0:39:12.927087\n[Epoch 606/80000] [D loss_whole: 0.226257, acc:  62%] [D loss_mask: 0.480259, acc:  55%] [G loss: 32.379906] time: 0:39:16.601178\n[Epoch 607/80000] [D loss_whole: 0.234807, acc:  58%] [D loss_mask: 0.521362, acc:  50%] [G loss: 34.514637] time: 0:39:20.286474\n[Epoch 608/80000] [D loss_whole: 0.236320, acc:  58%] [D loss_mask: 0.523740, acc:  49%] [G loss: 36.270378] time: 0:39:23.808249\n[Epoch 609/80000] [D loss_whole: 0.229619, acc:  62%] [D loss_mask: 0.500360, acc:  55%] [G loss: 34.561440] time: 0:39:27.370880\n[Epoch 610/80000] [D loss_whole: 0.265796, acc:  54%] [D loss_mask: 0.564398, acc:  47%] [G loss: 34.545376] time: 0:39:30.808849\n[Epoch 611/80000] [D loss_whole: 0.235330, acc:  59%] [D loss_mask: 0.557385, acc:  44%] [G loss: 35.617466] time: 0:39:34.210086\n[Epoch 612/80000] [D loss_whole: 0.265699, acc:  56%] [D loss_mask: 0.537620, acc:  49%] [G loss: 33.868706] time: 0:39:37.486531\n[Epoch 613/80000] [D loss_whole: 0.267453, acc:  54%] [D loss_mask: 0.520546, acc:  49%] [G loss: 33.739639] time: 0:39:41.175345\n[Epoch 614/80000] [D loss_whole: 0.283678, acc:  52%] [D loss_mask: 0.518269, acc:  47%] [G loss: 33.578075] time: 0:39:44.885201\n[Epoch 615/80000] [D loss_whole: 0.273948, acc:  54%] [D loss_mask: 0.505592, acc:  52%] [G loss: 33.463284] time: 0:39:48.540671\n[Epoch 616/80000] [D loss_whole: 0.278319, acc:  50%] [D loss_mask: 0.543184, acc:  45%] [G loss: 34.587666] time: 0:39:52.054757\n[Epoch 617/80000] [D loss_whole: 0.285951, acc:  50%] [D loss_mask: 0.513437, acc:  51%] [G loss: 37.137478] time: 0:39:55.427270\n[Epoch 618/80000] [D loss_whole: 0.314363, acc:  47%] [D loss_mask: 0.551669, acc:  49%] [G loss: 35.573627] time: 0:39:58.660407\n[Epoch 619/80000] [D loss_whole: 0.347892, acc:  48%] [D loss_mask: 0.544135, acc:  43%] [G loss: 35.762875] time: 0:40:02.334842\n[Epoch 620/80000] [D loss_whole: 0.327075, acc:  55%] [D loss_mask: 0.524188, acc:  45%] [G loss: 32.358799] time: 0:40:06.005747\n[Epoch 621/80000] [D loss_whole: 0.274253, acc:  58%] [D loss_mask: 0.524900, acc:  42%] [G loss: 32.579613] time: 0:40:09.656540\n[Epoch 622/80000] [D loss_whole: 0.254664, acc:  55%] [D loss_mask: 0.522852, acc:  47%] [G loss: 32.491806] time: 0:40:13.203537\n[Epoch 623/80000] [D loss_whole: 0.235240, acc:  60%] [D loss_mask: 0.493395, acc:  54%] [G loss: 35.801544] time: 0:40:16.772541\n[Epoch 624/80000] [D loss_whole: 0.248835, acc:  56%] [D loss_mask: 0.553588, acc:  49%] [G loss: 33.418686] time: 0:40:20.362900\n[Epoch 625/80000] [D loss_whole: 0.244684, acc:  58%] [D loss_mask: 0.540269, acc:  43%] [G loss: 35.591034] time: 0:40:24.000295\n[Epoch 626/80000] [D loss_whole: 0.256850, acc:  55%] [D loss_mask: 0.538254, acc:  42%] [G loss: 35.156265] time: 0:40:27.666843\n[Epoch 627/80000] [D loss_whole: 0.280429, acc:  51%] [D loss_mask: 0.536944, acc:  40%] [G loss: 34.147263] time: 0:40:31.327408\n[Epoch 628/80000] [D loss_whole: 0.313839, acc:  52%] [D loss_mask: 0.545591, acc:  47%] [G loss: 34.357018] time: 0:40:34.860145\n[Epoch 629/80000] [D loss_whole: 0.342930, acc:  54%] [D loss_mask: 0.509774, acc:  58%] [G loss: 34.885166] time: 0:40:38.423774\n[Epoch 630/80000] [D loss_whole: 0.303206, acc:  52%] [D loss_mask: 0.512899, acc:  49%] [G loss: 34.275730] time: 0:40:41.910666\n[Epoch 631/80000] [D loss_whole: 0.266911, acc:  51%] [D loss_mask: 0.532767, acc:  42%] [G loss: 32.461075] time: 0:40:45.464169\n[Epoch 632/80000] [D loss_whole: 0.273699, acc:  50%] [D loss_mask: 0.532918, acc:  44%] [G loss: 33.049751] time: 0:40:48.892203\n[Epoch 633/80000] [D loss_whole: 0.256256, acc:  55%] [D loss_mask: 0.480376, acc:  61%] [G loss: 33.791142] time: 0:40:52.495416\n[Epoch 634/80000] [D loss_whole: 0.239540, acc:  58%] [D loss_mask: 0.517082, acc:  52%] [G loss: 35.973866] time: 0:40:55.887200\n[Epoch 635/80000] [D loss_whole: 0.256423, acc:  54%] [D loss_mask: 0.522521, acc:  50%] [G loss: 33.036484] time: 0:40:59.420671\n[Epoch 636/80000] [D loss_whole: 0.264877, acc:  51%] [D loss_mask: 0.535853, acc:  44%] [G loss: 34.188869] time: 0:41:02.867408\n[Epoch 637/80000] [D loss_whole: 0.279523, acc:  55%] [D loss_mask: 0.530002, acc:  46%] [G loss: 34.029919] time: 0:41:06.496751\n[Epoch 638/80000] [D loss_whole: 0.290460, acc:  54%] [D loss_mask: 0.529680, acc:  45%] [G loss: 33.786797] time: 0:41:09.928849\n[Epoch 639/80000] [D loss_whole: 0.271758, acc:  52%] [D loss_mask: 0.498467, acc:  54%] [G loss: 33.668537] time: 0:41:13.267806\n[Epoch 640/80000] [D loss_whole: 0.262417, acc:  52%] [D loss_mask: 0.540856, acc:  49%] [G loss: 33.291458] time: 0:41:16.918252\n[Epoch 641/80000] [D loss_whole: 0.250972, acc:  55%] [D loss_mask: 0.537731, acc:  45%] [G loss: 32.932743] time: 0:41:20.602318\n[Epoch 642/80000] [D loss_whole: 0.263317, acc:  55%] [D loss_mask: 0.533995, acc:  46%] [G loss: 31.208147] time: 0:41:24.293688\n[Epoch 643/80000] [D loss_whole: 0.264466, acc:  52%] [D loss_mask: 0.503742, acc:  53%] [G loss: 33.824493] time: 0:41:27.992229\n[Epoch 644/80000] [D loss_whole: 0.248914, acc:  55%] [D loss_mask: 0.531657, acc:  48%] [G loss: 32.399433] time: 0:41:31.546962\n[Epoch 645/80000] [D loss_whole: 0.233769, acc:  61%] [D loss_mask: 0.500937, acc:  54%] [G loss: 35.798447] time: 0:41:35.112904\n[Epoch 646/80000] [D loss_whole: 0.256863, acc:  52%] [D loss_mask: 0.533666, acc:  45%] [G loss: 33.817352] time: 0:41:38.574905\n[Epoch 647/80000] [D loss_whole: 0.241495, acc:  60%] [D loss_mask: 0.507410, acc:  52%] [G loss: 35.374958] time: 0:41:42.145219\n[Epoch 648/80000] [D loss_whole: 0.243244, acc:  58%] [D loss_mask: 0.531056, acc:  45%] [G loss: 34.600464] time: 0:41:45.586758\n[Epoch 649/80000] [D loss_whole: 0.250387, acc:  55%] [D loss_mask: 0.524833, acc:  47%] [G loss: 33.817921] time: 0:41:48.872067\n[Epoch 650/80000] [D loss_whole: 0.244416, acc:  56%] [D loss_mask: 0.528565, acc:  47%] [G loss: 34.254055] time: 0:41:52.496550\n[Epoch 651/80000] [D loss_whole: 0.261378, acc:  51%] [D loss_mask: 0.528424, acc:  46%] [G loss: 34.719128] time: 0:41:56.151863\n[Epoch 652/80000] [D loss_whole: 0.262148, acc:  52%] [D loss_mask: 0.503381, acc:  53%] [G loss: 33.331161] time: 0:41:59.903850\n[Epoch 653/80000] [D loss_whole: 0.259635, acc:  53%] [D loss_mask: 0.514571, acc:  47%] [G loss: 33.498932] time: 0:42:03.582761\n[Epoch 654/80000] [D loss_whole: 0.243746, acc:  58%] [D loss_mask: 0.534693, acc:  39%] [G loss: 35.687618] time: 0:42:07.139261\n[Epoch 655/80000] [D loss_whole: 0.253081, acc:  61%] [D loss_mask: 0.524913, acc:  42%] [G loss: 33.081390] time: 0:42:10.519390\n[Epoch 656/80000] [D loss_whole: 0.282138, acc:  56%] [D loss_mask: 0.526690, acc:  42%] [G loss: 33.178463] time: 0:42:13.772711\n[Epoch 657/80000] [D loss_whole: 0.253257, acc:  59%] [D loss_mask: 0.506092, acc:  51%] [G loss: 31.330673] time: 0:42:17.440943\n[Epoch 658/80000] [D loss_whole: 0.249557, acc:  54%] [D loss_mask: 0.522801, acc:  45%] [G loss: 33.225273] time: 0:42:21.112329\n[Epoch 659/80000] [D loss_whole: 0.242906, acc:  56%] [D loss_mask: 0.507187, acc:  54%] [G loss: 34.055370] time: 0:42:24.750910\n[Epoch 660/80000] [D loss_whole: 0.242356, acc:  57%] [D loss_mask: 0.530770, acc:  49%] [G loss: 32.087406] time: 0:42:28.277436\n[Epoch 661/80000] [D loss_whole: 0.252295, acc:  57%] [D loss_mask: 0.527425, acc:  47%] [G loss: 31.953184] time: 0:42:31.648156\n[Epoch 662/80000] [D loss_whole: 0.255248, acc:  56%] [D loss_mask: 0.516453, acc:  45%] [G loss: 31.531561] time: 0:42:34.885583\n[Epoch 663/80000] [D loss_whole: 0.237730, acc:  59%] [D loss_mask: 0.507708, acc:  48%] [G loss: 36.100948] time: 0:42:38.571499\n[Epoch 664/80000] [D loss_whole: 0.250519, acc:  54%] [D loss_mask: 0.530737, acc:  43%] [G loss: 33.755245] time: 0:42:42.243931\n[Epoch 665/80000] [D loss_whole: 0.241685, acc:  58%] [D loss_mask: 0.503565, acc:  51%] [G loss: 32.428028] time: 0:42:45.936176\n[Epoch 666/80000] [D loss_whole: 0.252941, acc:  57%] [D loss_mask: 0.520759, acc:  47%] [G loss: 32.856606] time: 0:42:49.447773\n[Epoch 667/80000] [D loss_whole: 0.243480, acc:  61%] [D loss_mask: 0.531009, acc:  46%] [G loss: 31.714592] time: 0:42:52.998462\n[Epoch 668/80000] [D loss_whole: 0.245327, acc:  56%] [D loss_mask: 0.568245, acc:  47%] [G loss: 32.746914] time: 0:42:56.436389\n[Epoch 669/80000] [D loss_whole: 0.258435, acc:  56%] [D loss_mask: 0.548136, acc:  45%] [G loss: 32.949993] time: 0:43:00.030523\n[Epoch 670/80000] [D loss_whole: 0.309131, acc:  55%] [D loss_mask: 0.525244, acc:  51%] [G loss: 32.412460] time: 0:43:03.510105\n[Epoch 671/80000] [D loss_whole: 0.335790, acc:  53%] [D loss_mask: 0.490407, acc:  56%] [G loss: 33.162231] time: 0:43:07.118895\n[Epoch 672/80000] [D loss_whole: 0.448272, acc:  53%] [D loss_mask: 0.528194, acc:  41%] [G loss: 33.596813] time: 0:43:10.569455\n[Epoch 673/80000] [D loss_whole: 0.394882, acc:  58%] [D loss_mask: 0.548661, acc:  37%] [G loss: 31.907524] time: 0:43:14.110839\n[Epoch 674/80000] [D loss_whole: 0.288124, acc:  59%] [D loss_mask: 0.511380, acc:  49%] [G loss: 33.790295] time: 0:43:17.523068\n[Epoch 675/80000] [D loss_whole: 0.241557, acc:  57%] [D loss_mask: 0.522053, acc:  44%] [G loss: 32.426025] time: 0:43:21.068534\n[Epoch 676/80000] [D loss_whole: 0.243141, acc:  57%] [D loss_mask: 0.528662, acc:  46%] [G loss: 33.565178] time: 0:43:24.506039\n[Epoch 677/80000] [D loss_whole: 0.254486, acc:  53%] [D loss_mask: 0.530943, acc:  45%] [G loss: 33.695667] time: 0:43:28.142434\n[Epoch 678/80000] [D loss_whole: 0.272903, acc:  52%] [D loss_mask: 0.525156, acc:  45%] [G loss: 30.130556] time: 0:43:31.561971\n[Epoch 679/80000] [D loss_whole: 0.304398, acc:  49%] [D loss_mask: 0.499797, acc:  55%] [G loss: 31.813866] time: 0:43:35.115942\n[Epoch 680/80000] [D loss_whole: 0.308394, acc:  47%] [D loss_mask: 0.528482, acc:  47%] [G loss: 36.243675] time: 0:43:38.544314\n[Epoch 681/80000] [D loss_whole: 0.294275, acc:  50%] [D loss_mask: 0.526370, acc:  46%] [G loss: 32.912632] time: 0:43:42.099683\n[Epoch 682/80000] [D loss_whole: 0.274089, acc:  54%] [D loss_mask: 0.549412, acc:  49%] [G loss: 32.305553] time: 0:43:45.558407\n[Epoch 683/80000] [D loss_whole: 0.256978, acc:  56%] [D loss_mask: 0.584707, acc:  45%] [G loss: 33.291748] time: 0:43:49.142358\n[Epoch 684/80000] [D loss_whole: 0.244921, acc:  57%] [D loss_mask: 0.606573, acc:  48%] [G loss: 33.338772] time: 0:43:52.613238\n[Epoch 685/80000] [D loss_whole: 0.246784, acc:  57%] [D loss_mask: 0.643847, acc:  47%] [G loss: 36.154625] time: 0:43:55.984701\n[Epoch 686/80000] [D loss_whole: 0.265574, acc:  50%] [D loss_mask: 0.613340, acc:  43%] [G loss: 32.067001] time: 0:43:59.256282\n[Epoch 687/80000] [D loss_whole: 0.258155, acc:  52%] [D loss_mask: 0.589959, acc:  44%] [G loss: 31.261332] time: 0:44:02.971043\n[Epoch 688/80000] [D loss_whole: 0.251058, acc:  56%] [D loss_mask: 0.545661, acc:  44%] [G loss: 33.663834] time: 0:44:06.693024\n[Epoch 689/80000] [D loss_whole: 0.263798, acc:  55%] [D loss_mask: 0.513484, acc:  50%] [G loss: 31.776720] time: 0:44:10.398173\n[Epoch 690/80000] [D loss_whole: 0.263554, acc:  51%] [D loss_mask: 0.517803, acc:  46%] [G loss: 31.067642] time: 0:44:13.946286\n[Epoch 691/80000] [D loss_whole: 0.251409, acc:  56%] [D loss_mask: 0.516536, acc:  46%] [G loss: 33.898335] time: 0:44:17.447457\n[Epoch 692/80000] [D loss_whole: 0.262323, acc:  51%] [D loss_mask: 0.531054, acc:  41%] [G loss: 32.763367] time: 0:44:21.056516\n[Epoch 693/80000] [D loss_whole: 0.293873, acc:  52%] [D loss_mask: 0.545174, acc:  39%] [G loss: 33.554062] time: 0:44:24.687812\n[Epoch 694/80000] [D loss_whole: 0.240316, acc:  58%] [D loss_mask: 0.516906, acc:  45%] [G loss: 34.746208] time: 0:44:28.350976\n[Epoch 695/80000] [D loss_whole: 0.257193, acc:  53%] [D loss_mask: 0.543230, acc:  45%] [G loss: 32.888950] time: 0:44:32.014752\n[Epoch 696/80000] [D loss_whole: 0.241284, acc:  59%] [D loss_mask: 0.518012, acc:  42%] [G loss: 32.156147] time: 0:44:35.547535\n[Epoch 697/80000] [D loss_whole: 0.242129, acc:  57%] [D loss_mask: 0.526054, acc:  48%] [G loss: 33.918888] time: 0:44:39.104760\n[Epoch 698/80000] [D loss_whole: 0.309346, acc:  49%] [D loss_mask: 0.582556, acc:  41%] [G loss: 33.276707] time: 0:44:42.536280\n[Epoch 699/80000] [D loss_whole: 0.254308, acc:  57%] [D loss_mask: 0.552502, acc:  40%] [G loss: 35.685581] time: 0:44:46.074259\n[Epoch 700/80000] [D loss_whole: 0.253268, acc:  53%] [D loss_mask: 0.535295, acc:  43%] [G loss: 33.146679] time: 0:44:49.545402\nINFO:tensorflow:Assets written to: saved_models/inpaint_net700/assets\n[Epoch 701/80000] [D loss_whole: 0.271975, acc:  50%] [D loss_mask: 0.542837, acc:  40%] [G loss: 35.809769] time: 0:45:06.431987\n[Epoch 702/80000] [D loss_whole: 0.298366, acc:  47%] [D loss_mask: 0.522838, acc:  46%] [G loss: 34.034714] time: 0:45:10.106291\n[Epoch 703/80000] [D loss_whole: 0.340195, acc:  43%] [D loss_mask: 0.525382, acc:  46%] [G loss: 35.052528] time: 0:45:13.613351\n[Epoch 704/80000] [D loss_whole: 0.351158, acc:  42%] [D loss_mask: 0.530434, acc:  45%] [G loss: 32.023537] time: 0:45:16.949557\n[Epoch 705/80000] [D loss_whole: 0.331804, acc:  45%] [D loss_mask: 0.520286, acc:  49%] [G loss: 34.919216] time: 0:45:20.575946\n[Epoch 706/80000] [D loss_whole: 0.310686, acc:  51%] [D loss_mask: 0.520245, acc:  49%] [G loss: 34.023491] time: 0:45:24.252632\n[Epoch 707/80000] [D loss_whole: 0.294557, acc:  49%] [D loss_mask: 0.523844, acc:  44%] [G loss: 31.159740] time: 0:45:27.758165\n[Epoch 708/80000] [D loss_whole: 0.248142, acc:  57%] [D loss_mask: 0.497502, acc:  51%] [G loss: 31.024178] time: 0:45:31.042681\n[Epoch 709/80000] [D loss_whole: 0.265664, acc:  48%] [D loss_mask: 0.525526, acc:  43%] [G loss: 31.443840] time: 0:45:34.660051\n[Epoch 710/80000] [D loss_whole: 0.255243, acc:  52%] [D loss_mask: 0.530079, acc:  43%] [G loss: 33.513798] time: 0:45:38.285558\n[Epoch 711/80000] [D loss_whole: 0.256821, acc:  50%] [D loss_mask: 0.515856, acc:  47%] [G loss: 33.364426] time: 0:45:41.977647\n[Epoch 712/80000] [D loss_whole: 0.239037, acc:  59%] [D loss_mask: 0.512075, acc:  49%] [G loss: 30.446304] time: 0:45:45.472832\n[Epoch 713/80000] [D loss_whole: 0.252240, acc:  53%] [D loss_mask: 0.509358, acc:  50%] [G loss: 31.672857] time: 0:45:48.736427\n[Epoch 714/80000] [D loss_whole: 0.250197, acc:  54%] [D loss_mask: 0.519716, acc:  43%] [G loss: 33.827690] time: 0:45:52.344074\n[Epoch 715/80000] [D loss_whole: 0.281435, acc:  50%] [D loss_mask: 0.501806, acc:  50%] [G loss: 32.982662] time: 0:45:55.968409\n[Epoch 716/80000] [D loss_whole: 0.330513, acc:  53%] [D loss_mask: 0.536345, acc:  45%] [G loss: 33.376324] time: 0:45:59.636630\n[Epoch 717/80000] [D loss_whole: 0.281678, acc:  53%] [D loss_mask: 0.538595, acc:  39%] [G loss: 30.196800] time: 0:46:03.145731\n[Epoch 718/80000] [D loss_whole: 0.264070, acc:  54%] [D loss_mask: 0.524107, acc:  47%] [G loss: 31.539301] time: 0:46:06.433284\n[Epoch 719/80000] [D loss_whole: 0.298309, acc:  48%] [D loss_mask: 0.524123, acc:  49%] [G loss: 32.633842] time: 0:46:10.066983\n[Epoch 720/80000] [D loss_whole: 0.319733, acc:  47%] [D loss_mask: 0.534087, acc:  48%] [G loss: 31.457571] time: 0:46:13.720537\n[Epoch 721/80000] [D loss_whole: 0.317044, acc:  48%] [D loss_mask: 0.614147, acc:  51%] [G loss: 30.838177] time: 0:46:17.404829\n[Epoch 722/80000] [D loss_whole: 0.280427, acc:  47%] [D loss_mask: 0.828414, acc:  47%] [G loss: 34.080509] time: 0:46:21.072101\n[Epoch 723/80000] [D loss_whole: 0.261385, acc:  52%] [D loss_mask: 0.793006, acc:  43%] [G loss: 31.279474] time: 0:46:24.677095\n[Epoch 724/80000] [D loss_whole: 0.264811, acc:  48%] [D loss_mask: 0.641337, acc:  43%] [G loss: 32.039848] time: 0:46:28.224125\n[Epoch 725/80000] [D loss_whole: 0.271971, acc:  52%] [D loss_mask: 0.550060, acc:  50%] [G loss: 34.062565] time: 0:46:31.866361\n[Epoch 726/80000] [D loss_whole: 0.258385, acc:  52%] [D loss_mask: 0.503343, acc:  55%] [G loss: 31.661766] time: 0:46:35.558309\n[Epoch 727/80000] [D loss_whole: 0.303845, acc:  51%] [D loss_mask: 0.530339, acc:  44%] [G loss: 31.232904] time: 0:46:39.209256\n[Epoch 728/80000] [D loss_whole: 0.276064, acc:  52%] [D loss_mask: 0.531084, acc:  41%] [G loss: 32.392307] time: 0:46:42.859727\n[Epoch 729/80000] [D loss_whole: 0.267370, acc:  54%] [D loss_mask: 0.530209, acc:  40%] [G loss: 37.075703] time: 0:46:46.516780\n[Epoch 730/80000] [D loss_whole: 0.264053, acc:  51%] [D loss_mask: 0.529639, acc:  43%] [G loss: 29.955540] time: 0:46:49.980366\n[Epoch 731/80000] [D loss_whole: 0.264905, acc:  48%] [D loss_mask: 0.501888, acc:  48%] [G loss: 33.663422] time: 0:46:53.196941\n[Epoch 732/80000] [D loss_whole: 0.264405, acc:  49%] [D loss_mask: 0.534818, acc:  41%] [G loss: 34.262398] time: 0:46:56.818401\n[Epoch 733/80000] [D loss_whole: 0.258392, acc:  54%] [D loss_mask: 0.507558, acc:  50%] [G loss: 31.266472] time: 0:47:00.498017\n[Epoch 734/80000] [D loss_whole: 0.254131, acc:  52%] [D loss_mask: 0.514681, acc:  50%] [G loss: 32.666309] time: 0:47:04.111877\n[Epoch 735/80000] [D loss_whole: 0.276627, acc:  47%] [D loss_mask: 0.511109, acc:  46%] [G loss: 34.423706] time: 0:47:07.778510\n[Epoch 736/80000] [D loss_whole: 0.328635, acc:  46%] [D loss_mask: 0.539529, acc:  42%] [G loss: 30.499737] time: 0:47:11.438673\n[Epoch 737/80000] [D loss_whole: 0.267575, acc:  50%] [D loss_mask: 0.545034, acc:  36%] [G loss: 30.519161] time: 0:47:15.073648\n[Epoch 738/80000] [D loss_whole: 0.265833, acc:  55%] [D loss_mask: 0.502720, acc:  52%] [G loss: 32.621838] time: 0:47:18.725935\n[Epoch 739/80000] [D loss_whole: 0.264497, acc:  50%] [D loss_mask: 0.522766, acc:  45%] [G loss: 35.171612] time: 0:47:22.377296\n[Epoch 740/80000] [D loss_whole: 0.264444, acc:  48%] [D loss_mask: 0.525321, acc:  40%] [G loss: 32.224117] time: 0:47:25.982359\n[Epoch 741/80000] [D loss_whole: 0.275899, acc:  48%] [D loss_mask: 0.532197, acc:  40%] [G loss: 33.367054] time: 0:47:29.562769\n[Epoch 742/80000] [D loss_whole: 0.351014, acc:  51%] [D loss_mask: 0.517128, acc:  47%] [G loss: 31.208698] time: 0:47:33.175711\n[Epoch 743/80000] [D loss_whole: 0.345593, acc:  48%] [D loss_mask: 0.515297, acc:  48%] [G loss: 29.521318] time: 0:47:36.819751\n[Epoch 744/80000] [D loss_whole: 0.264193, acc:  52%] [D loss_mask: 0.503989, acc:  47%] [G loss: 32.800926] time: 0:47:40.462096\n[Epoch 745/80000] [D loss_whole: 0.289724, acc:  45%] [D loss_mask: 0.522032, acc:  45%] [G loss: 33.294674] time: 0:47:43.998694\n[Epoch 746/80000] [D loss_whole: 0.348608, acc:  48%] [D loss_mask: 0.590271, acc:  41%] [G loss: 32.310413] time: 0:47:47.655457\n[Epoch 747/80000] [D loss_whole: 0.282361, acc:  56%] [D loss_mask: 0.615518, acc:  41%] [G loss: 32.639622] time: 0:47:51.290459\n[Epoch 748/80000] [D loss_whole: 0.252603, acc:  53%] [D loss_mask: 0.549765, acc:  49%] [G loss: 31.569679] time: 0:47:54.824840\n[Epoch 749/80000] [D loss_whole: 0.257791, acc:  51%] [D loss_mask: 0.576093, acc:  45%] [G loss: 32.237679] time: 0:47:58.435789\n[Epoch 750/80000] [D loss_whole: 0.266641, acc:  46%] [D loss_mask: 0.574270, acc:  43%] [G loss: 30.965157] time: 0:48:02.082570\n[Epoch 751/80000] [D loss_whole: 0.275841, acc:  51%] [D loss_mask: 0.548512, acc:  42%] [G loss: 31.435768] time: 0:48:05.761285\n[Epoch 752/80000] [D loss_whole: 0.282092, acc:  47%] [D loss_mask: 0.525585, acc:  47%] [G loss: 31.840130] time: 0:48:09.408562\n[Epoch 753/80000] [D loss_whole: 0.284535, acc:  45%] [D loss_mask: 0.552604, acc:  41%] [G loss: 31.885330] time: 0:48:13.044743\n[Epoch 754/80000] [D loss_whole: 0.277362, acc:  48%] [D loss_mask: 0.525482, acc:  43%] [G loss: 31.213200] time: 0:48:16.698410\n[Epoch 755/80000] [D loss_whole: 0.253039, acc:  56%] [D loss_mask: 0.521594, acc:  47%] [G loss: 33.982235] time: 0:48:20.356274\n[Epoch 756/80000] [D loss_whole: 0.263532, acc:  48%] [D loss_mask: 0.523668, acc:  48%] [G loss: 29.975246] time: 0:48:23.954082\n[Epoch 757/80000] [D loss_whole: 0.244607, acc:  55%] [D loss_mask: 0.492715, acc:  57%] [G loss: 34.043747] time: 0:48:27.618761\n[Epoch 758/80000] [D loss_whole: 0.275025, acc:  50%] [D loss_mask: 0.513846, acc:  44%] [G loss: 32.729244] time: 0:48:31.124973\n[Epoch 759/80000] [D loss_whole: 0.274274, acc:  56%] [D loss_mask: 0.520811, acc:  42%] [G loss: 30.797945] time: 0:48:34.448388\n[Epoch 760/80000] [D loss_whole: 0.278204, acc:  54%] [D loss_mask: 0.523178, acc:  44%] [G loss: 31.524618] time: 0:48:38.078341\n[Epoch 761/80000] [D loss_whole: 0.266430, acc:  50%] [D loss_mask: 0.535043, acc:  43%] [G loss: 30.212976] time: 0:48:41.736716\n[Epoch 762/80000] [D loss_whole: 0.277585, acc:  50%] [D loss_mask: 0.538417, acc:  53%] [G loss: 33.895283] time: 0:48:45.242861\n[Epoch 763/80000] [D loss_whole: 0.296826, acc:  47%] [D loss_mask: 0.548331, acc:  56%] [G loss: 33.478729] time: 0:48:48.482983\n[Epoch 764/80000] [D loss_whole: 0.316348, acc:  45%] [D loss_mask: 0.551806, acc:  56%] [G loss: 33.862206] time: 0:48:52.110064\n[Epoch 765/80000] [D loss_whole: 0.318270, acc:  46%] [D loss_mask: 0.523594, acc:  52%] [G loss: 31.972382] time: 0:48:55.758019\n[Epoch 766/80000] [D loss_whole: 0.268351, acc:  52%] [D loss_mask: 0.547102, acc:  50%] [G loss: 31.356695] time: 0:48:59.304838\n[Epoch 767/80000] [D loss_whole: 0.266525, acc:  46%] [D loss_mask: 0.605978, acc:  44%] [G loss: 31.595158] time: 0:49:02.952180\n[Epoch 768/80000] [D loss_whole: 0.252316, acc:  52%] [D loss_mask: 0.637019, acc:  42%] [G loss: 32.131447] time: 0:49:06.610218\n[Epoch 769/80000] [D loss_whole: 0.263042, acc:  49%] [D loss_mask: 0.677372, acc:  45%] [G loss: 31.901957] time: 0:49:10.118339\n[Epoch 770/80000] [D loss_whole: 0.270064, acc:  52%] [D loss_mask: 0.675601, acc:  50%] [G loss: 36.266251] time: 0:49:13.418251\n[Epoch 771/80000] [D loss_whole: 0.241878, acc:  61%] [D loss_mask: 0.619962, acc:  53%] [G loss: 32.711086] time: 0:49:17.056345\n[Epoch 772/80000] [D loss_whole: 0.280006, acc:  50%] [D loss_mask: 0.588697, acc:  52%] [G loss: 30.781124] time: 0:49:20.725656\n[Epoch 773/80000] [D loss_whole: 0.276400, acc:  48%] [D loss_mask: 0.599266, acc:  43%] [G loss: 33.060673] time: 0:49:24.337898\n[Epoch 774/80000] [D loss_whole: 0.287616, acc:  52%] [D loss_mask: 0.654058, acc:  45%] [G loss: 32.742027] time: 0:49:27.998904\n[Epoch 775/80000] [D loss_whole: 0.278000, acc:  48%] [D loss_mask: 0.595195, acc:  46%] [G loss: 31.657146] time: 0:49:31.635295\n[Epoch 776/80000] [D loss_whole: 0.250829, acc:  53%] [D loss_mask: 0.532821, acc:  45%] [G loss: 31.640003] time: 0:49:35.313539\n[Epoch 777/80000] [D loss_whole: 0.269646, acc:  46%] [D loss_mask: 0.540124, acc:  37%] [G loss: 32.484074] time: 0:49:38.836611\n[Epoch 778/80000] [D loss_whole: 0.247024, acc:  54%] [D loss_mask: 0.512158, acc:  44%] [G loss: 32.546104] time: 0:49:42.042987\n[Epoch 779/80000] [D loss_whole: 0.261786, acc:  49%] [D loss_mask: 0.531757, acc:  39%] [G loss: 32.837757] time: 0:49:45.656701\n[Epoch 780/80000] [D loss_whole: 0.252562, acc:  52%] [D loss_mask: 0.513398, acc:  46%] [G loss: 31.074038] time: 0:49:49.358813\n[Epoch 781/80000] [D loss_whole: 0.280098, acc:  48%] [D loss_mask: 0.527272, acc:  42%] [G loss: 31.883999] time: 0:49:52.876365\n[Epoch 782/80000] [D loss_whole: 0.305717, acc:  45%] [D loss_mask: 0.531103, acc:  45%] [G loss: 30.913380] time: 0:49:56.176008\n[Epoch 783/80000] [D loss_whole: 0.297557, acc:  45%] [D loss_mask: 0.528890, acc:  45%] [G loss: 31.510586] time: 0:49:59.797366\n[Epoch 784/80000] [D loss_whole: 0.267852, acc:  49%] [D loss_mask: 0.518377, acc:  49%] [G loss: 31.901049] time: 0:50:03.429373\n[Epoch 785/80000] [D loss_whole: 0.243840, acc:  55%] [D loss_mask: 0.520045, acc:  48%] [G loss: 31.080128] time: 0:50:07.086007\n[Epoch 786/80000] [D loss_whole: 0.272826, acc:  46%] [D loss_mask: 0.520959, acc:  47%] [G loss: 33.216125] time: 0:50:10.766295\n[Epoch 787/80000] [D loss_whole: 0.276300, acc:  51%] [D loss_mask: 0.544999, acc:  42%] [G loss: 32.423832] time: 0:50:14.421896\n[Epoch 788/80000] [D loss_whole: 0.266901, acc:  47%] [D loss_mask: 0.550524, acc:  39%] [G loss: 31.555767] time: 0:50:18.089317\n[Epoch 789/80000] [D loss_whole: 0.244501, acc:  57%] [D loss_mask: 0.524485, acc:  43%] [G loss: 33.401222] time: 0:50:21.723349\n[Epoch 790/80000] [D loss_whole: 0.253212, acc:  52%] [D loss_mask: 0.549931, acc:  45%] [G loss: 30.395342] time: 0:50:25.298096\n[Epoch 791/80000] [D loss_whole: 0.270296, acc:  49%] [D loss_mask: 0.548661, acc:  36%] [G loss: 30.047737] time: 0:50:28.930898\n[Epoch 792/80000] [D loss_whole: 0.250378, acc:  55%] [D loss_mask: 0.525566, acc:  42%] [G loss: 30.083836] time: 0:50:32.533963\n[Epoch 793/80000] [D loss_whole: 0.235262, acc:  59%] [D loss_mask: 0.512313, acc:  49%] [G loss: 32.625889] time: 0:50:36.120679\n[Epoch 794/80000] [D loss_whole: 0.265035, acc:  51%] [D loss_mask: 0.545136, acc:  42%] [G loss: 32.420864] time: 0:50:39.728947\n[Epoch 795/80000] [D loss_whole: 0.252221, acc:  51%] [D loss_mask: 0.539022, acc:  41%] [G loss: 34.345646] time: 0:50:43.388240\n[Epoch 796/80000] [D loss_whole: 0.257309, acc:  49%] [D loss_mask: 0.538432, acc:  41%] [G loss: 30.842020] time: 0:50:47.023160\n[Epoch 797/80000] [D loss_whole: 0.263941, acc:  52%] [D loss_mask: 0.528665, acc:  41%] [G loss: 30.648315] time: 0:50:50.673979\n[Epoch 798/80000] [D loss_whole: 0.285712, acc:  48%] [D loss_mask: 0.521548, acc:  49%] [G loss: 30.667496] time: 0:50:54.253110\n[Epoch 799/80000] [D loss_whole: 0.318862, acc:  44%] [D loss_mask: 0.532657, acc:  46%] [G loss: 31.246727] time: 0:50:57.916996\n[Epoch 800/80000] [D loss_whole: 0.322730, acc:  43%] [D loss_mask: 0.548408, acc:  45%] [G loss: 31.360250] time: 0:51:01.444864\nINFO:tensorflow:Assets written to: saved_models/inpaint_net800/assets\n[Epoch 801/80000] [D loss_whole: 0.292340, acc:  46%] [D loss_mask: 0.567355, acc:  45%] [G loss: 32.154591] time: 0:51:18.292072\n[Epoch 802/80000] [D loss_whole: 0.296006, acc:  46%] [D loss_mask: 0.586942, acc:  44%] [G loss: 29.911251] time: 0:51:21.767953\n[Epoch 803/80000] [D loss_whole: 0.303505, acc:  49%] [D loss_mask: 0.572999, acc:  47%] [G loss: 33.158485] time: 0:51:24.877968\n[Epoch 804/80000] [D loss_whole: 0.266642, acc:  51%] [D loss_mask: 0.572797, acc:  48%] [G loss: 30.102411] time: 0:51:28.531735\n[Epoch 805/80000] [D loss_whole: 0.263173, acc:  52%] [D loss_mask: 0.563544, acc:  42%] [G loss: 31.628283] time: 0:51:32.195872\n[Epoch 806/80000] [D loss_whole: 0.268403, acc:  57%] [D loss_mask: 0.550071, acc:  46%] [G loss: 31.324995] time: 0:51:35.672319\n[Epoch 807/80000] [D loss_whole: 0.283606, acc:  47%] [D loss_mask: 0.543800, acc:  45%] [G loss: 30.319069] time: 0:51:39.294604\n[Epoch 808/80000] [D loss_whole: 0.297743, acc:  43%] [D loss_mask: 0.539366, acc:  44%] [G loss: 31.444382] time: 0:51:42.947832\n[Epoch 809/80000] [D loss_whole: 0.271782, acc:  49%] [D loss_mask: 0.528358, acc:  47%] [G loss: 32.570946] time: 0:51:46.302037\n[Epoch 810/80000] [D loss_whole: 0.268562, acc:  49%] [D loss_mask: 0.535458, acc:  52%] [G loss: 31.896479] time: 0:51:49.928245\n[Epoch 811/80000] [D loss_whole: 0.274321, acc:  50%] [D loss_mask: 0.530715, acc:  44%] [G loss: 31.227337] time: 0:51:53.594126\n[Epoch 812/80000] [D loss_whole: 0.301825, acc:  51%] [D loss_mask: 0.529929, acc:  46%] [G loss: 33.433899] time: 0:51:57.122513\n[Epoch 813/80000] [D loss_whole: 0.317304, acc:  50%] [D loss_mask: 0.532909, acc:  44%] [G loss: 30.727589] time: 0:52:00.123789\n[Epoch 814/80000] [D loss_whole: 0.281069, acc:  49%] [D loss_mask: 0.531196, acc:  49%] [G loss: 31.797827] time: 0:52:03.696776\n[Epoch 815/80000] [D loss_whole: 0.263339, acc:  51%] [D loss_mask: 0.527900, acc:  47%] [G loss: 30.783144] time: 0:52:07.396212\n[Epoch 816/80000] [D loss_whole: 0.256010, acc:  52%] [D loss_mask: 0.526152, acc:  53%] [G loss: 30.109102] time: 0:52:10.849167\n[Epoch 817/80000] [D loss_whole: 0.264734, acc:  49%] [D loss_mask: 0.519262, acc:  51%] [G loss: 31.072302] time: 0:52:14.469638\n[Epoch 818/80000] [D loss_whole: 0.250909, acc:  49%] [D loss_mask: 0.504725, acc:  52%] [G loss: 31.470934] time: 0:52:18.126728\n[Epoch 819/80000] [D loss_whole: 0.301010, acc:  45%] [D loss_mask: 0.536660, acc:  48%] [G loss: 32.980412] time: 0:52:21.569256\n[Epoch 820/80000] [D loss_whole: 0.269232, acc:  52%] [D loss_mask: 0.551313, acc:  46%] [G loss: 32.271461] time: 0:52:25.167537\n[Epoch 821/80000] [D loss_whole: 0.256989, acc:  50%] [D loss_mask: 0.583593, acc:  46%] [G loss: 31.907993] time: 0:52:28.848194\n[Epoch 822/80000] [D loss_whole: 0.260628, acc:  49%] [D loss_mask: 0.629675, acc:  45%] [G loss: 32.028618] time: 0:52:32.375945\n[Epoch 823/80000] [D loss_whole: 0.258245, acc:  52%] [D loss_mask: 0.579984, acc:  47%] [G loss: 30.834471] time: 0:52:35.996653\n[Epoch 824/80000] [D loss_whole: 0.247003, acc:  56%] [D loss_mask: 0.525649, acc:  50%] [G loss: 32.322235] time: 0:52:39.689564\n[Epoch 825/80000] [D loss_whole: 0.263896, acc:  45%] [D loss_mask: 0.513242, acc:  48%] [G loss: 31.761211] time: 0:52:43.170420\n[Epoch 826/80000] [D loss_whole: 0.245399, acc:  53%] [D loss_mask: 0.521286, acc:  43%] [G loss: 30.507673] time: 0:52:46.779016\n[Epoch 827/80000] [D loss_whole: 0.254391, acc:  49%] [D loss_mask: 0.547828, acc:  42%] [G loss: 31.476574] time: 0:52:50.455338\n[Epoch 828/80000] [D loss_whole: 0.256223, acc:  52%] [D loss_mask: 0.567842, acc:  45%] [G loss: 32.161018] time: 0:52:53.918232\n[Epoch 829/80000] [D loss_whole: 0.369613, acc:  54%] [D loss_mask: 0.811207, acc:  48%] [G loss: 32.291420] time: 0:52:57.556716\n[Epoch 830/80000] [D loss_whole: 0.386802, acc:  57%] [D loss_mask: 0.935930, acc:  51%] [G loss: 31.976986] time: 0:53:01.204908\n[Epoch 831/80000] [D loss_whole: 0.335788, acc:  57%] [D loss_mask: 0.987192, acc:  49%] [G loss: 33.226200] time: 0:53:04.578987\n[Epoch 832/80000] [D loss_whole: 0.263790, acc:  51%] [D loss_mask: 0.671040, acc:  48%] [G loss: 32.945587] time: 0:53:08.213571\n[Epoch 833/80000] [D loss_whole: 0.256759, acc:  51%] [D loss_mask: 0.550284, acc:  46%] [G loss: 29.956020] time: 0:53:11.908578\n[Epoch 834/80000] [D loss_whole: 0.250954, acc:  53%] [D loss_mask: 0.507843, acc:  48%] [G loss: 31.416210] time: 0:53:15.380599\n[Epoch 835/80000] [D loss_whole: 0.258641, acc:  50%] [D loss_mask: 0.527437, acc:  43%] [G loss: 31.158232] time: 0:53:19.021260\n[Epoch 836/80000] [D loss_whole: 0.254438, acc:  50%] [D loss_mask: 0.520154, acc:  46%] [G loss: 30.481771] time: 0:53:22.683630\n[Epoch 837/80000] [D loss_whole: 0.243759, acc:  56%] [D loss_mask: 0.498328, acc:  54%] [G loss: 30.860540] time: 0:53:26.185565\n[Epoch 838/80000] [D loss_whole: 0.254478, acc:  51%] [D loss_mask: 0.526217, acc:  48%] [G loss: 32.047085] time: 0:53:29.822704\n[Epoch 839/80000] [D loss_whole: 0.244790, acc:  53%] [D loss_mask: 0.529590, acc:  44%] [G loss: 33.385544] time: 0:53:33.485606\n[Epoch 840/80000] [D loss_whole: 0.265062, acc:  48%] [D loss_mask: 0.525877, acc:  45%] [G loss: 32.265636] time: 0:53:37.039676\n[Epoch 841/80000] [D loss_whole: 0.263459, acc:  47%] [D loss_mask: 0.530286, acc:  47%] [G loss: 29.468163] time: 0:53:40.721792\n[Epoch 842/80000] [D loss_whole: 0.262750, acc:  50%] [D loss_mask: 0.520290, acc:  50%] [G loss: 31.363207] time: 0:53:44.175297\n[Epoch 843/80000] [D loss_whole: 0.268510, acc:  49%] [D loss_mask: 0.536323, acc:  43%] [G loss: 31.445730] time: 0:53:47.782228\n[Epoch 844/80000] [D loss_whole: 0.294813, acc:  44%] [D loss_mask: 0.544346, acc:  36%] [G loss: 34.862701] time: 0:53:51.431771\n[Epoch 845/80000] [D loss_whole: 0.325148, acc:  46%] [D loss_mask: 0.519277, acc:  41%] [G loss: 34.202255] time: 0:53:54.942823\n[Epoch 846/80000] [D loss_whole: 0.320820, acc:  47%] [D loss_mask: 0.517123, acc:  45%] [G loss: 30.532751] time: 0:53:58.566531\n[Epoch 847/80000] [D loss_whole: 0.281401, acc:  44%] [D loss_mask: 0.526356, acc:  40%] [G loss: 30.218557] time: 0:54:02.245680\n[Epoch 848/80000] [D loss_whole: 0.257273, acc:  51%] [D loss_mask: 0.515926, acc:  48%] [G loss: 34.949554] time: 0:54:05.707845\n[Epoch 849/80000] [D loss_whole: 0.263832, acc:  54%] [D loss_mask: 0.515815, acc:  49%] [G loss: 32.878902] time: 0:54:09.359848\n[Epoch 850/80000] [D loss_whole: 0.242559, acc:  57%] [D loss_mask: 0.502312, acc:  52%] [G loss: 32.931553] time: 0:54:13.039059\n[Epoch 851/80000] [D loss_whole: 0.268630, acc:  51%] [D loss_mask: 0.500804, acc:  47%] [G loss: 31.356548] time: 0:54:16.517504\n[Epoch 852/80000] [D loss_whole: 0.361594, acc:  51%] [D loss_mask: 0.598878, acc:  44%] [G loss: 30.239550] time: 0:54:20.149879\n[Epoch 853/80000] [D loss_whole: 0.342174, acc:  56%] [D loss_mask: 0.602382, acc:  46%] [G loss: 30.633064] time: 0:54:23.823620\n[Epoch 854/80000] [D loss_whole: 0.271699, acc:  52%] [D loss_mask: 0.564498, acc:  43%] [G loss: 32.508736] time: 0:54:27.274660\n[Epoch 855/80000] [D loss_whole: 0.268403, acc:  50%] [D loss_mask: 0.529947, acc:  45%] [G loss: 31.753748] time: 0:54:30.890961\n[Epoch 856/80000] [D loss_whole: 0.257087, acc:  53%] [D loss_mask: 0.509789, acc:  53%] [G loss: 31.732832] time: 0:54:34.524140\n[Epoch 857/80000] [D loss_whole: 0.252751, acc:  54%] [D loss_mask: 0.515857, acc:  48%] [G loss: 32.275764] time: 0:54:38.064052\n[Epoch 858/80000] [D loss_whole: 0.244175, acc:  55%] [D loss_mask: 0.513620, acc:  50%] [G loss: 31.285442] time: 0:54:41.034410\n[Epoch 859/80000] [D loss_whole: 0.254264, acc:  51%] [D loss_mask: 0.516508, acc:  46%] [G loss: 28.974342] time: 0:54:44.622112\n[Epoch 860/80000] [D loss_whole: 0.253409, acc:  50%] [D loss_mask: 0.518472, acc:  42%] [G loss: 30.037542] time: 0:54:48.282045\n[Epoch 861/80000] [D loss_whole: 0.251518, acc:  53%] [D loss_mask: 0.519072, acc:  42%] [G loss: 31.825687] time: 0:54:51.717657\n[Epoch 862/80000] [D loss_whole: 0.248737, acc:  54%] [D loss_mask: 0.522523, acc:  42%] [G loss: 32.448399] time: 0:54:55.318258\n[Epoch 863/80000] [D loss_whole: 0.274129, acc:  48%] [D loss_mask: 0.531672, acc:  46%] [G loss: 30.165472] time: 0:54:58.978858\n[Epoch 864/80000] [D loss_whole: 0.293150, acc:  47%] [D loss_mask: 0.542935, acc:  53%] [G loss: 32.547886] time: 0:55:02.457411\n[Epoch 865/80000] [D loss_whole: 0.312131, acc:  47%] [D loss_mask: 0.560474, acc:  53%] [G loss: 33.033199] time: 0:55:06.079557\n[Epoch 866/80000] [D loss_whole: 0.302685, acc:  46%] [D loss_mask: 0.518430, acc:  53%] [G loss: 33.100304] time: 0:55:09.735400\n[Epoch 867/80000] [D loss_whole: 0.285919, acc:  46%] [D loss_mask: 0.537808, acc:  45%] [G loss: 30.113523] time: 0:55:13.124669\n[Epoch 868/80000] [D loss_whole: 0.265968, acc:  49%] [D loss_mask: 0.552149, acc:  44%] [G loss: 29.858980] time: 0:55:16.757422\n[Epoch 869/80000] [D loss_whole: 0.284259, acc:  45%] [D loss_mask: 0.574624, acc:  42%] [G loss: 30.628839] time: 0:55:20.435202\n[Epoch 870/80000] [D loss_whole: 0.258537, acc:  50%] [D loss_mask: 0.561367, acc:  46%] [G loss: 31.679974] time: 0:55:23.889433\n[Epoch 871/80000] [D loss_whole: 0.246742, acc:  58%] [D loss_mask: 0.564742, acc:  47%] [G loss: 30.064713] time: 0:55:27.484893\n[Epoch 872/80000] [D loss_whole: 0.252644, acc:  51%] [D loss_mask: 0.585709, acc:  45%] [G loss: 30.536440] time: 0:55:31.144334\n[Epoch 873/80000] [D loss_whole: 0.271854, acc:  49%] [D loss_mask: 0.589747, acc:  54%] [G loss: 35.190636] time: 0:55:34.583562\n[Epoch 874/80000] [D loss_whole: 0.262652, acc:  53%] [D loss_mask: 0.597679, acc:  59%] [G loss: 30.617155] time: 0:55:38.213614\n[Epoch 875/80000] [D loss_whole: 0.258697, acc:  53%] [D loss_mask: 0.619101, acc:  56%] [G loss: 29.707411] time: 0:55:41.870854\n[Epoch 876/80000] [D loss_whole: 0.265311, acc:  48%] [D loss_mask: 0.615594, acc:  45%] [G loss: 32.158039] time: 0:55:45.311348\n[Epoch 877/80000] [D loss_whole: 0.258464, acc:  49%] [D loss_mask: 0.534975, acc:  46%] [G loss: 31.951225] time: 0:55:48.920400\n[Epoch 878/80000] [D loss_whole: 0.272916, acc:  45%] [D loss_mask: 0.517156, acc:  49%] [G loss: 30.597160] time: 0:55:52.573511\n[Epoch 879/80000] [D loss_whole: 0.285854, acc:  43%] [D loss_mask: 0.547463, acc:  43%] [G loss: 33.279320] time: 0:55:55.941377\n[Epoch 880/80000] [D loss_whole: 0.301926, acc:  44%] [D loss_mask: 0.543555, acc:  45%] [G loss: 34.150833] time: 0:55:59.561707\n[Epoch 881/80000] [D loss_whole: 0.310435, acc:  45%] [D loss_mask: 0.562573, acc:  48%] [G loss: 32.360706] time: 0:56:03.296366\n[Epoch 882/80000] [D loss_whole: 0.336975, acc:  45%] [D loss_mask: 0.576731, acc:  46%] [G loss: 31.531378] time: 0:56:06.975119\n[Epoch 883/80000] [D loss_whole: 0.326910, acc:  48%] [D loss_mask: 0.610028, acc:  48%] [G loss: 31.856464] time: 0:56:10.696212\n[Epoch 884/80000] [D loss_whole: 0.283823, acc:  51%] [D loss_mask: 0.554948, acc:  46%] [G loss: 30.017273] time: 0:56:14.184037\n[Epoch 885/80000] [D loss_whole: 0.250455, acc:  54%] [D loss_mask: 0.537959, acc:  50%] [G loss: 29.290136] time: 0:56:17.843856\n[Epoch 886/80000] [D loss_whole: 0.272021, acc:  47%] [D loss_mask: 0.536986, acc:  44%] [G loss: 29.579527] time: 0:56:21.546505\n[Epoch 887/80000] [D loss_whole: 0.255486, acc:  52%] [D loss_mask: 0.506305, acc:  54%] [G loss: 31.389647] time: 0:56:24.999142\n[Epoch 888/80000] [D loss_whole: 0.245098, acc:  54%] [D loss_mask: 0.512759, acc:  46%] [G loss: 30.933279] time: 0:56:28.655465\n[Epoch 889/80000] [D loss_whole: 0.263746, acc:  49%] [D loss_mask: 0.538663, acc:  43%] [G loss: 30.175488] time: 0:56:32.337191\n[Epoch 890/80000] [D loss_whole: 0.251505, acc:  54%] [D loss_mask: 0.554407, acc:  39%] [G loss: 29.318411] time: 0:56:35.726978\n[Epoch 891/80000] [D loss_whole: 0.261795, acc:  49%] [D loss_mask: 0.562423, acc:  43%] [G loss: 33.667282] time: 0:56:39.366451\n[Epoch 892/80000] [D loss_whole: 0.264216, acc:  47%] [D loss_mask: 0.505458, acc:  49%] [G loss: 33.645443] time: 0:56:43.053413\n[Epoch 893/80000] [D loss_whole: 0.260312, acc:  49%] [D loss_mask: 0.525040, acc:  43%] [G loss: 31.821312] time: 0:56:46.583174\n[Epoch 894/80000] [D loss_whole: 0.256627, acc:  51%] [D loss_mask: 0.536423, acc:  37%] [G loss: 28.129290] time: 0:56:50.285916\n[Epoch 895/80000] [D loss_whole: 0.272648, acc:  47%] [D loss_mask: 0.536193, acc:  35%] [G loss: 28.375942] time: 0:56:53.708323\n[Epoch 896/80000] [D loss_whole: 0.278550, acc:  48%] [D loss_mask: 0.503841, acc:  53%] [G loss: 32.643360] time: 0:56:57.326197\n[Epoch 897/80000] [D loss_whole: 0.266141, acc:  50%] [D loss_mask: 0.503728, acc:  53%] [G loss: 30.660831] time: 0:57:01.015201\n[Epoch 898/80000] [D loss_whole: 0.252839, acc:  53%] [D loss_mask: 0.511338, acc:  46%] [G loss: 32.610691] time: 0:57:04.463498\n[Epoch 899/80000] [D loss_whole: 0.402956, acc:  47%] [D loss_mask: 0.680734, acc:  43%] [G loss: 30.777647] time: 0:57:08.147446\n[Epoch 900/80000] [D loss_whole: 0.318562, acc:  56%] [D loss_mask: 0.611443, acc:  50%] [G loss: 29.098856] time: 0:57:11.866401\nINFO:tensorflow:Assets written to: saved_models/inpaint_net900/assets\n[Epoch 901/80000] [D loss_whole: 0.280301, acc:  53%] [D loss_mask: 0.535718, acc:  47%] [G loss: 29.916391] time: 0:57:28.671291\n[Epoch 902/80000] [D loss_whole: 0.294848, acc:  56%] [D loss_mask: 0.521054, acc:  49%] [G loss: 30.003199] time: 0:57:31.586294\n[Epoch 903/80000] [D loss_whole: 0.269252, acc:  48%] [D loss_mask: 0.521155, acc:  42%] [G loss: 32.082550] time: 0:57:34.732771\n[Epoch 904/80000] [D loss_whole: 0.267275, acc:  50%] [D loss_mask: 0.504828, acc:  52%] [G loss: 30.959240] time: 0:57:37.631743\n[Epoch 905/80000] [D loss_whole: 0.275535, acc:  45%] [D loss_mask: 0.549556, acc:  42%] [G loss: 29.678808] time: 0:57:40.879218\n[Epoch 906/80000] [D loss_whole: 0.259499, acc:  49%] [D loss_mask: 0.558490, acc:  46%] [G loss: 29.377758] time: 0:57:43.809532\n[Epoch 907/80000] [D loss_whole: 0.263948, acc:  52%] [D loss_mask: 0.539348, acc:  46%] [G loss: 31.139032] time: 0:57:46.952351\n[Epoch 908/80000] [D loss_whole: 0.263198, acc:  47%] [D loss_mask: 0.514835, acc:  45%] [G loss: 32.380760] time: 0:57:49.845849\n[Epoch 909/80000] [D loss_whole: 0.260491, acc:  48%] [D loss_mask: 0.521476, acc:  40%] [G loss: 29.653805] time: 0:57:53.086190\n[Epoch 910/80000] [D loss_whole: 0.257866, acc:  54%] [D loss_mask: 0.515379, acc:  48%] [G loss: 29.931581] time: 0:57:55.990758\n[Epoch 911/80000] [D loss_whole: 0.285037, acc:  54%] [D loss_mask: 0.530130, acc:  47%] [G loss: 32.565594] time: 0:57:59.121260\n[Epoch 912/80000] [D loss_whole: 0.336244, acc:  45%] [D loss_mask: 0.584688, acc:  44%] [G loss: 31.452259] time: 0:58:02.050665\n[Epoch 913/80000] [D loss_whole: 0.394209, acc:  46%] [D loss_mask: 0.607692, acc:  47%] [G loss: 32.992195] time: 0:58:05.241303\n[Epoch 914/80000] [D loss_whole: 0.354694, acc:  48%] [D loss_mask: 0.574035, acc:  56%] [G loss: 29.565090] time: 0:58:08.162672\n[Epoch 915/80000] [D loss_whole: 0.291898, acc:  44%] [D loss_mask: 0.538922, acc:  52%] [G loss: 29.344305] time: 0:58:11.309857\n[Epoch 916/80000] [D loss_whole: 0.275408, acc:  48%] [D loss_mask: 0.555530, acc:  44%] [G loss: 29.398449] time: 0:58:14.259971\n[Epoch 917/80000] [D loss_whole: 0.283587, acc:  44%] [D loss_mask: 0.601427, acc:  42%] [G loss: 31.338837] time: 0:58:17.396932\n[Epoch 918/80000] [D loss_whole: 0.271615, acc:  49%] [D loss_mask: 0.588392, acc:  47%] [G loss: 32.352119] time: 0:58:20.323962\n[Epoch 919/80000] [D loss_whole: 0.289580, acc:  43%] [D loss_mask: 0.566826, acc:  48%] [G loss: 32.117802] time: 0:58:23.525113\n[Epoch 920/80000] [D loss_whole: 0.271697, acc:  44%] [D loss_mask: 0.546818, acc:  49%] [G loss: 31.144983] time: 0:58:26.447038\n[Epoch 921/80000] [D loss_whole: 0.256125, acc:  50%] [D loss_mask: 0.538207, acc:  45%] [G loss: 31.249125] time: 0:58:29.599299\n[Epoch 922/80000] [D loss_whole: 0.242275, acc:  57%] [D loss_mask: 0.511794, acc:  49%] [G loss: 30.765863] time: 0:58:32.520050\n[Epoch 923/80000] [D loss_whole: 0.260008, acc:  48%] [D loss_mask: 0.521916, acc:  47%] [G loss: 30.751068] time: 0:58:35.713345\n[Epoch 924/80000] [D loss_whole: 0.253882, acc:  51%] [D loss_mask: 0.532670, acc:  46%] [G loss: 30.569077] time: 0:58:38.637404\n[Epoch 925/80000] [D loss_whole: 0.257878, acc:  50%] [D loss_mask: 0.538327, acc:  44%] [G loss: 31.111727] time: 0:58:41.798390\n[Epoch 926/80000] [D loss_whole: 0.262566, acc:  48%] [D loss_mask: 0.502447, acc:  51%] [G loss: 31.733667] time: 0:58:44.726191\n[Epoch 927/80000] [D loss_whole: 0.247616, acc:  55%] [D loss_mask: 0.531165, acc:  48%] [G loss: 31.007753] time: 0:58:47.899265\n[Epoch 928/80000] [D loss_whole: 0.284133, acc:  46%] [D loss_mask: 0.574889, acc:  45%] [G loss: 29.282158] time: 0:58:50.814084\n[Epoch 929/80000] [D loss_whole: 0.284039, acc:  50%] [D loss_mask: 0.619194, acc:  44%] [G loss: 28.778923] time: 0:58:53.961259\n[Epoch 930/80000] [D loss_whole: 0.277706, acc:  52%] [D loss_mask: 0.595372, acc:  51%] [G loss: 32.183029] time: 0:58:56.883551\n[Epoch 931/80000] [D loss_whole: 0.269655, acc:  54%] [D loss_mask: 0.631402, acc:  43%] [G loss: 31.663715] time: 0:59:00.083030\n[Epoch 932/80000] [D loss_whole: 0.282418, acc:  46%] [D loss_mask: 0.676204, acc:  40%] [G loss: 33.011505] time: 0:59:03.034205\n[Epoch 933/80000] [D loss_whole: 0.243883, acc:  53%] [D loss_mask: 0.542278, acc:  43%] [G loss: 31.647757] time: 0:59:06.200290\n[Epoch 934/80000] [D loss_whole: 0.244999, acc:  54%] [D loss_mask: 0.537019, acc:  45%] [G loss: 31.618433] time: 0:59:09.139435\n[Epoch 935/80000] [D loss_whole: 0.279297, acc:  42%] [D loss_mask: 0.590168, acc:  43%] [G loss: 31.660473] time: 0:59:12.274455\n[Epoch 936/80000] [D loss_whole: 0.265929, acc:  47%] [D loss_mask: 0.547105, acc:  41%] [G loss: 30.286613] time: 0:59:15.206392\n[Epoch 937/80000] [D loss_whole: 0.264212, acc:  47%] [D loss_mask: 0.548933, acc:  38%] [G loss: 29.857264] time: 0:59:18.363020\n[Epoch 938/80000] [D loss_whole: 0.246236, acc:  56%] [D loss_mask: 0.505079, acc:  47%] [G loss: 30.959949] time: 0:59:21.293382\n[Epoch 939/80000] [D loss_whole: 0.259817, acc:  49%] [D loss_mask: 0.553480, acc:  48%] [G loss: 30.804205] time: 0:59:24.484200\n[Epoch 940/80000] [D loss_whole: 0.262602, acc:  49%] [D loss_mask: 0.545563, acc:  46%] [G loss: 30.287094] time: 0:59:27.409134\n[Epoch 941/80000] [D loss_whole: 0.310529, acc:  46%] [D loss_mask: 0.529085, acc:  40%] [G loss: 32.396069] time: 0:59:30.600335\n[Epoch 942/80000] [D loss_whole: 0.446640, acc:  44%] [D loss_mask: 0.549604, acc:  43%] [G loss: 33.957256] time: 0:59:33.543475\n[Epoch 943/80000] [D loss_whole: 0.570734, acc:  42%] [D loss_mask: 0.614524, acc:  44%] [G loss: 30.322769] time: 0:59:36.725008\n[Epoch 944/80000] [D loss_whole: 0.508019, acc:  41%] [D loss_mask: 0.681081, acc:  46%] [G loss: 30.960835] time: 0:59:39.658805\n[Epoch 945/80000] [D loss_whole: 0.277240, acc:  55%] [D loss_mask: 0.620698, acc:  49%] [G loss: 34.028458] time: 0:59:42.830195\n[Epoch 946/80000] [D loss_whole: 0.336491, acc:  51%] [D loss_mask: 0.537157, acc:  54%] [G loss: 29.094364] time: 0:59:45.764343\n[Epoch 947/80000] [D loss_whole: 0.386919, acc:  45%] [D loss_mask: 0.534746, acc:  45%] [G loss: 29.678188] time: 0:59:48.924779\n[Epoch 948/80000] [D loss_whole: 0.285504, acc:  47%] [D loss_mask: 0.522059, acc:  48%] [G loss: 29.722904] time: 0:59:51.854696\n[Epoch 949/80000] [D loss_whole: 0.265128, acc:  48%] [D loss_mask: 0.524502, acc:  47%] [G loss: 29.814135] time: 0:59:54.992459\n[Epoch 950/80000] [D loss_whole: 0.277399, acc:  52%] [D loss_mask: 0.515993, acc:  51%] [G loss: 28.890766] time: 0:59:57.935472\n[Epoch 951/80000] [D loss_whole: 0.247987, acc:  58%] [D loss_mask: 0.486337, acc:  54%] [G loss: 31.656549] time: 1:00:01.125174\n[Epoch 952/80000] [D loss_whole: 0.292537, acc:  45%] [D loss_mask: 0.574162, acc:  42%] [G loss: 30.693129] time: 1:00:04.073420\n[Epoch 953/80000] [D loss_whole: 0.269347, acc:  48%] [D loss_mask: 0.580788, acc:  46%] [G loss: 30.421219] time: 1:00:07.247474\n[Epoch 954/80000] [D loss_whole: 0.291811, acc:  53%] [D loss_mask: 0.530862, acc:  46%] [G loss: 30.773821] time: 1:00:10.192627\n[Epoch 955/80000] [D loss_whole: 0.303239, acc:  48%] [D loss_mask: 0.511432, acc:  53%] [G loss: 29.907610] time: 1:00:13.408770\n[Epoch 956/80000] [D loss_whole: 0.258141, acc:  52%] [D loss_mask: 0.516662, acc:  46%] [G loss: 30.933435] time: 1:00:16.352544\n[Epoch 957/80000] [D loss_whole: 0.256053, acc:  49%] [D loss_mask: 0.531008, acc:  38%] [G loss: 29.911673] time: 1:00:19.621593\n[Epoch 958/80000] [D loss_whole: 0.255403, acc:  48%] [D loss_mask: 0.523138, acc:  40%] [G loss: 31.066425] time: 1:00:22.868274\n[Epoch 959/80000] [D loss_whole: 0.255375, acc:  49%] [D loss_mask: 0.514980, acc:  46%] [G loss: 29.866604] time: 1:00:25.845188\n[Epoch 960/80000] [D loss_whole: 0.250943, acc:  51%] [D loss_mask: 0.521899, acc:  47%] [G loss: 32.456379] time: 1:00:29.073494\n[Epoch 961/80000] [D loss_whole: 0.258698, acc:  49%] [D loss_mask: 0.523799, acc:  48%] [G loss: 29.068640] time: 1:00:32.025224\n[Epoch 962/80000] [D loss_whole: 0.253343, acc:  51%] [D loss_mask: 0.514473, acc:  47%] [G loss: 32.608559] time: 1:00:35.219064\n[Epoch 963/80000] [D loss_whole: 0.267700, acc:  44%] [D loss_mask: 0.526202, acc:  45%] [G loss: 30.158590] time: 1:00:38.176373\n[Epoch 964/80000] [D loss_whole: 0.261922, acc:  47%] [D loss_mask: 0.519715, acc:  47%] [G loss: 31.351316] time: 1:00:41.399778\n[Epoch 965/80000] [D loss_whole: 0.244913, acc:  57%] [D loss_mask: 0.519227, acc:  45%] [G loss: 33.900661] time: 1:00:44.341314\n[Epoch 966/80000] [D loss_whole: 0.256224, acc:  50%] [D loss_mask: 0.522560, acc:  45%] [G loss: 30.032736] time: 1:00:47.580784\n[Epoch 967/80000] [D loss_whole: 0.249349, acc:  53%] [D loss_mask: 0.535037, acc:  44%] [G loss: 31.130566] time: 1:00:50.806468\n[Epoch 968/80000] [D loss_whole: 0.258668, acc:  49%] [D loss_mask: 0.523826, acc:  41%] [G loss: 29.657137] time: 1:00:53.753439\n[Epoch 969/80000] [D loss_whole: 0.264651, acc:  50%] [D loss_mask: 0.516554, acc:  48%] [G loss: 29.322817] time: 1:00:56.882468\n[Epoch 970/80000] [D loss_whole: 0.267905, acc:  48%] [D loss_mask: 0.508861, acc:  56%] [G loss: 31.180603] time: 1:00:59.816495\n[Epoch 971/80000] [D loss_whole: 0.245108, acc:  55%] [D loss_mask: 0.499059, acc:  50%] [G loss: 29.337498] time: 1:01:03.150262\n[Epoch 972/80000] [D loss_whole: 0.263331, acc:  47%] [D loss_mask: 0.536264, acc:  42%] [G loss: 33.511337] time: 1:01:06.419732\n[Epoch 973/80000] [D loss_whole: 0.306730, acc:  39%] [D loss_mask: 0.610743, acc:  38%] [G loss: 30.528164] time: 1:01:09.363852\n[Epoch 974/80000] [D loss_whole: 0.268703, acc:  49%] [D loss_mask: 0.538344, acc:  45%] [G loss: 33.581421] time: 1:01:12.520399\n[Epoch 975/80000] [D loss_whole: 0.279226, acc:  53%] [D loss_mask: 0.527218, acc:  46%] [G loss: 32.661972] time: 1:01:15.448061\n[Epoch 976/80000] [D loss_whole: 0.270457, acc:  52%] [D loss_mask: 0.531024, acc:  46%] [G loss: 31.439232] time: 1:01:18.605701\n[Epoch 977/80000] [D loss_whole: 0.267853, acc:  46%] [D loss_mask: 0.527823, acc:  45%] [G loss: 32.974197] time: 1:01:21.535821\n[Epoch 978/80000] [D loss_whole: 0.262524, acc:  48%] [D loss_mask: 0.504431, acc:  56%] [G loss: 32.767456] time: 1:01:24.685289\n[Epoch 979/80000] [D loss_whole: 0.267118, acc:  44%] [D loss_mask: 0.525845, acc:  45%] [G loss: 30.755486] time: 1:01:27.613855\n[Epoch 980/80000] [D loss_whole: 0.254944, acc:  55%] [D loss_mask: 0.517648, acc:  41%] [G loss: 29.968855] time: 1:01:30.804144\n[Epoch 981/80000] [D loss_whole: 0.261083, acc:  49%] [D loss_mask: 0.524488, acc:  44%] [G loss: 30.424273] time: 1:01:33.744381\n[Epoch 982/80000] [D loss_whole: 0.255027, acc:  53%] [D loss_mask: 0.504915, acc:  51%] [G loss: 31.777119] time: 1:01:36.906980\n[Epoch 983/80000] [D loss_whole: 0.254411, acc:  52%] [D loss_mask: 0.518222, acc:  49%] [G loss: 31.301363] time: 1:01:39.846484\n[Epoch 984/80000] [D loss_whole: 0.241137, acc:  51%] [D loss_mask: 0.508898, acc:  45%] [G loss: 29.360695] time: 1:01:43.012972\n[Epoch 985/80000] [D loss_whole: 0.327159, acc:  49%] [D loss_mask: 0.651122, acc:  47%] [G loss: 30.811169] time: 1:01:45.952705\n[Epoch 986/80000] [D loss_whole: 0.346606, acc:  50%] [D loss_mask: 0.689495, acc:  49%] [G loss: 32.631729] time: 1:01:49.151909\n[Epoch 987/80000] [D loss_whole: 0.281021, acc:  47%] [D loss_mask: 0.692983, acc:  50%] [G loss: 31.869822] time: 1:01:52.112780\n[Epoch 988/80000] [D loss_whole: 0.243234, acc:  57%] [D loss_mask: 0.726242, acc:  52%] [G loss: 29.494682] time: 1:01:55.300525\n[Epoch 989/80000] [D loss_whole: 0.258147, acc:  49%] [D loss_mask: 0.744402, acc:  55%] [G loss: 31.174036] time: 1:01:58.244310\n[Epoch 990/80000] [D loss_whole: 0.242487, acc:  55%] [D loss_mask: 0.699290, acc:  52%] [G loss: 33.028507] time: 1:02:01.398009\n[Epoch 991/80000] [D loss_whole: 0.256510, acc:  48%] [D loss_mask: 0.586802, acc:  55%] [G loss: 29.696802] time: 1:02:04.347624\n[Epoch 992/80000] [D loss_whole: 0.254930, acc:  51%] [D loss_mask: 0.500829, acc:  52%] [G loss: 29.735558] time: 1:02:07.561298\n[Epoch 993/80000] [D loss_whole: 0.255806, acc:  50%] [D loss_mask: 0.517938, acc:  44%] [G loss: 30.805058] time: 1:02:10.520673\n[Epoch 994/80000] [D loss_whole: 0.257836, acc:  48%] [D loss_mask: 0.527449, acc:  45%] [G loss: 28.411974] time: 1:02:13.693515\n[Epoch 995/80000] [D loss_whole: 0.272512, acc:  45%] [D loss_mask: 0.527018, acc:  44%] [G loss: 29.167122] time: 1:02:16.622830\n[Epoch 996/80000] [D loss_whole: 0.292575, acc:  44%] [D loss_mask: 0.543606, acc:  42%] [G loss: 30.530993] time: 1:02:19.835494\n[Epoch 997/80000] [D loss_whole: 0.304206, acc:  46%] [D loss_mask: 0.559675, acc:  50%] [G loss: 31.932854] time: 1:02:22.783103\n[Epoch 998/80000] [D loss_whole: 0.302659, acc:  47%] [D loss_mask: 0.562047, acc:  56%] [G loss: 30.979351] time: 1:02:25.928444\n[Epoch 999/80000] [D loss_whole: 0.276042, acc:  50%] [D loss_mask: 0.571589, acc:  58%] [G loss: 30.242683] time: 1:02:28.858507\n[Epoch 1000/80000] [D loss_whole: 0.261682, acc:  49%] [D loss_mask: 0.560588, acc:  57%] [G loss: 29.827362] time: 1:02:32.015430\nINFO:tensorflow:Assets written to: saved_models/inpaint_net1000/assets\n[Epoch 1001/80000] [D loss_whole: 0.262693, acc:  47%] [D loss_mask: 0.546589, acc:  54%] [G loss: 31.227127] time: 1:02:48.482297\n[Epoch 1002/80000] [D loss_whole: 0.257624, acc:  51%] [D loss_mask: 0.505855, acc:  58%] [G loss: 30.262430] time: 1:02:51.893488\n[Epoch 1003/80000] [D loss_whole: 0.256942, acc:  47%] [D loss_mask: 0.505199, acc:  54%] [G loss: 29.207569] time: 1:02:55.528627\n[Epoch 1004/80000] [D loss_whole: 0.273745, acc:  44%] [D loss_mask: 0.526900, acc:  45%] [G loss: 29.513113] time: 1:02:59.221351\n[Epoch 1005/80000] [D loss_whole: 0.258985, acc:  47%] [D loss_mask: 0.528166, acc:  45%] [G loss: 28.102434] time: 1:03:02.697383\n[Epoch 1006/80000] [D loss_whole: 0.264251, acc:  48%] [D loss_mask: 0.523473, acc:  46%] [G loss: 28.846245] time: 1:03:06.354444\n[Epoch 1007/80000] [D loss_whole: 0.260686, acc:  48%] [D loss_mask: 0.525370, acc:  42%] [G loss: 29.985620] time: 1:03:10.046569\n[Epoch 1008/80000] [D loss_whole: 0.258647, acc:  49%] [D loss_mask: 0.513023, acc:  45%] [G loss: 30.780470] time: 1:03:13.589592\n[Epoch 1009/80000] [D loss_whole: 0.271977, acc:  43%] [D loss_mask: 0.514562, acc:  47%] [G loss: 30.153038] time: 1:03:16.903098\n[Epoch 1010/80000] [D loss_whole: 0.268945, acc:  45%] [D loss_mask: 0.521523, acc:  49%] [G loss: 30.524960] time: 1:03:20.502262\n[Epoch 1011/80000] [D loss_whole: 0.273804, acc:  48%] [D loss_mask: 0.531175, acc:  46%] [G loss: 33.014759] time: 1:03:24.146690\n[Epoch 1012/80000] [D loss_whole: 0.264025, acc:  54%] [D loss_mask: 0.512389, acc:  52%] [G loss: 28.463758] time: 1:03:27.813998\n[Epoch 1013/80000] [D loss_whole: 0.263800, acc:  49%] [D loss_mask: 0.531481, acc:  48%] [G loss: 28.808474] time: 1:03:31.299037\n[Epoch 1014/80000] [D loss_whole: 0.262585, acc:  46%] [D loss_mask: 0.543003, acc:  39%] [G loss: 30.281384] time: 1:03:34.953483\n[Epoch 1015/80000] [D loss_whole: 0.255277, acc:  50%] [D loss_mask: 0.514345, acc:  48%] [G loss: 30.720230] time: 1:03:38.644322\n[Epoch 1016/80000] [D loss_whole: 0.257904, acc:  47%] [D loss_mask: 0.523925, acc:  41%] [G loss: 31.630875] time: 1:03:42.163728\n[Epoch 1017/80000] [D loss_whole: 0.276142, acc:  42%] [D loss_mask: 0.549227, acc:  38%] [G loss: 30.906258] time: 1:03:45.813479\n[Epoch 1018/80000] [D loss_whole: 0.254282, acc:  47%] [D loss_mask: 0.546130, acc:  43%] [G loss: 30.842083] time: 1:03:49.477786\n[Epoch 1019/80000] [D loss_whole: 0.266825, acc:  46%] [D loss_mask: 0.601156, acc:  42%] [G loss: 31.141214] time: 1:03:52.964309\n[Epoch 1020/80000] [D loss_whole: 0.270308, acc:  45%] [D loss_mask: 0.555681, acc:  43%] [G loss: 30.286934] time: 1:03:56.597991\n[Epoch 1021/80000] [D loss_whole: 0.244896, acc:  58%] [D loss_mask: 0.524076, acc:  47%] [G loss: 30.376379] time: 1:04:00.269454\n[Epoch 1022/80000] [D loss_whole: 0.268290, acc:  48%] [D loss_mask: 0.520466, acc:  50%] [G loss: 33.460480] time: 1:04:03.748375\n[Epoch 1023/80000] [D loss_whole: 0.261715, acc:  52%] [D loss_mask: 0.525913, acc:  54%] [G loss: 30.948196] time: 1:04:07.415004\n[Epoch 1024/80000] [D loss_whole: 0.256704, acc:  50%] [D loss_mask: 0.523961, acc:  44%] [G loss: 31.087250] time: 1:04:11.135314\n[Epoch 1025/80000] [D loss_whole: 0.245602, acc:  54%] [D loss_mask: 0.514027, acc:  44%] [G loss: 30.190283] time: 1:04:14.620629\n[Epoch 1026/80000] [D loss_whole: 0.260875, acc:  46%] [D loss_mask: 0.532589, acc:  42%] [G loss: 28.146175] time: 1:04:18.263993\n[Epoch 1027/80000] [D loss_whole: 0.260139, acc:  47%] [D loss_mask: 0.528546, acc:  46%] [G loss: 29.625547] time: 1:04:21.945307\n[Epoch 1028/80000] [D loss_whole: 0.274695, acc:  44%] [D loss_mask: 0.529905, acc:  44%] [G loss: 31.417038] time: 1:04:25.331704\n[Epoch 1029/80000] [D loss_whole: 0.264428, acc:  46%] [D loss_mask: 0.523182, acc:  47%] [G loss: 30.256353] time: 1:04:28.981199\n[Epoch 1030/80000] [D loss_whole: 0.264687, acc:  48%] [D loss_mask: 0.521118, acc:  46%] [G loss: 30.576420] time: 1:04:32.673611\n[Epoch 1031/80000] [D loss_whole: 0.270755, acc:  43%] [D loss_mask: 0.529522, acc:  44%] [G loss: 29.181309] time: 1:04:36.153956\n[Epoch 1032/80000] [D loss_whole: 0.301008, acc:  43%] [D loss_mask: 0.542704, acc:  44%] [G loss: 31.411015] time: 1:04:39.772657\n[Epoch 1033/80000] [D loss_whole: 0.289964, acc:  46%] [D loss_mask: 0.560651, acc:  44%] [G loss: 29.885603] time: 1:04:43.441424\n[Epoch 1034/80000] [D loss_whole: 0.278415, acc:  47%] [D loss_mask: 0.595651, acc:  46%] [G loss: 28.608215] time: 1:04:46.876638\n[Epoch 1035/80000] [D loss_whole: 0.287327, acc:  45%] [D loss_mask: 0.653660, acc:  44%] [G loss: 28.372929] time: 1:04:50.449304\n[Epoch 1036/80000] [D loss_whole: 0.313249, acc:  46%] [D loss_mask: 0.784546, acc:  44%] [G loss: 30.125731] time: 1:04:54.116499\n[Epoch 1037/80000] [D loss_whole: 0.320945, acc:  45%] [D loss_mask: 0.922479, acc:  43%] [G loss: 29.937828] time: 1:04:57.651579\n[Epoch 1038/80000] [D loss_whole: 0.322565, acc:  43%] [D loss_mask: 0.859034, acc:  46%] [G loss: 31.535278] time: 1:05:00.929258\n[Epoch 1039/80000] [D loss_whole: 0.314480, acc:  43%] [D loss_mask: 0.770896, acc:  46%] [G loss: 31.094828] time: 1:05:04.549587\n[Epoch 1040/80000] [D loss_whole: 0.309489, acc:  45%] [D loss_mask: 0.719397, acc:  53%] [G loss: 29.808784] time: 1:05:08.186557\n[Epoch 1041/80000] [D loss_whole: 0.262172, acc:  54%] [D loss_mask: 0.631005, acc:  58%] [G loss: 30.619223] time: 1:05:11.879424\n[Epoch 1042/80000] [D loss_whole: 0.259831, acc:  48%] [D loss_mask: 0.558364, acc:  53%] [G loss: 31.164650] time: 1:05:15.351239\n[Epoch 1043/80000] [D loss_whole: 0.250320, acc:  55%] [D loss_mask: 0.522433, acc:  48%] [G loss: 28.784554] time: 1:05:19.014287\n[Epoch 1044/80000] [D loss_whole: 0.247234, acc:  56%] [D loss_mask: 0.519272, acc:  44%] [G loss: 28.719481] time: 1:05:22.695208\n[Epoch 1045/80000] [D loss_whole: 0.252241, acc:  48%] [D loss_mask: 0.525598, acc:  45%] [G loss: 32.077549] time: 1:05:26.255622\n[Epoch 1046/80000] [D loss_whole: 0.280932, acc:  42%] [D loss_mask: 0.522389, acc:  46%] [G loss: 29.142965] time: 1:05:29.558526\n[Epoch 1047/80000] [D loss_whole: 0.282762, acc:  44%] [D loss_mask: 0.506580, acc:  49%] [G loss: 30.461185] time: 1:05:33.151252\n[Epoch 1048/80000] [D loss_whole: 0.328301, acc:  46%] [D loss_mask: 0.532776, acc:  41%] [G loss: 31.712225] time: 1:05:36.774499\n[Epoch 1049/80000] [D loss_whole: 0.311834, acc:  49%] [D loss_mask: 0.547593, acc:  36%] [G loss: 28.569826] time: 1:05:40.463245\n[Epoch 1050/80000] [D loss_whole: 0.252495, acc:  54%] [D loss_mask: 0.524611, acc:  46%] [G loss: 30.105900] time: 1:05:43.952577\n[Epoch 1051/80000] [D loss_whole: 0.268234, acc:  51%] [D loss_mask: 0.516098, acc:  47%] [G loss: 30.396749] time: 1:05:47.528953\n[Epoch 1052/80000] [D loss_whole: 0.308141, acc:  42%] [D loss_mask: 0.538292, acc:  46%] [G loss: 28.637983] time: 1:05:51.191791\n[Epoch 1053/80000] [D loss_whole: 0.318665, acc:  42%] [D loss_mask: 0.533642, acc:  48%] [G loss: 30.926424] time: 1:05:54.645539\n[Epoch 1054/80000] [D loss_whole: 0.280910, acc:  44%] [D loss_mask: 0.519075, acc:  43%] [G loss: 30.428543] time: 1:05:58.284273\n[Epoch 1055/80000] [D loss_whole: 0.245808, acc:  53%] [D loss_mask: 0.517689, acc:  42%] [G loss: 29.605309] time: 1:06:01.969079\n[Epoch 1056/80000] [D loss_whole: 0.298004, acc:  42%] [D loss_mask: 0.547292, acc:  42%] [G loss: 29.219637] time: 1:06:05.500523\n[Epoch 1057/80000] [D loss_whole: 0.299480, acc:  46%] [D loss_mask: 0.559645, acc:  35%] [G loss: 29.211317] time: 1:06:08.819366\n[Epoch 1058/80000] [D loss_whole: 0.263565, acc:  49%] [D loss_mask: 0.540078, acc:  36%] [G loss: 28.997711] time: 1:06:12.467638\n[Epoch 1059/80000] [D loss_whole: 0.243219, acc:  58%] [D loss_mask: 0.499483, acc:  47%] [G loss: 31.196217] time: 1:06:16.111568\n[Epoch 1060/80000] [D loss_whole: 0.253674, acc:  50%] [D loss_mask: 0.529397, acc:  41%] [G loss: 30.767912] time: 1:06:19.790606\n[Epoch 1061/80000] [D loss_whole: 0.250319, acc:  50%] [D loss_mask: 0.534714, acc:  39%] [G loss: 29.418463] time: 1:06:23.354420\n[Epoch 1062/80000] [D loss_whole: 0.266650, acc:  50%] [D loss_mask: 0.560149, acc:  47%] [G loss: 29.801369] time: 1:06:27.041745\n[Epoch 1063/80000] [D loss_whole: 0.263160, acc:  46%] [D loss_mask: 0.529890, acc:  39%] [G loss: 30.082817] time: 1:06:30.527579\n[Epoch 1064/80000] [D loss_whole: 0.256674, acc:  48%] [D loss_mask: 0.509211, acc:  49%] [G loss: 29.446404] time: 1:06:34.174522\n[Epoch 1065/80000] [D loss_whole: 0.263232, acc:  48%] [D loss_mask: 0.513150, acc:  44%] [G loss: 31.076040] time: 1:06:37.823588\n[Epoch 1066/80000] [D loss_whole: 0.260456, acc:  46%] [D loss_mask: 0.527583, acc:  43%] [G loss: 29.282188] time: 1:06:41.334055\n[Epoch 1067/80000] [D loss_whole: 0.309943, acc:  45%] [D loss_mask: 0.550425, acc:  44%] [G loss: 30.380888] time: 1:06:44.939777\n[Epoch 1068/80000] [D loss_whole: 0.391016, acc:  46%] [D loss_mask: 0.583676, acc:  45%] [G loss: 31.604317] time: 1:06:48.560940\n[Epoch 1069/80000] [D loss_whole: 0.360476, acc:  54%] [D loss_mask: 0.525632, acc:  55%] [G loss: 30.724325] time: 1:06:52.028181\n[Epoch 1070/80000] [D loss_whole: 0.284340, acc:  59%] [D loss_mask: 0.519484, acc:  56%] [G loss: 29.298843] time: 1:06:55.624236\n[Epoch 1071/80000] [D loss_whole: 0.246408, acc:  58%] [D loss_mask: 0.521369, acc:  53%] [G loss: 30.430231] time: 1:06:59.302643\n[Epoch 1072/80000] [D loss_whole: 0.263712, acc:  45%] [D loss_mask: 0.532361, acc:  44%] [G loss: 31.013119] time: 1:07:02.950450\n[Epoch 1073/80000] [D loss_whole: 0.246083, acc:  54%] [D loss_mask: 0.485037, acc:  58%] [G loss: 30.232191] time: 1:07:06.619052\n[Epoch 1074/80000] [D loss_whole: 0.276522, acc:  46%] [D loss_mask: 0.513287, acc:  46%] [G loss: 27.989611] time: 1:07:10.210473\n[Epoch 1075/80000] [D loss_whole: 0.335602, acc:  47%] [D loss_mask: 0.548656, acc:  40%] [G loss: 30.291946] time: 1:07:13.890958\n[Epoch 1076/80000] [D loss_whole: 0.277487, acc:  54%] [D loss_mask: 0.548977, acc:  39%] [G loss: 29.811842] time: 1:07:17.436224\n[Epoch 1077/80000] [D loss_whole: 0.262137, acc:  51%] [D loss_mask: 0.522984, acc:  41%] [G loss: 33.546932] time: 1:07:20.722462\n[Epoch 1078/80000] [D loss_whole: 0.278601, acc:  48%] [D loss_mask: 0.522235, acc:  47%] [G loss: 28.208530] time: 1:07:24.315798\n[Epoch 1079/80000] [D loss_whole: 0.287412, acc:  43%] [D loss_mask: 0.529708, acc:  46%] [G loss: 31.181334] time: 1:07:27.955845\n[Epoch 1080/80000] [D loss_whole: 0.272384, acc:  47%] [D loss_mask: 0.518671, acc:  55%] [G loss: 33.686562] time: 1:07:31.636786\n[Epoch 1081/80000] [D loss_whole: 0.254484, acc:  52%] [D loss_mask: 0.521044, acc:  45%] [G loss: 29.407991] time: 1:07:35.129852\n[Epoch 1082/80000] [D loss_whole: 0.258797, acc:  47%] [D loss_mask: 0.520354, acc:  42%] [G loss: 28.904095] time: 1:07:38.739185\n[Epoch 1083/80000] [D loss_whole: 0.254416, acc:  50%] [D loss_mask: 0.519972, acc:  40%] [G loss: 27.426603] time: 1:07:42.406611\n[Epoch 1084/80000] [D loss_whole: 0.257026, acc:  51%] [D loss_mask: 0.526227, acc:  42%] [G loss: 29.701820] time: 1:07:45.933374\n[Epoch 1085/80000] [D loss_whole: 0.260846, acc:  51%] [D loss_mask: 0.531258, acc:  37%] [G loss: 31.609097] time: 1:07:49.184666\n[Epoch 1086/80000] [D loss_whole: 0.239603, acc:  57%] [D loss_mask: 0.504467, acc:  48%] [G loss: 32.285061] time: 1:07:52.738597\n[Epoch 1087/80000] [D loss_whole: 0.271904, acc:  42%] [D loss_mask: 0.540210, acc:  44%] [G loss: 27.908432] time: 1:07:56.333614\n[Epoch 1088/80000] [D loss_whole: 0.275198, acc:  44%] [D loss_mask: 0.539961, acc:  36%] [G loss: 29.350485] time: 1:07:59.996682\n[Epoch 1089/80000] [D loss_whole: 0.265817, acc:  47%] [D loss_mask: 0.521445, acc:  39%] [G loss: 32.466129] time: 1:08:03.462897\n[Epoch 1090/80000] [D loss_whole: 0.264882, acc:  52%] [D loss_mask: 0.518543, acc:  42%] [G loss: 28.290503] time: 1:08:07.079262\n[Epoch 1091/80000] [D loss_whole: 0.288959, acc:  49%] [D loss_mask: 0.530145, acc:  44%] [G loss: 29.655140] time: 1:08:10.730386\n[Epoch 1092/80000] [D loss_whole: 0.294422, acc:  45%] [D loss_mask: 0.534169, acc:  45%] [G loss: 32.919571] time: 1:08:14.295731\n[Epoch 1093/80000] [D loss_whole: 0.295799, acc:  41%] [D loss_mask: 0.539516, acc:  44%] [G loss: 28.287241] time: 1:08:17.579344\n[Epoch 1094/80000] [D loss_whole: 0.310345, acc:  46%] [D loss_mask: 0.559310, acc:  44%] [G loss: 27.662167] time: 1:08:21.142114\n[Epoch 1095/80000] [D loss_whole: 0.296780, acc:  48%] [D loss_mask: 0.555654, acc:  47%] [G loss: 27.488735] time: 1:08:24.742397\n[Epoch 1096/80000] [D loss_whole: 0.257441, acc:  51%] [D loss_mask: 0.531521, acc:  46%] [G loss: 29.171522] time: 1:08:28.400392\n[Epoch 1097/80000] [D loss_whole: 0.275142, acc:  47%] [D loss_mask: 0.542120, acc:  47%] [G loss: 29.109238] time: 1:08:31.850133\n[Epoch 1098/80000] [D loss_whole: 0.274377, acc:  53%] [D loss_mask: 0.551677, acc:  50%] [G loss: 30.874523] time: 1:08:35.504549\n[Epoch 1099/80000] [D loss_whole: 0.264709, acc:  53%] [D loss_mask: 0.540569, acc:  55%] [G loss: 29.880655] time: 1:08:39.152171\n[Epoch 1100/80000] [D loss_whole: 0.244759, acc:  56%] [D loss_mask: 0.514291, acc:  53%] [G loss: 29.840202] time: 1:08:42.636560\nINFO:tensorflow:Assets written to: saved_models/inpaint_net1100/assets\n[Epoch 1101/80000] [D loss_whole: 0.253042, acc:  49%] [D loss_mask: 0.516122, acc:  47%] [G loss: 31.101843] time: 1:08:59.500273\n[Epoch 1102/80000] [D loss_whole: 0.251594, acc:  52%] [D loss_mask: 0.511720, acc:  49%] [G loss: 29.081339] time: 1:09:03.158904\n[Epoch 1103/80000] [D loss_whole: 0.238939, acc:  54%] [D loss_mask: 0.486546, acc:  56%] [G loss: 29.715744] time: 1:09:06.811373\n[Epoch 1104/80000] [D loss_whole: 0.373017, acc:  47%] [D loss_mask: 0.537274, acc:  43%] [G loss: 29.689812] time: 1:09:10.463792\n[Epoch 1105/80000] [D loss_whole: 0.430902, acc:  47%] [D loss_mask: 0.583138, acc:  39%] [G loss: 30.108913] time: 1:09:14.123400\n[Epoch 1106/80000] [D loss_whole: 0.292387, acc:  51%] [D loss_mask: 0.568476, acc:  36%] [G loss: 32.624767] time: 1:09:17.823157\n[Epoch 1107/80000] [D loss_whole: 0.234000, acc:  63%] [D loss_mask: 0.493853, acc:  54%] [G loss: 30.444967] time: 1:09:21.493249\n[Epoch 1108/80000] [D loss_whole: 0.260800, acc:  55%] [D loss_mask: 0.597251, acc:  53%] [G loss: 29.376072] time: 1:09:25.143918\n[Epoch 1109/80000] [D loss_whole: 0.304742, acc:  46%] [D loss_mask: 0.744365, acc:  42%] [G loss: 31.166777] time: 1:09:28.801356\n[Epoch 1110/80000] [D loss_whole: 0.260578, acc:  50%] [D loss_mask: 0.738519, acc:  49%] [G loss: 29.960915] time: 1:09:32.451997\n[Epoch 1111/80000] [D loss_whole: 0.279878, acc:  55%] [D loss_mask: 0.677059, acc:  51%] [G loss: 31.102865] time: 1:09:36.093878\n[Epoch 1112/80000] [D loss_whole: 0.318489, acc:  49%] [D loss_mask: 0.590033, acc:  44%] [G loss: 29.128429] time: 1:09:39.760345\n[Epoch 1113/80000] [D loss_whole: 0.304121, acc:  43%] [D loss_mask: 0.542942, acc:  46%] [G loss: 29.841249] time: 1:09:43.429952\n[Epoch 1114/80000] [D loss_whole: 0.259369, acc:  50%] [D loss_mask: 0.490689, acc:  54%] [G loss: 29.556309] time: 1:09:47.066594\n[Epoch 1115/80000] [D loss_whole: 0.256141, acc:  48%] [D loss_mask: 0.539938, acc:  46%] [G loss: 28.733887] time: 1:09:50.719654\n[Epoch 1116/80000] [D loss_whole: 0.305286, acc:  44%] [D loss_mask: 0.641960, acc:  41%] [G loss: 30.231003] time: 1:09:54.380726\n[Epoch 1117/80000] [D loss_whole: 0.264932, acc:  47%] [D loss_mask: 0.577162, acc:  40%] [G loss: 29.373034] time: 1:09:58.026511\n[Epoch 1118/80000] [D loss_whole: 0.255341, acc:  51%] [D loss_mask: 0.525575, acc:  42%] [G loss: 29.086353] time: 1:10:01.708873\n[Epoch 1119/80000] [D loss_whole: 0.277678, acc:  43%] [D loss_mask: 0.519998, acc:  47%] [G loss: 31.754679] time: 1:10:05.417988\n[Epoch 1120/80000] [D loss_whole: 0.291927, acc:  42%] [D loss_mask: 0.513917, acc:  46%] [G loss: 29.798639] time: 1:10:09.075748\n[Epoch 1121/80000] [D loss_whole: 0.277231, acc:  44%] [D loss_mask: 0.533389, acc:  47%] [G loss: 28.095438] time: 1:10:12.718065\n[Epoch 1122/80000] [D loss_whole: 0.267591, acc:  45%] [D loss_mask: 0.550548, acc:  43%] [G loss: 30.049688] time: 1:10:16.354367\n[Epoch 1123/80000] [D loss_whole: 0.267888, acc:  45%] [D loss_mask: 0.551765, acc:  41%] [G loss: 30.148252] time: 1:10:20.012659\n[Epoch 1124/80000] [D loss_whole: 0.273269, acc:  45%] [D loss_mask: 0.550099, acc:  41%] [G loss: 28.362783] time: 1:10:23.652300\n[Epoch 1125/80000] [D loss_whole: 0.283882, acc:  43%] [D loss_mask: 0.557936, acc:  39%] [G loss: 29.555492] time: 1:10:27.295958\n[Epoch 1126/80000] [D loss_whole: 0.279752, acc:  48%] [D loss_mask: 0.523128, acc:  48%] [G loss: 30.294930] time: 1:10:30.967696\n[Epoch 1127/80000] [D loss_whole: 0.251466, acc:  54%] [D loss_mask: 0.520032, acc:  51%] [G loss: 31.514982] time: 1:10:34.628145\n[Epoch 1128/80000] [D loss_whole: 0.252041, acc:  51%] [D loss_mask: 0.520526, acc:  47%] [G loss: 30.994591] time: 1:10:38.278183\n[Epoch 1129/80000] [D loss_whole: 0.262553, acc:  46%] [D loss_mask: 0.527165, acc:  45%] [G loss: 28.160173] time: 1:10:41.958443\n[Epoch 1130/80000] [D loss_whole: 0.252264, acc:  51%] [D loss_mask: 0.519271, acc:  46%] [G loss: 29.085005] time: 1:10:45.594041\n[Epoch 1131/80000] [D loss_whole: 0.248491, acc:  53%] [D loss_mask: 0.505096, acc:  51%] [G loss: 29.849249] time: 1:10:49.189828\n[Epoch 1132/80000] [D loss_whole: 0.257352, acc:  48%] [D loss_mask: 0.517659, acc:  46%] [G loss: 32.183826] time: 1:10:52.835976\n[Epoch 1133/80000] [D loss_whole: 0.245842, acc:  55%] [D loss_mask: 0.525070, acc:  46%] [G loss: 30.694168] time: 1:10:56.487937\n[Epoch 1134/80000] [D loss_whole: 0.263430, acc:  46%] [D loss_mask: 0.530968, acc:  44%] [G loss: 28.488243] time: 1:11:00.170934\n[Epoch 1135/80000] [D loss_whole: 0.270282, acc:  47%] [D loss_mask: 0.549550, acc:  43%] [G loss: 28.281719] time: 1:11:03.799106\n[Epoch 1136/80000] [D loss_whole: 0.253324, acc:  54%] [D loss_mask: 0.523262, acc:  48%] [G loss: 28.752777] time: 1:11:07.464151\n[Epoch 1137/80000] [D loss_whole: 0.255449, acc:  50%] [D loss_mask: 0.526203, acc:  47%] [G loss: 28.482924] time: 1:11:11.135399\n[Epoch 1138/80000] [D loss_whole: 0.257468, acc:  49%] [D loss_mask: 0.537327, acc:  46%] [G loss: 32.195427] time: 1:11:14.805031\n[Epoch 1139/80000] [D loss_whole: 0.262626, acc:  45%] [D loss_mask: 0.531312, acc:  43%] [G loss: 29.591700] time: 1:11:18.469684\n[Epoch 1140/80000] [D loss_whole: 0.261567, acc:  47%] [D loss_mask: 0.520188, acc:  45%] [G loss: 28.250259] time: 1:11:22.138810\n[Epoch 1141/80000] [D loss_whole: 0.280312, acc:  45%] [D loss_mask: 0.525419, acc:  44%] [G loss: 27.944551] time: 1:11:25.794539\n[Epoch 1142/80000] [D loss_whole: 0.294374, acc:  43%] [D loss_mask: 0.521642, acc:  46%] [G loss: 29.705896] time: 1:11:29.466361\n[Epoch 1143/80000] [D loss_whole: 0.285554, acc:  47%] [D loss_mask: 0.505051, acc:  51%] [G loss: 29.953281] time: 1:11:33.113905\n[Epoch 1144/80000] [D loss_whole: 0.252537, acc:  57%] [D loss_mask: 0.497330, acc:  50%] [G loss: 29.678806] time: 1:11:36.772202\n[Epoch 1145/80000] [D loss_whole: 0.262467, acc:  48%] [D loss_mask: 0.536345, acc:  40%] [G loss: 32.264061] time: 1:11:40.439456\n[Epoch 1146/80000] [D loss_whole: 0.245456, acc:  56%] [D loss_mask: 0.511332, acc:  43%] [G loss: 31.243084] time: 1:11:44.111506\n[Epoch 1147/80000] [D loss_whole: 0.259731, acc:  50%] [D loss_mask: 0.554555, acc:  44%] [G loss: 31.036417] time: 1:11:47.746232\n[Epoch 1148/80000] [D loss_whole: 0.325094, acc:  46%] [D loss_mask: 0.674940, acc:  42%] [G loss: 28.561813] time: 1:11:51.376816\n[Epoch 1149/80000] [D loss_whole: 0.354222, acc:  47%] [D loss_mask: 0.773013, acc:  42%] [G loss: 29.478481] time: 1:11:55.039832\n[Epoch 1150/80000] [D loss_whole: 0.287339, acc:  53%] [D loss_mask: 0.664458, acc:  44%] [G loss: 28.758593] time: 1:11:58.708997\n[Epoch 1151/80000] [D loss_whole: 0.269985, acc:  54%] [D loss_mask: 0.619219, acc:  52%] [G loss: 28.206652] time: 1:12:02.369373\n[Epoch 1152/80000] [D loss_whole: 0.255728, acc:  59%] [D loss_mask: 0.616835, acc:  52%] [G loss: 30.376360] time: 1:12:06.033251\n[Epoch 1153/80000] [D loss_whole: 0.276041, acc:  51%] [D loss_mask: 0.605814, acc:  51%] [G loss: 27.876944] time: 1:12:09.691768\n[Epoch 1154/80000] [D loss_whole: 0.240186, acc:  59%] [D loss_mask: 0.545908, acc:  49%] [G loss: 29.973753] time: 1:12:13.338379\n[Epoch 1155/80000] [D loss_whole: 0.254596, acc:  56%] [D loss_mask: 0.528283, acc:  50%] [G loss: 30.378141] time: 1:12:16.991994\n[Epoch 1156/80000] [D loss_whole: 0.258303, acc:  49%] [D loss_mask: 0.525760, acc:  44%] [G loss: 28.958611] time: 1:12:20.634668\n[Epoch 1157/80000] [D loss_whole: 0.259606, acc:  49%] [D loss_mask: 0.529634, acc:  50%] [G loss: 27.773466] time: 1:12:24.313486\n[Epoch 1158/80000] [D loss_whole: 0.288506, acc:  47%] [D loss_mask: 0.534220, acc:  53%] [G loss: 29.917574] time: 1:12:27.969682\n[Epoch 1159/80000] [D loss_whole: 0.272127, acc:  51%] [D loss_mask: 0.515916, acc:  52%] [G loss: 29.988966] time: 1:12:31.624476\n[Epoch 1160/80000] [D loss_whole: 0.259037, acc:  51%] [D loss_mask: 0.510810, acc:  49%] [G loss: 27.316633] time: 1:12:35.279660\n[Epoch 1161/80000] [D loss_whole: 0.243708, acc:  56%] [D loss_mask: 0.499760, acc:  53%] [G loss: 30.482714] time: 1:12:38.932884\n[Epoch 1162/80000] [D loss_whole: 0.259059, acc:  46%] [D loss_mask: 0.513348, acc:  47%] [G loss: 30.821680] time: 1:12:42.586212\n[Epoch 1163/80000] [D loss_whole: 0.264465, acc:  45%] [D loss_mask: 0.531575, acc:  44%] [G loss: 28.603514] time: 1:12:46.223513\n[Epoch 1164/80000] [D loss_whole: 0.285258, acc:  47%] [D loss_mask: 0.552429, acc:  43%] [G loss: 27.897266] time: 1:12:49.810263\n[Epoch 1165/80000] [D loss_whole: 0.294109, acc:  47%] [D loss_mask: 0.534612, acc:  46%] [G loss: 29.113562] time: 1:12:53.435853\n[Epoch 1166/80000] [D loss_whole: 0.280380, acc:  45%] [D loss_mask: 0.522596, acc:  48%] [G loss: 29.742180] time: 1:12:57.086061\n[Epoch 1167/80000] [D loss_whole: 0.277123, acc:  47%] [D loss_mask: 0.523709, acc:  48%] [G loss: 32.113953] time: 1:13:00.757114\n[Epoch 1168/80000] [D loss_whole: 0.274636, acc:  43%] [D loss_mask: 0.529828, acc:  45%] [G loss: 28.398218] time: 1:13:04.443525\n[Epoch 1169/80000] [D loss_whole: 0.272662, acc:  47%] [D loss_mask: 0.534475, acc:  43%] [G loss: 35.102051] time: 1:13:08.120407\n[Epoch 1170/80000] [D loss_whole: 0.266564, acc:  52%] [D loss_mask: 0.522075, acc:  46%] [G loss: 29.093422] time: 1:13:11.781571\n[Epoch 1171/80000] [D loss_whole: 0.280694, acc:  50%] [D loss_mask: 0.518452, acc:  49%] [G loss: 34.417450] time: 1:13:15.464394\n[Epoch 1172/80000] [D loss_whole: 0.271968, acc:  49%] [D loss_mask: 0.524849, acc:  47%] [G loss: 31.384916] time: 1:13:19.123651\n[Epoch 1173/80000] [D loss_whole: 0.261237, acc:  48%] [D loss_mask: 0.512505, acc:  49%] [G loss: 29.258114] time: 1:13:22.765492\n[Epoch 1174/80000] [D loss_whole: 0.255299, acc:  50%] [D loss_mask: 0.515769, acc:  51%] [G loss: 29.189348] time: 1:13:26.428039\n[Epoch 1175/80000] [D loss_whole: 0.264837, acc:  45%] [D loss_mask: 0.526831, acc:  48%] [G loss: 27.792763] time: 1:13:30.080068\n[Epoch 1176/80000] [D loss_whole: 0.247007, acc:  54%] [D loss_mask: 0.525299, acc:  47%] [G loss: 29.607906] time: 1:13:33.731965\n[Epoch 1177/80000] [D loss_whole: 0.246321, acc:  54%] [D loss_mask: 0.514495, acc:  49%] [G loss: 30.154627] time: 1:13:37.395735\n[Epoch 1178/80000] [D loss_whole: 0.257570, acc:  50%] [D loss_mask: 0.534381, acc:  48%] [G loss: 31.595846] time: 1:13:41.047283\n[Epoch 1179/80000] [D loss_whole: 0.262034, acc:  48%] [D loss_mask: 0.542287, acc:  44%] [G loss: 28.712456] time: 1:13:44.720750\n[Epoch 1180/80000] [D loss_whole: 0.245965, acc:  53%] [D loss_mask: 0.501040, acc:  54%] [G loss: 27.893606] time: 1:13:48.353878\n[Epoch 1181/80000] [D loss_whole: 0.244476, acc:  55%] [D loss_mask: 0.491698, acc:  49%] [G loss: 29.054920] time: 1:13:51.988486\n[Epoch 1182/80000] [D loss_whole: 0.303607, acc:  40%] [D loss_mask: 0.574184, acc:  40%] [G loss: 31.184082] time: 1:13:55.656453\n[Epoch 1183/80000] [D loss_whole: 0.290764, acc:  40%] [D loss_mask: 0.580546, acc:  39%] [G loss: 30.185192] time: 1:13:59.336264\n[Epoch 1184/80000] [D loss_whole: 0.265981, acc:  46%] [D loss_mask: 0.544160, acc:  43%] [G loss: 28.265982] time: 1:14:02.994954\n[Epoch 1185/80000] [D loss_whole: 0.301879, acc:  54%] [D loss_mask: 0.528611, acc:  47%] [G loss: 29.698362] time: 1:14:06.672020\n[Epoch 1186/80000] [D loss_whole: 0.330518, acc:  49%] [D loss_mask: 0.515474, acc:  50%] [G loss: 28.120369] time: 1:14:10.330745\n[Epoch 1187/80000] [D loss_whole: 0.352196, acc:  41%] [D loss_mask: 0.532344, acc:  51%] [G loss: 29.143494] time: 1:14:13.991162\n[Epoch 1188/80000] [D loss_whole: 0.398189, acc:  43%] [D loss_mask: 0.549704, acc:  50%] [G loss: 29.881723] time: 1:14:17.641163\n[Epoch 1189/80000] [D loss_whole: 0.525603, acc:  40%] [D loss_mask: 0.554563, acc:  42%] [G loss: 27.846189] time: 1:14:21.320233\n[Epoch 1190/80000] [D loss_whole: 0.444164, acc:  43%] [D loss_mask: 0.575755, acc:  45%] [G loss: 28.349693] time: 1:14:24.990058\n[Epoch 1191/80000] [D loss_whole: 0.346347, acc:  60%] [D loss_mask: 0.582980, acc:  52%] [G loss: 31.728649] time: 1:14:28.654363\n[Epoch 1192/80000] [D loss_whole: 0.307988, acc:  51%] [D loss_mask: 0.615277, acc:  44%] [G loss: 29.657019] time: 1:14:32.292062\n[Epoch 1193/80000] [D loss_whole: 0.256716, acc:  58%] [D loss_mask: 0.543396, acc:  44%] [G loss: 27.766121] time: 1:14:35.962294\n[Epoch 1194/80000] [D loss_whole: 0.246762, acc:  52%] [D loss_mask: 0.522134, acc:  48%] [G loss: 30.662918] time: 1:14:39.617398\n[Epoch 1195/80000] [D loss_whole: 0.320242, acc:  42%] [D loss_mask: 0.545800, acc:  43%] [G loss: 29.211256] time: 1:14:43.289082\n[Epoch 1196/80000] [D loss_whole: 0.296370, acc:  44%] [D loss_mask: 0.548059, acc:  41%] [G loss: 29.275946] time: 1:14:46.898143\n[Epoch 1197/80000] [D loss_whole: 0.257693, acc:  48%] [D loss_mask: 0.546305, acc:  41%] [G loss: 28.930120] time: 1:14:50.541277\n[Epoch 1198/80000] [D loss_whole: 0.249567, acc:  52%] [D loss_mask: 0.531051, acc:  44%] [G loss: 30.356487] time: 1:14:54.178723\n[Epoch 1199/80000] [D loss_whole: 0.251638, acc:  48%] [D loss_mask: 0.513651, acc:  52%] [G loss: 27.900833] time: 1:14:57.809752\n[Epoch 1200/80000] [D loss_whole: 0.272071, acc:  44%] [D loss_mask: 0.531265, acc:  43%] [G loss: 27.566357] time: 1:15:01.456853\nINFO:tensorflow:Assets written to: saved_models/inpaint_net1200/assets\n[Epoch 1201/80000] [D loss_whole: 0.263798, acc:  46%] [D loss_mask: 0.532670, acc:  49%] [G loss: 27.187777] time: 1:15:18.197397\n"}],"execution_count":null},{"cell_type":"code","source":"#!L\n","metadata":{"cellId":"hgn9uxrgojvv2lxmesacr9"},"outputs":[],"execution_count":null}]}