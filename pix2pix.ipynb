{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookId":"68f84228-f3f2-4b07-8241-2be2f562fe98","language_info":{"mimetype":"text/x-python","version":"3.7.7","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"name":"ipython","version":3}},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"code","source":"from __future__ import print_function, division\n\nimport datetime\nimport os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Input, Dropout, Concatenate\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import UpSampling2D, Conv2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nimport PIL.Image as Image\nfrom data_loader import DataLoader","metadata":{"cellId":"7ihj9ch40kb5cqavz4fsr5","execution_id":"2b13f94c-4524-4eca-a50b-0c4665314bee","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Pix2Pix():\n    def __init__(self):\n        self.img_rows = 256\n        self.img_cols = 256\n        self.channels = 3\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n\n        # Configure data loader\n        self.dataset_name = 'facades'\n        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n                                      img_res=(self.img_rows, self.img_cols))\n\n        # Calculate output shape of D (PatchGAN)\n        patch = int(self.img_rows / 2 ** 4)\n        self.disc_patch = (patch, patch, 1)\n\n        # Number of filters in the first layer of G and D\n        self.gf = 64\n        self.df = 64\n\n        optimizer = Adam(0.0002, 0.5)\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.summary()\n        self.discriminator.compile(loss='mse',\n                                   optimizer=optimizer,\n                                   metrics=['accuracy'])\n\n        self.discriminator_mask = self.build_discriminator()\n        self.discriminator_mask.compile(loss='mse', loss_weights=[2],\n                                        optimizer=optimizer,\n                                        metrics=['accuracy'])\n        # -------------------------\n        # Construct Computational\n        #   Graph of Generator\n        # -------------------------\n\n        # Build the generator\n        self.generator = self.build_generator()\n        self.generator.summary()\n\n        # Input images and their conditioning images\n        img_A = Input(shape=self.img_shape)\n        img_B = Input(shape=self.img_shape)\n\n        # By conditioning on B generate a fake version of A\n        fake_A = self.generator(img_B)\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n        self.discriminator_mask.trainable = False\n\n        # Discriminators determines validity of translated images / condition pairs\n        valid = self.discriminator([fake_A, img_B])\n        valid_mask = self.discriminator_mask([fake_A, img_B])\n\n        self.combined = Model(inputs=[img_A, img_B], outputs=[valid, valid_mask, fake_A])\n        self.combined.compile(loss=['mse', 'mse', 'mae'],\n                              loss_weights=[1, 2, 1],\n                              optimizer=optimizer)\n\n    def build_generator(self):\n        \"\"\"U-Net Generator\"\"\"\n\n        def conv2d(layer_input, filters, f_size=4, bn=True):\n            \"\"\"Layers used during downsampling\"\"\"\n            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n            d = LeakyReLU(alpha=0.2)(d)\n            if bn:\n                d = BatchNormalization(momentum=0.8)(d)\n            return d\n\n        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n            \"\"\"Layers used during upsampling\"\"\"\n            u = UpSampling2D(size=2)(layer_input)\n            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n            if dropout_rate:\n                u = Dropout(dropout_rate)(u)\n            u = BatchNormalization(momentum=0.8)(u)\n            u = Concatenate()([u, skip_input])\n            return u\n\n        # Image input\n        d0 = Input(shape=self.img_shape)\n\n        # Downsampling\n        d1 = conv2d(d0, self.gf, bn=False)\n        d2 = conv2d(d1, self.gf * 2)\n        d3 = conv2d(d2, self.gf * 4)\n        d4 = conv2d(d3, self.gf * 8)\n        d5 = conv2d(d4, self.gf * 8)\n        d6 = conv2d(d5, self.gf * 8)\n        d7 = conv2d(d6, self.gf * 8)\n\n        # Upsampling\n        u1 = deconv2d(d7, d6, self.gf * 8)\n        u2 = deconv2d(u1, d5, self.gf * 8)\n        u3 = deconv2d(u2, d4, self.gf * 8)\n        u4 = deconv2d(u3, d3, self.gf * 4)\n        u5 = deconv2d(u4, d2, self.gf * 2)\n        u6 = deconv2d(u5, d1, self.gf)\n\n        u7 = UpSampling2D(size=2)(u6)\n        output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n\n        return Model(d0, output_img)\n\n    def build_discriminator(self):\n\n        def d_layer(layer_input, filters, f_size=4, bn=True):\n            \"\"\"Discriminator layer\"\"\"\n            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n            d = LeakyReLU(alpha=0.2)(d)\n            if bn:\n                d = BatchNormalization(momentum=0.8)(d)\n            return d\n\n        img_A = Input(shape=self.img_shape)\n        img_B = Input(shape=self.img_shape)\n\n        # Concatenate image and conditioning image by channels to produce input\n        combined_imgs = Concatenate(axis=-1)([img_A, img_B])\n\n        d1 = d_layer(combined_imgs, self.df, bn=False)\n        d2 = d_layer(d1, self.df * 2)\n        d3 = d_layer(d2, self.df * 4)\n        d4 = d_layer(d3, self.df * 8)\n\n        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n\n        return Model([img_A, img_B], validity)\n\n    def train(self, epochs, batch_size=1, sample_interval=50):\n\n        start_time = datetime.datetime.now()\n\n        # Adversarial loss ground truths\n        valid = np.ones((64,) + self.disc_patch)\n        fake = np.zeros((64,) + self.disc_patch)\n\n        for epoch in range(epochs):\n            (imgs_A, imgs_B, mask) = self.data_loader.load_data()\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Condition on B and generate a translated version\n            fake_A = self.generator.predict(imgs_B)\n\n            # Train the discriminators (original images = real / generated = Fake)\n            d_loss_real = self.discriminator.train_on_batch([imgs_A, imgs_B], valid)\n            d_loss_fake = self.discriminator.train_on_batch([fake_A, imgs_B], fake)\n\n            d_loss_real_mask = self.discriminator_mask.train_on_batch([imgs_A, imgs_B], valid)\n            fake_A_mask = imgs_A * (1 - mask) + fake_A * mask\n            d_loss_fake_mask = self.discriminator_mask.train_on_batch([fake_A_mask, imgs_B], fake)\n\n            \n            d_loss_whole = 0.5 * np.add(d_loss_real, d_loss_fake)\n            d_loss_mask = 0.5 * np.add(d_loss_real_mask, d_loss_fake_mask)\n\n            # -----------------\n            #  Train Generator\n            # -----------------\n\n            # Train the generators\n            g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, valid, imgs_A])\n\n            elapsed_time = datetime.datetime.now() - start_time\n            # Plot the progress\n            print(\"[Epoch %d/%d] [D loss_whole: %f, acc: %3d%%] [D loss_mask: %f, acc: %3d%%] [G loss: %f] time: %s\" % (epoch, epochs,\n                                                                                    d_loss_whole[0],\n                                                                                    100 * d_loss_whole[1],\n                                                                                    d_loss_mask[0],\n                                                                                    100 * d_loss_mask[1],\n                                                                                    g_loss[0],\n                                                                                    elapsed_time))\n\n\n            # If at save interval => save generated image samples\n            # if epoch % sample_interval == 0:\n            if epoch % 100 == 0:\n                self.sample_images(epoch)\n                self.generator.save(\"saved_models/inpaint_net\" + str(epoch), save_format=\"tf\")\n\n    def sample_images(self, epoch):\n        imgs_A, imgs_B, _ = self.data_loader.load_data()\n        fake_A = self.generator.predict(imgs_B)\n\n        Image.fromarray(((0.5 * imgs_A[0] + 0.5) * 255).astype('uint8')).save(\"gan_images/real.png\")\n        Image.fromarray(((0.5 * imgs_B[0] + 0.5) * 255).astype('uint8')).save(\"gan_images/input.png\")\n        Image.fromarray(((0.5 * fake_A[0] + 0.5) * 255).astype('uint8')).save(\"gan_images/generated.png\")","metadata":{"cellId":"xcyb0y1znymkbxos4j4rzq","execution_id":"265f92f5-9dfb-45ac-b0da-52b692c51645","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!L\nif __name__ == '__main__':\n    gan = Pix2Pix()\n    gan.train(epochs=2000, batch_size=1, sample_interval=200)","metadata":{"cellId":"f099v62c3noygwhsm70zq","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 256, 256, 6)  0           input_1[0][0]                    \n                                                                 input_2[0][0]                    \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 128, 128, 64) 6208        concatenate[0][0]                \n__________________________________________________________________________________________________\nleaky_re_lu (LeakyReLU)         (None, 128, 128, 64) 0           conv2d[0][0]                     \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 64, 64, 128)  131200      leaky_re_lu[0][0]                \n__________________________________________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)       (None, 64, 64, 128)  0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 64, 64, 128)  512         leaky_re_lu_1[0][0]              \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 32, 32, 256)  524544      batch_normalization[0][0]        \n__________________________________________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)       (None, 32, 32, 256)  0           conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 32, 32, 256)  1024        leaky_re_lu_2[0][0]              \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 16, 16, 512)  2097664     batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 512)  0           conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 16, 16, 512)  2048        leaky_re_lu_3[0][0]              \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 16, 16, 1)    8193        batch_normalization_2[0][0]      \n==================================================================================================\nTotal params: 2,771,393\nTrainable params: 2,769,601\nNon-trainable params: 1,792\n__________________________________________________________________________________________________\nModel: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_5 (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 128, 128, 64) 3136        input_5[0][0]                    \n__________________________________________________________________________________________________\nleaky_re_lu_8 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 64, 64, 128)  131200      leaky_re_lu_8[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_9 (LeakyReLU)       (None, 64, 64, 128)  0           conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 64, 64, 128)  512         leaky_re_lu_9[0][0]              \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 32, 32, 256)  524544      batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nleaky_re_lu_10 (LeakyReLU)      (None, 32, 32, 256)  0           conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        leaky_re_lu_10[0][0]             \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 16, 16, 512)  2097664     batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nleaky_re_lu_11 (LeakyReLU)      (None, 16, 16, 512)  0           conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 16, 16, 512)  2048        leaky_re_lu_11[0][0]             \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 8, 8, 512)    4194816     batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nleaky_re_lu_12 (LeakyReLU)      (None, 8, 8, 512)    0           conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 8, 8, 512)    2048        leaky_re_lu_12[0][0]             \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 4, 4, 512)    4194816     batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nleaky_re_lu_13 (LeakyReLU)      (None, 4, 4, 512)    0           conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 4, 4, 512)    2048        leaky_re_lu_13[0][0]             \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 2, 2, 512)    4194816     batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nleaky_re_lu_14 (LeakyReLU)      (None, 2, 2, 512)    0           conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 2, 2, 512)    2048        leaky_re_lu_14[0][0]             \n__________________________________________________________________________________________________\nup_sampling2d (UpSampling2D)    (None, 4, 4, 512)    0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 4, 4, 512)    4194816     up_sampling2d[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 4, 4, 512)    2048        conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 4, 4, 1024)   0           batch_normalization_12[0][0]     \n                                                                 batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nup_sampling2d_1 (UpSampling2D)  (None, 8, 8, 1024)   0           concatenate_2[0][0]              \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 8, 8, 512)    8389120     up_sampling2d_1[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 8, 8, 512)    2048        conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 8, 8, 1024)   0           batch_normalization_13[0][0]     \n                                                                 batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nup_sampling2d_2 (UpSampling2D)  (None, 16, 16, 1024) 0           concatenate_3[0][0]              \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 16, 16, 512)  8389120     up_sampling2d_2[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 16, 16, 512)  2048        conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_4 (Concatenate)     (None, 16, 16, 1024) 0           batch_normalization_14[0][0]     \n                                                                 batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nup_sampling2d_3 (UpSampling2D)  (None, 32, 32, 1024) 0           concatenate_4[0][0]              \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 32, 32, 256)  4194560     up_sampling2d_3[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 32, 32, 256)  1024        conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_5 (Concatenate)     (None, 32, 32, 512)  0           batch_normalization_15[0][0]     \n                                                                 batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nup_sampling2d_4 (UpSampling2D)  (None, 64, 64, 512)  0           concatenate_5[0][0]              \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 64, 64, 128)  1048704     up_sampling2d_4[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 64, 64, 128)  512         conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_6 (Concatenate)     (None, 64, 64, 256)  0           batch_normalization_16[0][0]     \n                                                                 batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nup_sampling2d_5 (UpSampling2D)  (None, 128, 128, 256 0           concatenate_6[0][0]              \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 128, 128, 64) 262208      up_sampling2d_5[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 128, 128, 64) 256         conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_7 (Concatenate)     (None, 128, 128, 128 0           batch_normalization_17[0][0]     \n                                                                 leaky_re_lu_8[0][0]              \n__________________________________________________________________________________________________\nup_sampling2d_6 (UpSampling2D)  (None, 256, 256, 128 0           concatenate_7[0][0]              \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 256, 256, 3)  6147        up_sampling2d_6[0][0]            \n==================================================================================================\nTotal params: 41,843,331\nTrainable params: 41,834,499\nNon-trainable params: 8,832\n__________________________________________________________________________________________________\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\nWARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\nWARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\nWARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n[Epoch 0/2000] [D loss_whole: 12.211558, acc:  42%] [D loss_mask: 61.551392, acc:  44%] [G loss: 17.634817] time: 0:00:21.814399\n"},{"output_type":"error","ename":"ValueError","evalue":"too many values to unpack (expected 2)","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)","\u001B[0;32m<ipython-input-1-ecd11fd556b3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'__main__'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mgan\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPix2Pix\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mgan\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2000\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_interval\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m200\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m<ipython-input-4-492c78e80cd8>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, epochs, batch_size, sample_interval)\u001B[0m\n","\u001B[0;32m<ipython-input-4-492c78e80cd8>\u001B[0m in \u001B[0;36msample_images\u001B[0;34m(self, epoch)\u001B[0m\n","\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 2)"]}],"execution_count":78},{"cell_type":"code","source":"#!L\n","metadata":{"cellId":"hgn9uxrgojvv2lxmesacr9"},"outputs":[],"execution_count":null}]}