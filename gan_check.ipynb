{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookId":"d554e56d-ce68-42c3-bf8a-1a51081fb3f6","language_info":{"mimetype":"text/x-python","version":"3.7.7","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"}},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"code","source":"import cv2.cv2 as cv2\nimport numpy as np\nfrom tensorflow.keras.metrics import BinaryAccuracy\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.metrics import *\nimport random\nimport dataset\nimport os\n","metadata":{"cellId":"38z7nrkbu92a0ts089bz5t","trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def discriminator():\n    model = Sequential()\n\n    kernel_initializer = \"random_normal\"\n    kernel_regularizer = None\n    dropout_rate = 0.4\n    pool_size = (2, 2)\n    model.add(Conv2D(16, kernel_size=6, input_shape=(256, 256, 3), kernel_initializer=kernel_initializer,  kernel_regularizer=kernel_regularizer))\n    model.add(LeakyReLU())\n    model.add(MaxPool2D(pool_size=pool_size))\n    model.add(Conv2D(8, kernel_size=4, kernel_initializer=kernel_initializer,  kernel_regularizer=kernel_regularizer))\n    model.add(LeakyReLU())\n    model.add(MaxPool2D(pool_size=pool_size))\n    model.add(Conv2D(4, kernel_size=4, kernel_initializer=kernel_initializer,  kernel_regularizer=kernel_regularizer))\n    model.add(LeakyReLU())\n    model.add(MaxPool2D(pool_size=pool_size))\n    model.add(Conv2D(1, kernel_size=4, kernel_initializer=kernel_initializer,  kernel_regularizer=kernel_regularizer))\n    model.add(Flatten())\n    model.add(LeakyReLU())\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=kernel_initializer))\n    ba = BinaryAccuracy(\n        name=\"binary_accuracy\", threshold=0.5\n    )\n    model.compile(Adam(), \"binary_crossentropy\", metrics=[ba])\n    model.summary()\n\n    return model","metadata":{"cellId":"n78kuu945qc48wia7xgqw","trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def get_randoms(batch=32, lower_bound=0, upper_bound=9999, ):\n    rands = []\n    for i in range(0, batch):\n        rands.append(random.randint(lower_bound, upper_bound))\n    return rands\n\ndef load_data(everyone_dir, me_dir, batch):\n    indexes = get_randoms(batch=batch, lower_bound=0, upper_bound=1400)\n    me = dataset.sort_names(os.listdir(me_dir))\n    everyone = dataset.sort_names(os.listdir(everyone_dir))\n    images_me = [me[indexes[i]] for i in range(len(indexes))]\n    images_everyone = [everyone[indexes[i]] for i in range(len(indexes))]\n\n    me_pictures, _ = dataset.load_face_pictures_list(me_dir, images_me, color_mode=\"rgb\")\n    everyone_pictures, _ = dataset.load_face_pictures_list(everyone_dir, images_everyone, color_mode=\"rgb\")\n\n    return me_pictures, everyone_pictures","metadata":{"cellId":"ft4uw6mvhzvjdz57txhad","trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"#!g1.1\nif __name__ == '__main__':\n    model = discriminator()\n\n    batch = 64\n\n    me = np.ones(shape=(batch,))\n    not_me = np.zeros(shape=(batch,))\n\n    epochs = 4000\n\n    for epoch in range(epochs):\n        me_pictures, everyone_pictures = load_data(everyone_dir=\"./train_data/medical/CelebA-HQ-img-256-256\",\n                                                   me_dir=\"./me\", batch=batch)\n\n        me_pictures = me_pictures / 255\n        everyone_pictures = everyone_pictures / 255\n\n        features = np.concatenate((me_pictures, everyone_pictures))\n        labels = np.concatenate((me, not_me))\n\n        la = model.train_on_batch(features, labels)\n\n        print(\"[Epoch %d/%d] [loss: %f, acc: %f]\" % (\n            epoch, epochs,\n            la[0], la[1]))\n\n        if epoch % 100 == 0:\n            predicted = model.predict(features)\n#             cv2.imshow(\"imgae\", (features[12] * 255).astype('uint8'))\n#             k = cv2.waitKey(30) & 0xff\n#             if k == 27:\n#                 break\n            print(\"Real: \" + str(labels[12]))\n            print(\"Generated: \" + str(predicted[12]))\n            model.save(\"./saved_models/\" + str(epoch) + \"classifier\", save_format=\"tf\")","metadata":{"cellId":"qn33fijabt9lc3nceuj3rg","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nWARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 251, 251, 16)      1744      \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, 251, 251, 16)      0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 125, 125, 16)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 122, 122, 8)       2056      \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 122, 122, 8)       0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 61, 61, 8)         0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 58, 58, 4)         516       \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 58, 58, 4)         0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 29, 29, 4)         0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 26, 26, 1)         65        \n_________________________________________________________________\nflatten (Flatten)            (None, 676)               0         \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 676)               0         \n_________________________________________________________________\ndropout (Dropout)            (None, 676)               0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 677       \n=================================================================\nTotal params: 5,058\nTrainable params: 5,058\nNon-trainable params: 0\n_________________________________________________________________\n[Epoch 0/4000] [loss: 0.693287, acc: 0.484375]\nReal: 1.0\nGenerated: [0.49891844]\nINFO:tensorflow:Assets written to: ./saved_models/0classifier/assets\n[Epoch 1/4000] [loss: 0.692783, acc: 0.554688]\n[Epoch 2/4000] [loss: 0.692189, acc: 0.539062]\n[Epoch 3/4000] [loss: 0.692100, acc: 0.554688]\n[Epoch 4/4000] [loss: 0.691792, acc: 0.562500]\n[Epoch 5/4000] [loss: 0.690732, acc: 0.625000]\n[Epoch 6/4000] [loss: 0.689746, acc: 0.648438]\n[Epoch 7/4000] [loss: 0.688086, acc: 0.703125]\n[Epoch 8/4000] [loss: 0.688406, acc: 0.570312]\n[Epoch 9/4000] [loss: 0.682460, acc: 0.703125]\n[Epoch 10/4000] [loss: 0.681903, acc: 0.671875]\n[Epoch 11/4000] [loss: 0.677998, acc: 0.656250]\n[Epoch 12/4000] [loss: 0.673140, acc: 0.679688]\n[Epoch 13/4000] [loss: 0.674769, acc: 0.625000]\n[Epoch 14/4000] [loss: 0.654296, acc: 0.742188]\n[Epoch 15/4000] [loss: 0.637846, acc: 0.703125]\n[Epoch 16/4000] [loss: 0.624530, acc: 0.679688]\n[Epoch 17/4000] [loss: 0.609839, acc: 0.718750]\n[Epoch 18/4000] [loss: 0.611377, acc: 0.710938]\n[Epoch 19/4000] [loss: 0.575335, acc: 0.710938]\n[Epoch 20/4000] [loss: 0.538636, acc: 0.773438]\n[Epoch 21/4000] [loss: 0.524025, acc: 0.796875]\n[Epoch 22/4000] [loss: 0.497097, acc: 0.789062]\n[Epoch 23/4000] [loss: 0.479626, acc: 0.789062]\n[Epoch 24/4000] [loss: 0.467785, acc: 0.789062]\n[Epoch 25/4000] [loss: 0.474019, acc: 0.781250]\n[Epoch 26/4000] [loss: 0.494579, acc: 0.781250]\n[Epoch 27/4000] [loss: 0.365038, acc: 0.812500]\n[Epoch 28/4000] [loss: 0.432537, acc: 0.851562]\n[Epoch 29/4000] [loss: 0.294056, acc: 0.898438]\n[Epoch 30/4000] [loss: 0.370514, acc: 0.828125]\n[Epoch 31/4000] [loss: 0.426336, acc: 0.835938]\n[Epoch 32/4000] [loss: 0.299726, acc: 0.859375]\n[Epoch 33/4000] [loss: 0.416878, acc: 0.789062]\n[Epoch 34/4000] [loss: 0.322619, acc: 0.859375]\n[Epoch 35/4000] [loss: 0.421841, acc: 0.859375]\n[Epoch 36/4000] [loss: 0.435413, acc: 0.843750]\n[Epoch 37/4000] [loss: 0.430825, acc: 0.835938]\n[Epoch 38/4000] [loss: 0.333650, acc: 0.898438]\n[Epoch 39/4000] [loss: 0.441005, acc: 0.789062]\n[Epoch 40/4000] [loss: 0.294037, acc: 0.882812]\n[Epoch 41/4000] [loss: 0.358197, acc: 0.882812]\n[Epoch 42/4000] [loss: 0.398394, acc: 0.843750]\n[Epoch 43/4000] [loss: 0.329282, acc: 0.882812]\n[Epoch 44/4000] [loss: 0.214069, acc: 0.914062]\n[Epoch 45/4000] [loss: 0.386395, acc: 0.859375]\n[Epoch 46/4000] [loss: 0.308787, acc: 0.898438]\n[Epoch 47/4000] [loss: 0.362474, acc: 0.882812]\n[Epoch 48/4000] [loss: 0.489796, acc: 0.781250]\n[Epoch 49/4000] [loss: 0.327681, acc: 0.882812]\n[Epoch 50/4000] [loss: 0.247813, acc: 0.914062]\n[Epoch 51/4000] [loss: 0.262066, acc: 0.890625]\n[Epoch 52/4000] [loss: 0.309018, acc: 0.890625]\n[Epoch 53/4000] [loss: 0.294869, acc: 0.906250]\n[Epoch 54/4000] [loss: 0.311839, acc: 0.882812]\n[Epoch 55/4000] [loss: 0.416755, acc: 0.843750]\n[Epoch 56/4000] [loss: 0.264067, acc: 0.859375]\n[Epoch 57/4000] [loss: 0.325456, acc: 0.890625]\n[Epoch 58/4000] [loss: 0.240806, acc: 0.906250]\n[Epoch 59/4000] [loss: 0.388447, acc: 0.898438]\n[Epoch 60/4000] [loss: 0.406301, acc: 0.843750]\n[Epoch 61/4000] [loss: 0.308959, acc: 0.875000]\n[Epoch 62/4000] [loss: 0.238675, acc: 0.921875]\n[Epoch 63/4000] [loss: 0.245939, acc: 0.914062]\n[Epoch 64/4000] [loss: 0.277516, acc: 0.906250]\n[Epoch 65/4000] [loss: 0.286085, acc: 0.906250]\n[Epoch 66/4000] [loss: 0.315422, acc: 0.914062]\n[Epoch 67/4000] [loss: 0.307079, acc: 0.867188]\n[Epoch 68/4000] [loss: 0.264489, acc: 0.875000]\n[Epoch 69/4000] [loss: 0.270415, acc: 0.914062]\n[Epoch 70/4000] [loss: 0.270627, acc: 0.859375]\n[Epoch 71/4000] [loss: 0.232911, acc: 0.937500]\n[Epoch 72/4000] [loss: 0.300295, acc: 0.914062]\n[Epoch 73/4000] [loss: 0.216803, acc: 0.929688]\n[Epoch 74/4000] [loss: 0.250205, acc: 0.914062]\n[Epoch 75/4000] [loss: 0.256859, acc: 0.890625]\n[Epoch 76/4000] [loss: 0.325425, acc: 0.898438]\n[Epoch 77/4000] [loss: 0.204889, acc: 0.921875]\n[Epoch 78/4000] [loss: 0.188840, acc: 0.929688]\n[Epoch 79/4000] [loss: 0.248852, acc: 0.898438]\n[Epoch 80/4000] [loss: 0.190445, acc: 0.945312]\n[Epoch 81/4000] [loss: 0.187779, acc: 0.929688]\n[Epoch 82/4000] [loss: 0.260166, acc: 0.906250]\n[Epoch 83/4000] [loss: 0.315529, acc: 0.890625]\n[Epoch 84/4000] [loss: 0.143204, acc: 0.953125]\n[Epoch 85/4000] [loss: 0.148302, acc: 0.945312]\n[Epoch 86/4000] [loss: 0.256513, acc: 0.882812]\n[Epoch 87/4000] [loss: 0.253124, acc: 0.929688]\n[Epoch 88/4000] [loss: 0.255113, acc: 0.882812]\n[Epoch 89/4000] [loss: 0.146398, acc: 0.960938]\n[Epoch 90/4000] [loss: 0.221110, acc: 0.906250]\n[Epoch 91/4000] [loss: 0.225528, acc: 0.914062]\n[Epoch 92/4000] [loss: 0.369601, acc: 0.851562]\n[Epoch 93/4000] [loss: 0.247367, acc: 0.898438]\n[Epoch 94/4000] [loss: 0.149254, acc: 0.945312]\n[Epoch 95/4000] [loss: 0.250765, acc: 0.921875]\n[Epoch 96/4000] [loss: 0.188143, acc: 0.937500]\n[Epoch 97/4000] [loss: 0.170750, acc: 0.945312]\n[Epoch 98/4000] [loss: 0.191898, acc: 0.906250]\n[Epoch 99/4000] [loss: 0.170015, acc: 0.945312]\n[Epoch 100/4000] [loss: 0.250423, acc: 0.875000]\nReal: 1.0\nGenerated: [0.8575017]\nINFO:tensorflow:Assets written to: ./saved_models/100classifier/assets\n[Epoch 101/4000] [loss: 0.240286, acc: 0.914062]\n[Epoch 102/4000] [loss: 0.179673, acc: 0.937500]\n[Epoch 103/4000] [loss: 0.186117, acc: 0.921875]\n[Epoch 104/4000] [loss: 0.190514, acc: 0.914062]\n[Epoch 105/4000] [loss: 0.178292, acc: 0.945312]\n[Epoch 106/4000] [loss: 0.248607, acc: 0.882812]\n[Epoch 107/4000] [loss: 0.178608, acc: 0.945312]\n[Epoch 108/4000] [loss: 0.185696, acc: 0.929688]\n[Epoch 109/4000] [loss: 0.185966, acc: 0.960938]\n[Epoch 110/4000] [loss: 0.236835, acc: 0.914062]\n[Epoch 111/4000] [loss: 0.161556, acc: 0.953125]\n[Epoch 112/4000] [loss: 0.196068, acc: 0.921875]\n[Epoch 113/4000] [loss: 0.160023, acc: 0.945312]\n[Epoch 114/4000] [loss: 0.172459, acc: 0.937500]\n[Epoch 115/4000] [loss: 0.211964, acc: 0.914062]\n[Epoch 116/4000] [loss: 0.136326, acc: 0.953125]\n[Epoch 117/4000] [loss: 0.154545, acc: 0.968750]\n[Epoch 118/4000] [loss: 0.180632, acc: 0.968750]\n[Epoch 119/4000] [loss: 0.151567, acc: 0.953125]\n[Epoch 120/4000] [loss: 0.114741, acc: 0.960938]\n[Epoch 121/4000] [loss: 0.199763, acc: 0.945312]\n[Epoch 122/4000] [loss: 0.146237, acc: 0.937500]\n[Epoch 123/4000] [loss: 0.119613, acc: 0.953125]\n[Epoch 124/4000] [loss: 0.115455, acc: 0.960938]\n[Epoch 125/4000] [loss: 0.133797, acc: 0.960938]\n[Epoch 126/4000] [loss: 0.263142, acc: 0.929688]\n[Epoch 127/4000] [loss: 0.130677, acc: 0.968750]\n[Epoch 128/4000] [loss: 0.080882, acc: 0.960938]\n[Epoch 129/4000] [loss: 0.123677, acc: 0.960938]\n[Epoch 130/4000] [loss: 0.089390, acc: 0.960938]\n[Epoch 131/4000] [loss: 0.179111, acc: 0.945312]\n[Epoch 132/4000] [loss: 0.078500, acc: 0.976562]\n[Epoch 133/4000] [loss: 0.209880, acc: 0.929688]\n[Epoch 134/4000] [loss: 0.103744, acc: 0.968750]\n[Epoch 135/4000] [loss: 0.115280, acc: 0.960938]\n[Epoch 136/4000] [loss: 0.125839, acc: 0.960938]\n[Epoch 137/4000] [loss: 0.084274, acc: 0.984375]\n[Epoch 138/4000] [loss: 0.107612, acc: 0.953125]\n[Epoch 139/4000] [loss: 0.161472, acc: 0.945312]\n[Epoch 140/4000] [loss: 0.085987, acc: 0.976562]\n[Epoch 141/4000] [loss: 0.107293, acc: 0.960938]\n[Epoch 142/4000] [loss: 0.125413, acc: 0.945312]\n[Epoch 143/4000] [loss: 0.127090, acc: 0.960938]\n[Epoch 144/4000] [loss: 0.124556, acc: 0.976562]\n[Epoch 145/4000] [loss: 0.119720, acc: 0.945312]\n[Epoch 146/4000] [loss: 0.066004, acc: 0.976562]\n[Epoch 147/4000] [loss: 0.057378, acc: 0.984375]\n[Epoch 148/4000] [loss: 0.083567, acc: 0.968750]\n[Epoch 149/4000] [loss: 0.109439, acc: 0.960938]\n[Epoch 150/4000] [loss: 0.055617, acc: 0.992188]\n[Epoch 151/4000] [loss: 0.073755, acc: 0.976562]\n[Epoch 152/4000] [loss: 0.062673, acc: 0.976562]\n[Epoch 153/4000] [loss: 0.145460, acc: 0.953125]\n[Epoch 154/4000] [loss: 0.140991, acc: 0.953125]\n[Epoch 155/4000] [loss: 0.051257, acc: 0.968750]\n[Epoch 156/4000] [loss: 0.118043, acc: 0.960938]\n[Epoch 157/4000] [loss: 0.085797, acc: 0.960938]\n[Epoch 158/4000] [loss: 0.125764, acc: 0.960938]\n[Epoch 159/4000] [loss: 0.082325, acc: 0.976562]\n[Epoch 160/4000] [loss: 0.144424, acc: 0.953125]\n[Epoch 161/4000] [loss: 0.077920, acc: 0.968750]\n[Epoch 162/4000] [loss: 0.152866, acc: 0.929688]\n[Epoch 163/4000] [loss: 0.079896, acc: 0.945312]\n[Epoch 164/4000] [loss: 0.051258, acc: 0.992188]\n[Epoch 165/4000] [loss: 0.123680, acc: 0.937500]\n[Epoch 166/4000] [loss: 0.103060, acc: 0.937500]\n[Epoch 167/4000] [loss: 0.066156, acc: 0.984375]\n[Epoch 168/4000] [loss: 0.059353, acc: 0.984375]\n[Epoch 169/4000] [loss: 0.038858, acc: 0.992188]\n[Epoch 170/4000] [loss: 0.063195, acc: 0.984375]\n[Epoch 171/4000] [loss: 0.048974, acc: 0.984375]\n[Epoch 172/4000] [loss: 0.080436, acc: 0.960938]\n[Epoch 173/4000] [loss: 0.078373, acc: 0.984375]\n[Epoch 174/4000] [loss: 0.088861, acc: 0.960938]\n[Epoch 175/4000] [loss: 0.049375, acc: 0.984375]\n[Epoch 176/4000] [loss: 0.136967, acc: 0.960938]\n[Epoch 177/4000] [loss: 0.070546, acc: 0.992188]\n[Epoch 178/4000] [loss: 0.079607, acc: 0.984375]\n[Epoch 179/4000] [loss: 0.056458, acc: 0.976562]\n[Epoch 180/4000] [loss: 0.124354, acc: 0.937500]\n[Epoch 181/4000] [loss: 0.075048, acc: 0.984375]\n[Epoch 182/4000] [loss: 0.072074, acc: 0.976562]\n[Epoch 183/4000] [loss: 0.043396, acc: 0.984375]\n[Epoch 184/4000] [loss: 0.073688, acc: 0.968750]\n[Epoch 185/4000] [loss: 0.051615, acc: 0.992188]\n[Epoch 186/4000] [loss: 0.108906, acc: 0.953125]\n[Epoch 187/4000] [loss: 0.053085, acc: 0.992188]\n[Epoch 188/4000] [loss: 0.100505, acc: 0.968750]\n[Epoch 189/4000] [loss: 0.041035, acc: 0.992188]\n[Epoch 190/4000] [loss: 0.061740, acc: 0.960938]\n[Epoch 191/4000] [loss: 0.095363, acc: 0.976562]\n[Epoch 192/4000] [loss: 0.052244, acc: 0.984375]\n[Epoch 193/4000] [loss: 0.055557, acc: 0.984375]\n[Epoch 194/4000] [loss: 0.038774, acc: 0.992188]\n[Epoch 195/4000] [loss: 0.035840, acc: 0.992188]\n[Epoch 196/4000] [loss: 0.072020, acc: 0.976562]\n[Epoch 197/4000] [loss: 0.051587, acc: 0.992188]\n[Epoch 198/4000] [loss: 0.032585, acc: 0.992188]\n[Epoch 199/4000] [loss: 0.119455, acc: 0.976562]\n[Epoch 200/4000] [loss: 0.083655, acc: 0.968750]\nReal: 1.0\nGenerated: [0.99618745]\nINFO:tensorflow:Assets written to: ./saved_models/200classifier/assets\n[Epoch 201/4000] [loss: 0.053861, acc: 0.984375]\n[Epoch 202/4000] [loss: 0.061430, acc: 0.976562]\n[Epoch 203/4000] [loss: 0.044436, acc: 0.984375]\n[Epoch 204/4000] [loss: 0.025788, acc: 1.000000]\n[Epoch 205/4000] [loss: 0.048450, acc: 0.976562]\n[Epoch 206/4000] [loss: 0.053574, acc: 0.984375]\n[Epoch 207/4000] [loss: 0.024301, acc: 0.992188]\n[Epoch 208/4000] [loss: 0.059631, acc: 0.968750]\n[Epoch 209/4000] [loss: 0.033745, acc: 0.992188]\n[Epoch 210/4000] [loss: 0.056972, acc: 0.984375]\n[Epoch 211/4000] [loss: 0.050491, acc: 0.984375]\n[Epoch 212/4000] [loss: 0.090230, acc: 0.960938]\n[Epoch 213/4000] [loss: 0.022987, acc: 1.000000]\n[Epoch 214/4000] [loss: 0.030626, acc: 0.992188]\n[Epoch 215/4000] [loss: 0.070292, acc: 0.968750]\n[Epoch 216/4000] [loss: 0.045395, acc: 0.968750]\n[Epoch 217/4000] [loss: 0.113601, acc: 0.968750]\n[Epoch 218/4000] [loss: 0.096059, acc: 0.968750]\n[Epoch 219/4000] [loss: 0.028511, acc: 0.992188]\n[Epoch 220/4000] [loss: 0.130119, acc: 0.968750]\n[Epoch 221/4000] [loss: 0.085264, acc: 0.960938]\n[Epoch 222/4000] [loss: 0.085410, acc: 0.960938]\n[Epoch 223/4000] [loss: 0.047418, acc: 0.992188]\n[Epoch 224/4000] [loss: 0.037860, acc: 0.984375]\n[Epoch 225/4000] [loss: 0.057454, acc: 0.984375]\n[Epoch 226/4000] [loss: 0.062064, acc: 0.984375]\n[Epoch 227/4000] [loss: 0.105647, acc: 0.976562]\n[Epoch 228/4000] [loss: 0.018869, acc: 0.992188]\n[Epoch 229/4000] [loss: 0.025439, acc: 0.976562]\n[Epoch 230/4000] [loss: 0.044307, acc: 0.976562]\n[Epoch 231/4000] [loss: 0.036854, acc: 0.984375]\n[Epoch 232/4000] [loss: 0.049963, acc: 0.992188]\n[Epoch 233/4000] [loss: 0.045179, acc: 0.984375]\n[Epoch 234/4000] [loss: 0.100307, acc: 0.976562]\n[Epoch 235/4000] [loss: 0.084992, acc: 0.968750]\n[Epoch 236/4000] [loss: 0.030951, acc: 0.984375]\n[Epoch 237/4000] [loss: 0.048877, acc: 0.992188]\n[Epoch 238/4000] [loss: 0.047733, acc: 0.992188]\n[Epoch 239/4000] [loss: 0.021506, acc: 0.992188]\n[Epoch 240/4000] [loss: 0.039559, acc: 0.992188]\n[Epoch 241/4000] [loss: 0.032112, acc: 0.984375]\n[Epoch 242/4000] [loss: 0.042028, acc: 0.992188]\n[Epoch 243/4000] [loss: 0.011532, acc: 1.000000]\n[Epoch 244/4000] [loss: 0.066684, acc: 0.984375]\n[Epoch 245/4000] [loss: 0.018385, acc: 0.992188]\n[Epoch 246/4000] [loss: 0.070655, acc: 0.968750]\n[Epoch 247/4000] [loss: 0.138061, acc: 0.968750]\n[Epoch 248/4000] [loss: 0.046859, acc: 0.984375]\n[Epoch 249/4000] [loss: 0.038454, acc: 0.984375]\n[Epoch 250/4000] [loss: 0.037441, acc: 0.992188]\n[Epoch 251/4000] [loss: 0.023926, acc: 1.000000]\n[Epoch 252/4000] [loss: 0.035582, acc: 0.984375]\n[Epoch 253/4000] [loss: 0.035438, acc: 0.992188]\n[Epoch 254/4000] [loss: 0.033221, acc: 0.992188]\n[Epoch 255/4000] [loss: 0.053900, acc: 0.984375]\n[Epoch 256/4000] [loss: 0.038925, acc: 0.992188]\n[Epoch 257/4000] [loss: 0.052989, acc: 0.984375]\n[Epoch 258/4000] [loss: 0.011623, acc: 1.000000]\n[Epoch 259/4000] [loss: 0.026424, acc: 0.992188]\n[Epoch 260/4000] [loss: 0.035668, acc: 0.984375]\n[Epoch 261/4000] [loss: 0.037438, acc: 0.992188]\n[Epoch 262/4000] [loss: 0.016940, acc: 1.000000]\n[Epoch 263/4000] [loss: 0.056008, acc: 0.976562]\n[Epoch 264/4000] [loss: 0.033090, acc: 0.984375]\n[Epoch 265/4000] [loss: 0.035381, acc: 0.992188]\n[Epoch 266/4000] [loss: 0.030120, acc: 0.992188]\n[Epoch 267/4000] [loss: 0.023387, acc: 1.000000]\n[Epoch 268/4000] [loss: 0.011858, acc: 1.000000]\n[Epoch 269/4000] [loss: 0.023111, acc: 0.992188]\n[Epoch 270/4000] [loss: 0.045367, acc: 0.984375]\n[Epoch 271/4000] [loss: 0.041854, acc: 0.976562]\n[Epoch 272/4000] [loss: 0.039525, acc: 0.984375]\n[Epoch 273/4000] [loss: 0.033598, acc: 0.984375]\n[Epoch 274/4000] [loss: 0.029160, acc: 0.992188]\n[Epoch 275/4000] [loss: 0.021340, acc: 0.992188]\n[Epoch 276/4000] [loss: 0.057784, acc: 0.984375]\n[Epoch 277/4000] [loss: 0.018018, acc: 0.992188]\n[Epoch 278/4000] [loss: 0.024263, acc: 0.992188]\n[Epoch 279/4000] [loss: 0.009261, acc: 1.000000]\n[Epoch 280/4000] [loss: 0.008210, acc: 1.000000]\n[Epoch 281/4000] [loss: 0.024607, acc: 0.992188]\n[Epoch 282/4000] [loss: 0.031318, acc: 0.992188]\n[Epoch 283/4000] [loss: 0.067333, acc: 0.968750]\n[Epoch 284/4000] [loss: 0.010002, acc: 1.000000]\n[Epoch 285/4000] [loss: 0.068616, acc: 0.984375]\n[Epoch 286/4000] [loss: 0.037100, acc: 0.984375]\n[Epoch 287/4000] [loss: 0.028819, acc: 0.984375]\n[Epoch 288/4000] [loss: 0.029269, acc: 0.992188]\n[Epoch 289/4000] [loss: 0.012241, acc: 1.000000]\n[Epoch 290/4000] [loss: 0.031589, acc: 0.984375]\n[Epoch 291/4000] [loss: 0.038976, acc: 0.976562]\n[Epoch 292/4000] [loss: 0.077302, acc: 0.968750]\n[Epoch 293/4000] [loss: 0.021464, acc: 0.992188]\n[Epoch 294/4000] [loss: 0.046268, acc: 0.984375]\n[Epoch 295/4000] [loss: 0.063562, acc: 0.984375]\n[Epoch 296/4000] [loss: 0.013357, acc: 1.000000]\n[Epoch 297/4000] [loss: 0.015911, acc: 0.992188]\n[Epoch 298/4000] [loss: 0.019600, acc: 0.992188]\n[Epoch 299/4000] [loss: 0.049461, acc: 0.976562]\n[Epoch 300/4000] [loss: 0.033437, acc: 0.984375]\nReal: 1.0\nGenerated: [0.9988804]\nINFO:tensorflow:Assets written to: ./saved_models/300classifier/assets\n[Epoch 301/4000] [loss: 0.018793, acc: 1.000000]\n[Epoch 302/4000] [loss: 0.013641, acc: 1.000000]\n[Epoch 303/4000] [loss: 0.032441, acc: 0.992188]\n[Epoch 304/4000] [loss: 0.025629, acc: 0.992188]\n[Epoch 305/4000] [loss: 0.037842, acc: 0.976562]\n[Epoch 306/4000] [loss: 0.042487, acc: 0.976562]\n[Epoch 307/4000] [loss: 0.021619, acc: 0.992188]\n[Epoch 308/4000] [loss: 0.018495, acc: 0.992188]\n[Epoch 309/4000] [loss: 0.046312, acc: 0.992188]\n[Epoch 310/4000] [loss: 0.028982, acc: 0.992188]\n[Epoch 311/4000] [loss: 0.007476, acc: 1.000000]\n[Epoch 312/4000] [loss: 0.027652, acc: 0.992188]\n[Epoch 313/4000] [loss: 0.026024, acc: 0.992188]\n[Epoch 314/4000] [loss: 0.016656, acc: 1.000000]\n[Epoch 315/4000] [loss: 0.014110, acc: 1.000000]\n[Epoch 316/4000] [loss: 0.014599, acc: 1.000000]\n[Epoch 317/4000] [loss: 0.015153, acc: 1.000000]\n[Epoch 318/4000] [loss: 0.028240, acc: 0.992188]\n[Epoch 319/4000] [loss: 0.040246, acc: 0.984375]\n[Epoch 320/4000] [loss: 0.013367, acc: 0.992188]\n[Epoch 321/4000] [loss: 0.012863, acc: 0.992188]\n[Epoch 322/4000] [loss: 0.015133, acc: 1.000000]\n[Epoch 323/4000] [loss: 0.025535, acc: 0.984375]\n[Epoch 324/4000] [loss: 0.029753, acc: 0.992188]\n[Epoch 325/4000] [loss: 0.024214, acc: 0.992188]\n[Epoch 326/4000] [loss: 0.038918, acc: 0.992188]\n[Epoch 327/4000] [loss: 0.013074, acc: 1.000000]\n[Epoch 328/4000] [loss: 0.008589, acc: 1.000000]\n[Epoch 329/4000] [loss: 0.021176, acc: 0.992188]\n[Epoch 330/4000] [loss: 0.020818, acc: 0.984375]\n[Epoch 331/4000] [loss: 0.020723, acc: 0.992188]\n[Epoch 332/4000] [loss: 0.003437, acc: 1.000000]\n[Epoch 333/4000] [loss: 0.010275, acc: 1.000000]\n[Epoch 334/4000] [loss: 0.010601, acc: 1.000000]\n[Epoch 335/4000] [loss: 0.013705, acc: 0.992188]\n[Epoch 336/4000] [loss: 0.041191, acc: 0.976562]\n[Epoch 337/4000] [loss: 0.021913, acc: 0.984375]\n[Epoch 338/4000] [loss: 0.007270, acc: 1.000000]\n[Epoch 339/4000] [loss: 0.003022, acc: 1.000000]\n[Epoch 340/4000] [loss: 0.018669, acc: 1.000000]\n[Epoch 341/4000] [loss: 0.074207, acc: 0.984375]\n[Epoch 342/4000] [loss: 0.005529, acc: 1.000000]\n[Epoch 343/4000] [loss: 0.003947, acc: 1.000000]\n[Epoch 344/4000] [loss: 0.012482, acc: 1.000000]\n[Epoch 345/4000] [loss: 0.031936, acc: 0.976562]\n[Epoch 346/4000] [loss: 0.027959, acc: 0.992188]\n[Epoch 347/4000] [loss: 0.013948, acc: 1.000000]\n[Epoch 348/4000] [loss: 0.006907, acc: 1.000000]\n[Epoch 349/4000] [loss: 0.015992, acc: 1.000000]\n[Epoch 350/4000] [loss: 0.008415, acc: 1.000000]\n[Epoch 351/4000] [loss: 0.011782, acc: 0.992188]\n[Epoch 352/4000] [loss: 0.012866, acc: 0.992188]\n[Epoch 353/4000] [loss: 0.010885, acc: 1.000000]\n[Epoch 354/4000] [loss: 0.056893, acc: 0.992188]\n[Epoch 355/4000] [loss: 0.024861, acc: 0.992188]\n[Epoch 356/4000] [loss: 0.007948, acc: 1.000000]\n[Epoch 357/4000] [loss: 0.016763, acc: 0.992188]\n[Epoch 358/4000] [loss: 0.033212, acc: 0.976562]\n[Epoch 359/4000] [loss: 0.026771, acc: 0.976562]\n[Epoch 360/4000] [loss: 0.008739, acc: 1.000000]\n[Epoch 361/4000] [loss: 0.007848, acc: 1.000000]\n[Epoch 362/4000] [loss: 0.061530, acc: 0.976562]\n[Epoch 363/4000] [loss: 0.006200, acc: 1.000000]\n[Epoch 364/4000] [loss: 0.038688, acc: 0.992188]\n[Epoch 365/4000] [loss: 0.001736, acc: 1.000000]\n[Epoch 366/4000] [loss: 0.004722, acc: 1.000000]\n[Epoch 367/4000] [loss: 0.006917, acc: 1.000000]\n[Epoch 368/4000] [loss: 0.002544, acc: 1.000000]\n[Epoch 369/4000] [loss: 0.011189, acc: 0.992188]\n[Epoch 370/4000] [loss: 0.031642, acc: 0.992188]\n[Epoch 371/4000] [loss: 0.007813, acc: 1.000000]\n[Epoch 372/4000] [loss: 0.014088, acc: 0.992188]\n[Epoch 373/4000] [loss: 0.003231, acc: 1.000000]\n[Epoch 374/4000] [loss: 0.004472, acc: 1.000000]\n[Epoch 375/4000] [loss: 0.036724, acc: 0.992188]\n[Epoch 376/4000] [loss: 0.006229, acc: 1.000000]\n[Epoch 377/4000] [loss: 0.003234, acc: 1.000000]\n[Epoch 378/4000] [loss: 0.016454, acc: 0.992188]\n[Epoch 379/4000] [loss: 0.033651, acc: 0.992188]\n[Epoch 380/4000] [loss: 0.007984, acc: 1.000000]\n[Epoch 381/4000] [loss: 0.013179, acc: 1.000000]\n[Epoch 382/4000] [loss: 0.010736, acc: 1.000000]\n[Epoch 383/4000] [loss: 0.011843, acc: 1.000000]\n[Epoch 384/4000] [loss: 0.012827, acc: 0.992188]\n[Epoch 385/4000] [loss: 0.017299, acc: 0.992188]\n[Epoch 386/4000] [loss: 0.011123, acc: 1.000000]\n[Epoch 387/4000] [loss: 0.007233, acc: 1.000000]\n[Epoch 388/4000] [loss: 0.067184, acc: 0.992188]\n[Epoch 389/4000] [loss: 0.005569, acc: 1.000000]\n[Epoch 390/4000] [loss: 0.004033, acc: 1.000000]\n[Epoch 391/4000] [loss: 0.015781, acc: 0.992188]\n[Epoch 392/4000] [loss: 0.018782, acc: 0.992188]\n[Epoch 393/4000] [loss: 0.016070, acc: 0.992188]\n[Epoch 394/4000] [loss: 0.005671, acc: 1.000000]\n[Epoch 395/4000] [loss: 0.007012, acc: 1.000000]\n[Epoch 396/4000] [loss: 0.006259, acc: 1.000000]\n[Epoch 397/4000] [loss: 0.011221, acc: 0.992188]\n[Epoch 398/4000] [loss: 0.005634, acc: 1.000000]\n[Epoch 399/4000] [loss: 0.010854, acc: 1.000000]\n[Epoch 400/4000] [loss: 0.023664, acc: 0.992188]\nReal: 1.0\nGenerated: [0.99999905]\nINFO:tensorflow:Assets written to: ./saved_models/400classifier/assets\n[Epoch 401/4000] [loss: 0.021894, acc: 0.992188]\n[Epoch 402/4000] [loss: 0.006101, acc: 1.000000]\n[Epoch 403/4000] [loss: 0.001454, acc: 1.000000]\n[Epoch 404/4000] [loss: 0.023646, acc: 0.984375]\n[Epoch 405/4000] [loss: 0.003324, acc: 1.000000]\n[Epoch 406/4000] [loss: 0.022394, acc: 0.992188]\n[Epoch 407/4000] [loss: 0.009150, acc: 1.000000]\n[Epoch 408/4000] [loss: 0.008878, acc: 1.000000]\n[Epoch 409/4000] [loss: 0.014408, acc: 0.992188]\n[Epoch 410/4000] [loss: 0.009547, acc: 1.000000]\n[Epoch 411/4000] [loss: 0.015679, acc: 1.000000]\n[Epoch 412/4000] [loss: 0.004770, acc: 1.000000]\n[Epoch 413/4000] [loss: 0.010976, acc: 1.000000]\n[Epoch 414/4000] [loss: 0.010639, acc: 1.000000]\n[Epoch 415/4000] [loss: 0.004472, acc: 1.000000]\n[Epoch 416/4000] [loss: 0.012368, acc: 0.992188]\n[Epoch 417/4000] [loss: 0.017249, acc: 0.992188]\n[Epoch 418/4000] [loss: 0.029529, acc: 0.984375]\n[Epoch 419/4000] [loss: 0.025142, acc: 0.992188]\n[Epoch 420/4000] [loss: 0.025349, acc: 0.992188]\n[Epoch 421/4000] [loss: 0.007673, acc: 1.000000]\n[Epoch 422/4000] [loss: 0.012528, acc: 1.000000]\n[Epoch 423/4000] [loss: 0.028351, acc: 0.992188]\n[Epoch 424/4000] [loss: 0.034323, acc: 0.992188]\n[Epoch 425/4000] [loss: 0.009210, acc: 1.000000]\n[Epoch 426/4000] [loss: 0.013004, acc: 1.000000]\n[Epoch 427/4000] [loss: 0.010619, acc: 0.992188]\n[Epoch 428/4000] [loss: 0.006130, acc: 1.000000]\n[Epoch 429/4000] [loss: 0.010118, acc: 1.000000]\n[Epoch 430/4000] [loss: 0.027229, acc: 0.992188]\n[Epoch 431/4000] [loss: 0.003914, acc: 1.000000]\n[Epoch 432/4000] [loss: 0.014412, acc: 0.992188]\n[Epoch 433/4000] [loss: 0.007169, acc: 0.992188]\n[Epoch 434/4000] [loss: 0.004593, acc: 1.000000]\n[Epoch 435/4000] [loss: 0.011604, acc: 1.000000]\n[Epoch 436/4000] [loss: 0.005123, acc: 1.000000]\n[Epoch 437/4000] [loss: 0.023592, acc: 0.984375]\n[Epoch 438/4000] [loss: 0.021632, acc: 1.000000]\n[Epoch 439/4000] [loss: 0.003417, acc: 1.000000]\n[Epoch 440/4000] [loss: 0.001528, acc: 1.000000]\n[Epoch 441/4000] [loss: 0.019958, acc: 0.992188]\n[Epoch 442/4000] [loss: 0.018910, acc: 0.992188]\n[Epoch 443/4000] [loss: 0.025704, acc: 0.984375]\n[Epoch 444/4000] [loss: 0.002926, acc: 1.000000]\n[Epoch 445/4000] [loss: 0.024532, acc: 0.992188]\n[Epoch 446/4000] [loss: 0.003271, acc: 1.000000]\n[Epoch 447/4000] [loss: 0.019186, acc: 0.992188]\n[Epoch 448/4000] [loss: 0.018412, acc: 0.992188]\n[Epoch 449/4000] [loss: 0.013724, acc: 1.000000]\n[Epoch 450/4000] [loss: 0.007694, acc: 1.000000]\n[Epoch 451/4000] [loss: 0.009457, acc: 1.000000]\n[Epoch 452/4000] [loss: 0.006708, acc: 1.000000]\n[Epoch 453/4000] [loss: 0.002047, acc: 1.000000]\n[Epoch 454/4000] [loss: 0.021363, acc: 0.992188]\n[Epoch 455/4000] [loss: 0.011178, acc: 0.992188]\n[Epoch 456/4000] [loss: 0.059856, acc: 0.976562]\n[Epoch 457/4000] [loss: 0.005904, acc: 1.000000]\n[Epoch 458/4000] [loss: 0.006052, acc: 1.000000]\n[Epoch 459/4000] [loss: 0.007812, acc: 1.000000]\n[Epoch 460/4000] [loss: 0.006725, acc: 1.000000]\n[Epoch 461/4000] [loss: 0.019076, acc: 0.992188]\n[Epoch 462/4000] [loss: 0.003069, acc: 1.000000]\n[Epoch 463/4000] [loss: 0.002217, acc: 1.000000]\n[Epoch 464/4000] [loss: 0.010250, acc: 1.000000]\n[Epoch 465/4000] [loss: 0.006908, acc: 1.000000]\n[Epoch 466/4000] [loss: 0.004674, acc: 1.000000]\n[Epoch 467/4000] [loss: 0.005720, acc: 1.000000]\n[Epoch 468/4000] [loss: 0.003455, acc: 1.000000]\n[Epoch 469/4000] [loss: 0.013198, acc: 0.992188]\n[Epoch 470/4000] [loss: 0.052460, acc: 0.976562]\n[Epoch 471/4000] [loss: 0.007799, acc: 1.000000]\n[Epoch 472/4000] [loss: 0.037113, acc: 0.992188]\n[Epoch 473/4000] [loss: 0.037619, acc: 0.992188]\n[Epoch 474/4000] [loss: 0.020593, acc: 0.992188]\n[Epoch 475/4000] [loss: 0.011392, acc: 1.000000]\n[Epoch 476/4000] [loss: 0.021922, acc: 0.984375]\n[Epoch 477/4000] [loss: 0.009062, acc: 0.992188]\n[Epoch 478/4000] [loss: 0.031356, acc: 0.992188]\n[Epoch 479/4000] [loss: 0.021191, acc: 0.992188]\n[Epoch 480/4000] [loss: 0.007571, acc: 1.000000]\n[Epoch 481/4000] [loss: 0.031438, acc: 0.984375]\n[Epoch 482/4000] [loss: 0.001232, acc: 1.000000]\n[Epoch 483/4000] [loss: 0.002784, acc: 1.000000]\n[Epoch 484/4000] [loss: 0.019822, acc: 0.992188]\n[Epoch 485/4000] [loss: 0.001747, acc: 1.000000]\n[Epoch 486/4000] [loss: 0.003551, acc: 1.000000]\n[Epoch 487/4000] [loss: 0.004811, acc: 1.000000]\n[Epoch 488/4000] [loss: 0.008079, acc: 1.000000]\n[Epoch 489/4000] [loss: 0.005211, acc: 1.000000]\n[Epoch 490/4000] [loss: 0.015488, acc: 0.992188]\n[Epoch 491/4000] [loss: 0.005020, acc: 1.000000]\n[Epoch 492/4000] [loss: 0.021798, acc: 0.992188]\n[Epoch 493/4000] [loss: 0.008525, acc: 1.000000]\n[Epoch 494/4000] [loss: 0.008432, acc: 0.992188]\n[Epoch 495/4000] [loss: 0.031785, acc: 0.992188]\n[Epoch 496/4000] [loss: 0.006619, acc: 1.000000]\n[Epoch 497/4000] [loss: 0.003549, acc: 1.000000]\n[Epoch 498/4000] [loss: 0.003851, acc: 1.000000]\n[Epoch 499/4000] [loss: 0.013045, acc: 0.992188]\n[Epoch 500/4000] [loss: 0.002796, acc: 1.000000]\nReal: 1.0\nGenerated: [0.99999607]\nINFO:tensorflow:Assets written to: ./saved_models/500classifier/assets\n"},{"output_type":"stream","name":"stderr","text":"ERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\nERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\n"},{"output_type":"stream","name":"stdout","text":"Traceback (most recent call last):\n  File \"/kernel/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-c90e11c5ab67>\", line 15, in <module>\n    me_pictures = me_pictures / 255\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/kernel/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/kernel/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"/kernel/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n    return f(*args, **kwargs)\n  File \"/kernel/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n    filename = getsourcefile(frame) or getfile(frame)\n  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n  File \"/usr/lib/python3.7/inspect.py\", line 739, in getmodule\n    f = getabsfile(module)\n  File \"/usr/lib/python3.7/inspect.py\", line 708, in getabsfile\n    _filename = getsourcefile(object) or getfile(object)\n  File \"/usr/lib/python3.7/inspect.py\", line 693, in getsourcefile\n    if os.path.exists(filename):\n  File \"/usr/lib/python3.7/genericpath.py\", line 19, in exists\n    os.stat(path)\nKeyboardInterrupt\n"},{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: model\n  warnings.warn(message)\n"},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)","    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n","\u001B[0;32m<ipython-input-1-c90e11c5ab67>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m         \u001B[0mme_pictures\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mme_pictures\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;36m255\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m         \u001B[0meveryone_pictures\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0meveryone_pictures\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;36m255\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mKeyboardInterrupt\u001B[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)","\u001B[0;32m/kernel/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2044\u001B[0m                         \u001B[0;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2045\u001B[0;31m                         \u001B[0mstb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2046\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mAttributeError\u001B[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)","    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n","\u001B[0;32m/kernel/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2046\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2047\u001B[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[0;32m-> 2048\u001B[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001B[0m\u001B[1;32m   2049\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2050\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_showtraceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/kernel/lib/python3.7/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1435\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1436\u001B[0m         return FormattedTB.structured_traceback(\n\u001B[0;32m-> 1437\u001B[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[0m\u001B[1;32m   1438\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1439\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/kernel/lib/python3.7/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1335\u001B[0m             \u001B[0;31m# Verbose modes need a full traceback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1336\u001B[0m             return VerboseTB.structured_traceback(\n\u001B[0;32m-> 1337\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1338\u001B[0m             )\n\u001B[1;32m   1339\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'Minimal'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/kernel/lib/python3.7/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1192\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1193\u001B[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[0;32m-> 1194\u001B[0;31m                                                                tb_offset)\n\u001B[0m\u001B[1;32m   1195\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1196\u001B[0m         \u001B[0mcolors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mColors\u001B[0m  \u001B[0;31m# just a shorthand + quicker name lookup\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/kernel/lib/python3.7/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1149\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1150\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1151\u001B[0;31m         \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1152\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1153\u001B[0m         \u001B[0mframes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/kernel/lib/python3.7/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[0;34m(etype, value, records)\u001B[0m\n\u001B[1;32m    449\u001B[0m     \u001B[0;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    450\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 451\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    452\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    453\u001B[0m     \u001B[0;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"]}],"execution_count":21},{"cell_type":"code","source":"#!g1.1\n","metadata":{"cellId":"j3o2ossoao3vcfqjtl7qc"},"outputs":[],"execution_count":null}]}